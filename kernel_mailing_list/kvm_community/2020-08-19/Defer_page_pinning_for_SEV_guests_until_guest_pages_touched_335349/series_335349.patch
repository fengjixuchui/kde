From patchwork Wed Aug 19 15:17:39 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: eric van tassell <Eric.VanTassell@amd.com>
X-Patchwork-Id: 11724409
Return-Path: <SRS0=Yqqy=B5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 27FD21575
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:17:22 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id F13F220885
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:17:21 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=amdcloud.onmicrosoft.com
 header.i=@amdcloud.onmicrosoft.com header.b="doyoLTjh"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728664AbgHSPRT (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 19 Aug 2020 11:17:19 -0400
Received: from mail-bn7nam10on2044.outbound.protection.outlook.com
 ([40.107.92.44]:48186
        "EHLO NAM10-BN7-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726899AbgHSPRH (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 19 Aug 2020 11:17:07 -0400
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=QWWAcdH4KXUZKQzT6yc7tnQTHG2eps9E/YMxztDc0piKCbjAxxdDRsQc4JvPKHApCVQoOfDAHNALfrsGaZqmR7pQzyCC0W+InMJAXd5U/5R7CeGwUOrxJdBF01d4pgzFRDspLLL4+zmElpB8B5fDD/EzvOIjf334Pox3FBtL0ioAATch+fTU4tMp7u48WWBdb/y+TaGQrjIw045PkY9obALrGE06kpi38Y1y/NGk2OBUlLMaGWsCxegcO9S3Mp1+ly9rUK1DXFKG7yhncikf8to/SZvmaqHuJJCeOb50meETa8SsxxIZxiFa7UHancRxS9G6G0XR+BF+R0VzGLZUQg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=VaKGJyweKaytkfpqj2e0PU0xmX+dpQkYsSUqtutHKgM=;
 b=i4rUieP1mMQ1BptpDPHu9684l65XG1HPPfGjlqF6Q0YJenpHQYOxNoA2zgwd7GBV6XDXT73wtvE+J8LnpdYbAs8+wYD6+YbvEnO0j8QHSn5VSokaJDtamedTFtALZgXRU2F19J1Sj7y+QLtAB+lcptJ1hkViKXaR2jY1SLsXmnUxHgm++PPyHIFic2xkCYgPHGKa7EbN450XCRd3FKbfcAgljnkN7Qu+rQ+n09TqzH9JAgj8Lzahk549FweCJ7ODCKBnEYPLtotiKIKUTZV6/NZz973gv4KYso16wgn141IVPi6EWwf1dICXSKgzibsvtDcXgKpKd0Rh6gSE+4AoIQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=VaKGJyweKaytkfpqj2e0PU0xmX+dpQkYsSUqtutHKgM=;
 b=doyoLTjhf4f6bkTV8ZxaIIhLjkVF6GLQi32PlnckP/WsbfMo3jNB6rRDubk0zCJBQNq3RzyPz7PSmZ2RdhI+GEPshidxnpvSZHwSs/Gcj72yVyySzA7o5AqTjy00jlHwnoaNF0R/wginSCLmD8AZapudjCzAO8xobPgDKD+4bpM=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from DM5PR12MB1307.namprd12.prod.outlook.com (2603:10b6:3:79::21) by
 DM6PR12MB3227.namprd12.prod.outlook.com (2603:10b6:5:18d::14) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.3305.24; Wed, 19 Aug 2020 15:16:57 +0000
Received: from DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162]) by DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162%11]) with mapi id 15.20.3283.028; Wed, 19 Aug
 2020 15:16:57 +0000
From: eric van tassell <Eric.VanTassell@amd.com>
To: kvm@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, bp@alien8.de, hpa@zytor.com,
        mingo@redhat.com, jmattson@google.com, joro@8bytes.org,
        pbonzini@redhat.com, sean.j.christopherson@intel.com,
        tglx@linutronix.de, vkuznets@redhat.com, wanpengli@tencent.com,
        x86@kernel.org, rientjes@google.com, junaids@google.com,
        evantass@amd.com
Subject: [Patch v2 1/4] KVM:MMU: Introduce the pin_page() callback
Date: Wed, 19 Aug 2020 10:17:39 -0500
Message-Id: <20200819151742.7892-2-Eric.VanTassell@amd.com>
X-Mailer: git-send-email 2.17.1
In-Reply-To: <20200819151742.7892-1-Eric.VanTassell@amd.com>
References: <20200819151742.7892-1-Eric.VanTassell@amd.com>
X-ClientProxiedBy: DM5PR19CA0045.namprd19.prod.outlook.com
 (2603:10b6:3:9a::31) To DM5PR12MB1307.namprd12.prod.outlook.com
 (2603:10b6:3:79::21)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from evt-speedway-83bc.amd.com (165.204.78.2) by
 DM5PR19CA0045.namprd19.prod.outlook.com (2603:10b6:3:9a::31) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3305.24 via Frontend
 Transport; Wed, 19 Aug 2020 15:16:56 +0000
X-Mailer: git-send-email 2.17.1
X-Originating-IP: [165.204.78.2]
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: 9f639cf6-edbf-4ff1-2d0f-08d84452e9dc
X-MS-TrafficTypeDiagnostic: DM6PR12MB3227:
X-MS-Exchange-Transport-Forked: True
X-Microsoft-Antispam-PRVS: 
 <DM6PR12MB3227543FC5E01C5F0A77E098E75D0@DM6PR12MB3227.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:8882;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 GaSvrHAMZGNVvPkRrTSrfj189Dc22maaJdbBVJslHIp61o4JKf+N69Zg5oMrW0q17fieSYNvu0m3SGzsL6hKEqtLFbaLwGWjhm9JaZ+NKYcaob+yI7vednSyj5XA7J4mpd42RKQdVVI/nTMpoT7ys5TD9clg0V5KkIuHYRwJdywtjybg5MaTt1zpyrzGvVHCJPSj5lpO4rdUX90Y16a/bDWzkTmm3UBDxGAn6Spo0197obO4635zdNuzBxZQnXrlOkk8jNJMF8SCElc24OZCMndBf59II8c06Z7W8eQpg3ieTiYQPDPEnX5thdqlEuWZ
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:DM5PR12MB1307.namprd12.prod.outlook.com;PTR:;CAT:NONE;SFS:(4636009)(346002)(376002)(136003)(396003)(366004)(39860400002)(66556008)(66476007)(8676002)(66946007)(26005)(86362001)(1076003)(5660300002)(478600001)(6486002)(36756003)(316002)(83380400001)(6666004)(7416002)(2906002)(8936002)(6916009)(4326008)(2616005)(7696005)(16526019)(52116002)(186003)(956004);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData: 
 E357RBRZowO273PDBhEUmo+B2tNkvt26FTm0WMJwPZlPWlTE2Y9/4JZ4x+x1+ZEBkppQ2me1IPwBVSGsWeQaS3jcoGI/k/G/RgB/s/L70Vi02EbtCS6dwuoElSAlWywhgrlt8ab3q+0zN0pbUo5YSiDjrs/wGDqgJkzwoJ7czfoBJBT1f+eV3c1NpuxJpyxppJSJdFdkQ1H6E/0LWD0q1lBGJZg77O3mu4OVWU1ieW93tMUxsx76Ly17Av+K2LrM9nUTMFSNAElkJL7dLu0VocZXtAuXHxjf/QZsjainoyVyodOmV6hkaqPwWm7VIKhXlDOlz9i2Lcu09uD+OQ62TIuvFU+5LzI8jwtxKvYW69p6Oi1QKeMESSWsfAgph/ZdJD9sAS13lYSr1wI7mgogqT4KqO3Ik9qyiXL3TZ2Dpc8PlaAI36daY3Na9MSBNgn1/6fTJyXGJiVDTS0CixS0bgrVFvoQl7anMYh1EZzTa040tp+3osRERmFPb+57Ok2R9gIHNVnWV87PExgnzi1QSWiB2XKU+8XGaAjBc/EVfNdzQ7KzrJxWXJTC8sQ8Uo9L800EHPSLtDnwTt6gTYslX1eeN4P2b8KtX9lBnDi34vw/0Ky9M+DCIeZdvIHo2kesfRa7ZeZBsYooL7e4hcj43g==
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 9f639cf6-edbf-4ff1-2d0f-08d84452e9dc
X-MS-Exchange-CrossTenant-AuthSource: DM5PR12MB1307.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Aug 2020 15:16:57.6612
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 2mt7HUv/gDMoA1yakRHrbZTxzzn2JjJi+3n6K37wElrhcAfIMSLYdYX4epJrFfioR2INDElMomlDlOFro0DtRg==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM6PR12MB3227
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

This generic callback will be called just before setting the spte.

Check the return code where not previously checked since this operation can
return an error.

Defer pinning of SEV guest pages until they're used in order to reduce SEV
guest startup time by eliminating the compute cycles required to pin all
the pages up front. Additionally, we want to reduce memory pressure due to
guests that reserve but only sparsely access a large amount of memory.

Co-developed-by: Brijesh Singh <brijesh.singh@amd.com>
Signed-off-by: eric van tassell <Eric.VanTassell@amd.com>
---
 arch/x86/include/asm/kvm_host.h |  3 +++
 arch/x86/kvm/mmu/mmu.c          | 30 ++++++++++++++++++++++++++----
 arch/x86/kvm/mmu/paging_tmpl.h  | 27 ++++++++++++++++-----------
 3 files changed, 45 insertions(+), 15 deletions(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 5aaef036627f..767653fa3245 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1227,6 +1227,9 @@ struct kvm_x86_ops {
 	int (*enable_direct_tlbflush)(struct kvm_vcpu *vcpu);
 
 	void (*migrate_timers)(struct kvm_vcpu *vcpu);
+
+	int (*pin_page)(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn,
+			int level, u64 *spte);
 };
 
 struct kvm_x86_nested_ops {
diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
index fa506aaaf019..2b60fdb79b86 100644
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -3004,6 +3004,22 @@ static int set_spte(struct kvm_vcpu *vcpu, u64 *sptep,
 		spte |= kvm_x86_ops.get_mt_mask(vcpu, gfn,
 			kvm_is_mmio_pfn(pfn));
 
+	if (kvm_x86_ops.pin_page && !kvm_is_mmio_pfn(pfn)) {
+		ret = kvm_x86_ops.pin_page(vcpu, gfn, pfn, level, &spte);
+		if (ret) {
+			if (WARN_ON_ONCE(ret > 0))
+				/*
+				 * pin_page() should return 0 on success
+				 * and non-zero preferably less than zero,
+				 * for failure.  We check for any unanticipated
+				 * positive return values here.
+				 */
+				ret = -EINVAL;
+
+			return ret;
+		}
+	}
+
 	if (host_writable)
 		spte |= SPTE_HOST_WRITEABLE;
 	else
@@ -3086,6 +3102,9 @@ static int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,
 
 	set_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,
 				speculative, true, host_writable);
+	if (set_spte_ret < 0)
+		return set_spte_ret;
+
 	if (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {
 		if (write_fault)
 			ret = RET_PF_EMULATE;
@@ -3134,7 +3153,7 @@ static int direct_pte_prefetch_many(struct kvm_vcpu *vcpu,
 	struct page *pages[PTE_PREFETCH_NUM];
 	struct kvm_memory_slot *slot;
 	unsigned int access = sp->role.access;
-	int i, ret;
+	int i, ret, error_ret = 0;
 	gfn_t gfn;
 
 	gfn = kvm_mmu_page_get_gfn(sp, start - sp->spt);
@@ -3147,12 +3166,15 @@ static int direct_pte_prefetch_many(struct kvm_vcpu *vcpu,
 		return -1;
 
 	for (i = 0; i < ret; i++, gfn++, start++) {
-		mmu_set_spte(vcpu, start, access, 0, sp->role.level, gfn,
-			     page_to_pfn(pages[i]), true, true);
+		ret = mmu_set_spte(vcpu, start, access, 0, sp->role.level, gfn,
+				   page_to_pfn(pages[i]), true, true);
+		if (ret < 0 && error_ret == 0) /* only track 1st fail */
+			error_ret = ret;
 		put_page(pages[i]);
 	}
 
-	return 0;
+	/* If there was an error for any gfn, return non-0. */
+	return error_ret;
 }
 
 static void __direct_pte_prefetch(struct kvm_vcpu *vcpu,
diff --git a/arch/x86/kvm/mmu/paging_tmpl.h b/arch/x86/kvm/mmu/paging_tmpl.h
index 0172a949f6a7..a777bb43dfa0 100644
--- a/arch/x86/kvm/mmu/paging_tmpl.h
+++ b/arch/x86/kvm/mmu/paging_tmpl.h
@@ -532,6 +532,7 @@ FNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,
 	unsigned pte_access;
 	gfn_t gfn;
 	kvm_pfn_t pfn;
+	int set_spte_ret;
 
 	if (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))
 		return false;
@@ -550,11 +551,12 @@ FNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,
 	 * we call mmu_set_spte() with host_writable = true because
 	 * pte_prefetch_gfn_to_pfn always gets a writable pfn.
 	 */
-	mmu_set_spte(vcpu, spte, pte_access, 0, PG_LEVEL_4K, gfn, pfn,
-		     true, true);
+	set_spte_ret = mmu_set_spte(vcpu, spte, pte_access, 0,
+				    PG_LEVEL_4K, gfn, pfn, true, true);
 
 	kvm_release_pfn_clean(pfn);
-	return true;
+
+	return set_spte_ret >= 0;
 }
 
 static void FNAME(update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,
@@ -1011,7 +1013,8 @@ static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)
 	int i, nr_present = 0;
 	bool host_writable;
 	gpa_t first_pte_gpa;
-	int set_spte_ret = 0;
+	int ret;
+	int accum_set_spte_flags = 0;
 
 	/* direct kvm_mmu_page can not be unsync. */
 	BUG_ON(sp->role.direct);
@@ -1064,17 +1067,19 @@ static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)
 			continue;
 		}
 
-		nr_present++;
-
 		host_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;
 
-		set_spte_ret |= set_spte(vcpu, &sp->spt[i],
-					 pte_access, PG_LEVEL_4K,
-					 gfn, spte_to_pfn(sp->spt[i]),
-					 true, false, host_writable);
+		ret = set_spte(vcpu, &sp->spt[i], pte_access,
+			       PG_LEVEL_4K, gfn,
+			       spte_to_pfn(sp->spt[i]), true, false,
+			       host_writable);
+		if (ret >= 0) {
+			nr_present++;
+			accum_set_spte_flags |= ret;
+		}
 	}
 
-	if (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH)
+	if (accum_set_spte_flags & SET_SPTE_NEED_REMOTE_TLB_FLUSH)
 		kvm_flush_remote_tlbs(vcpu->kvm);
 
 	return nr_present;

From patchwork Wed Aug 19 15:17:40 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: eric van tassell <Eric.VanTassell@amd.com>
X-Patchwork-Id: 11724411
Return-Path: <SRS0=Yqqy=B5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id BB2D01575
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:17:43 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id 8C606207FF
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:17:43 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=amdcloud.onmicrosoft.com
 header.i=@amdcloud.onmicrosoft.com header.b="nZ1Pz+3w"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726897AbgHSPRk (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 19 Aug 2020 11:17:40 -0400
Received: from mail-bn7nam10on2044.outbound.protection.outlook.com
 ([40.107.92.44]:48186
        "EHLO NAM10-BN7-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726894AbgHSPRT (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 19 Aug 2020 11:17:19 -0400
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=SgYvMlTpXo3Zdt7iH1O78yenxFhS40Yr6XOLsU/wmgXPZhUGu6BCYYX2C6JWrblPxBuLMX7TnowC6V/CYVWE+1q98PXkv2mP9nsZYL5yPiokw8zvP+zMACD8lDk8L5Z2gtZQHWlwDeTajb5kdm0QqPBluBGsg5KKRlv7N+8HFPcgdaGO9UI77BExQyAnkfN64Du1rYcEbbwRn626sc9j5L6zR6io76HqRqooUxfRgd4BNnUTMDNzrs6mZZDkVWxz7cF50WvNKuSYgUvxfjfaT9V74xP73zP1iwS/bKMWc+pLgf8bW0qJnH/tY0Ghuwj3o2s4PXpY/G6AziI5rD0KRw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=ZFKwKTr1cZPT09GMIL93Z0ukKNniqRmLsiDSLh8BJ/E=;
 b=j8/GZrJbo/OMSmlXAoNJB7ascSPiiU2eISXbRBEv9e+SmFc+5hRLahWzbcNF/JwJoJ+P9j1xLII1r+PrfBD5copIFbqx1TFo11yM/auNdbJOpoOACYki3YX5EqnN0/QUvQ0RQ4AH6ALm0JXmTtRQcJUJJgffTtXJ1TlTkh9MAYFhE3032QSaOtU5vUhQyIuO1aq2o+GZqmNnZnDMvweDXwlI8/9nLV+JRZpdkRoHqQb5pL0LMLuDKBJxDEW2rYtGWncW5soJg4psX6bQ6zkScdJBQjstLW9/jrrnisAZWwK0NpPxHRy0QZjPoHH75Bb5pHPDlyHt/gCNFt0kMnxaMg==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=ZFKwKTr1cZPT09GMIL93Z0ukKNniqRmLsiDSLh8BJ/E=;
 b=nZ1Pz+3w7nDXBzltJhgKwwVNY5A5B11dv3xfjQVyYQndmS/XyfklxnjLNz7zhBBEe2+8eLaWjYRMgT5b+PF0vphtxQ0Arg2mJLt+ZhqBHJScG17ot93ZqymZT4a0kqtAfsi/c8ySSflUJS/gY+T7susFAwmNCY8bqSAoQYgnBrg=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from DM5PR12MB1307.namprd12.prod.outlook.com (2603:10b6:3:79::21) by
 DM6PR12MB3227.namprd12.prod.outlook.com (2603:10b6:5:18d::14) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.3305.24; Wed, 19 Aug 2020 15:16:59 +0000
Received: from DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162]) by DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162%11]) with mapi id 15.20.3283.028; Wed, 19 Aug
 2020 15:16:58 +0000
From: eric van tassell <Eric.VanTassell@amd.com>
To: kvm@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, bp@alien8.de, hpa@zytor.com,
        mingo@redhat.com, jmattson@google.com, joro@8bytes.org,
        pbonzini@redhat.com, sean.j.christopherson@intel.com,
        tglx@linutronix.de, vkuznets@redhat.com, wanpengli@tencent.com,
        x86@kernel.org, rientjes@google.com, junaids@google.com,
        evantass@amd.com
Subject: [Patch v2 2/4] KVM:SVM: Implement pin_page support
Date: Wed, 19 Aug 2020 10:17:40 -0500
Message-Id: <20200819151742.7892-3-Eric.VanTassell@amd.com>
X-Mailer: git-send-email 2.17.1
In-Reply-To: <20200819151742.7892-1-Eric.VanTassell@amd.com>
References: <20200819151742.7892-1-Eric.VanTassell@amd.com>
X-ClientProxiedBy: DM5PR19CA0045.namprd19.prod.outlook.com
 (2603:10b6:3:9a::31) To DM5PR12MB1307.namprd12.prod.outlook.com
 (2603:10b6:3:79::21)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from evt-speedway-83bc.amd.com (165.204.78.2) by
 DM5PR19CA0045.namprd19.prod.outlook.com (2603:10b6:3:9a::31) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3305.24 via Frontend
 Transport; Wed, 19 Aug 2020 15:16:57 +0000
X-Mailer: git-send-email 2.17.1
X-Originating-IP: [165.204.78.2]
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: 5f22a8c5-2942-4058-8f9f-08d84452ea8d
X-MS-TrafficTypeDiagnostic: DM6PR12MB3227:
X-MS-Exchange-Transport-Forked: True
X-Microsoft-Antispam-PRVS: 
 <DM6PR12MB322759B0E2A793F37EF0D787E75D0@DM6PR12MB3227.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:2733;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 vIb8Icni/FRFt12bcktDjauqC49muDWQPioTm3NeegfspZFMY+VEoYT85JLOuGi2F/BE1LUwmloz3qETubfyu3B1vpXm5sxri6F9tJlJmC6aqcRlcjfH2VIau4zD20bIoFplND53lRmwVfhxrZBEzhFcktzQswYhfLo/oZIX+gxrQgZxqezW8vu8UUF5wQ1jCyHNLloe2YPYJQo2SmJvYEREnhWC3fAQwyCtYo+SZ9zqkR3eulYhz3/SPXVZUzeXpvcudaFfzoG4A6BZ5Gn8J1oF7BuJ/Rx+zbrNCDjA157ezuSb/zHVQcxxhcEzPMlo
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:DM5PR12MB1307.namprd12.prod.outlook.com;PTR:;CAT:NONE;SFS:(4636009)(346002)(376002)(136003)(396003)(366004)(39860400002)(66556008)(66476007)(8676002)(66946007)(26005)(86362001)(1076003)(5660300002)(478600001)(6486002)(36756003)(316002)(83380400001)(6666004)(7416002)(2906002)(8936002)(6916009)(4326008)(2616005)(7696005)(16526019)(52116002)(186003)(956004);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData: 
 P9P2rqwReD1+e81dfCh2GfH1EHIUkwcwSREnad2HW+eOuuYyjvHmFWtu5ELstD27rdDZCnVvROWX9My5xm+QatxZrvmXHpbEBgQjO6q6Ey2l8qmZqqxIlYq57p5Ym14czGvcymt0jKSYSBscOZDqhloJ4k4LchUesDJmgUdSKVCZ82EFR1njAsD9WQrRRIZ202lln9d+FSCXsWH0/P2iXz5UC+eztSDueWmbeOCPMc5keTw+hpjRrZVKsg3kOpUKP+mJjWcf5hZ1R9u3iZWSdf/BdvA3EDv5CX2tjCbk63APlE+wPZL6s4AfghYn9x6haj9Fg3mY6b1XB5E3Or++L2845JrvMgLify/Rry9dBziAQAzZokEnKiVLmtOEXhEVLACBJPqGmd+RuM5PJFL7a+XarJDdqaan8YRc/tL9T1rOTb7WMU+FSwiu5hPt57rVrLCokXX3Fn/ORYlejHePKGecUFxJNBWYFikBkminkHnfi2LNW4Zqb3AkfMtCDJgq6vBK+E8u+XA8VCwp5YqrfC8TqK1ff2OKktoVm/mF4KbhcZN+OfNDIcvWPO4EKX0eEjWvyiSHXMCrTCL1G71kCl1yEMWdFkT67NJxL7yLLTrQRUMhJgnzt2A3IBLowImHaaaZJzr1+u1jie6pdnYTww==
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 5f22a8c5-2942-4058-8f9f-08d84452ea8d
X-MS-Exchange-CrossTenant-AuthSource: DM5PR12MB1307.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Aug 2020 15:16:58.7597
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 swbdO479WyydJKz9R2WOLnrMNe5AQeZaFe2IBHffuBqKJWr/sos1QDCTxpbgA/ov+Q89HmNELPSeHJ54TiIsrw==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM6PR12MB3227
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Improve SEV guest startup time from O(n) to a constant by deferring
guest page pinning until the pages are used to satisfy nested page faults.

Implement the code to do the pinning (sev_get_page) and the notifier
sev_pin_page().

Track the pinned pages with xarray so they can be released during guest
termination.

Co-developed-by: Brijesh Singh <brijesh.singh@amd.com>
Signed-off-by: eric van tassell <Eric.VanTassell@amd.com>
---
 arch/x86/kvm/svm/sev.c | 68 ++++++++++++++++++++++++++++++++++++++++++
 arch/x86/kvm/svm/svm.c |  2 ++
 arch/x86/kvm/svm/svm.h |  3 ++
 3 files changed, 73 insertions(+)

diff --git a/arch/x86/kvm/svm/sev.c b/arch/x86/kvm/svm/sev.c
index f7f1f4ecf08e..8d56d1afb33e 100644
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@ -184,6 +184,8 @@ static int sev_guest_init(struct kvm *kvm, struct kvm_sev_cmd *argp)
 	sev->asid = asid;
 	INIT_LIST_HEAD(&sev->regions_list);
 
+	xa_init(&sev->pages_xarray);
+
 	return 0;
 
 e_free:
@@ -415,6 +417,43 @@ static unsigned long get_num_contig_pages(unsigned long idx,
 	return pages;
 }
 
+static int sev_get_page(struct kvm *kvm, gfn_t gfn, kvm_pfn_t pfn)
+{
+	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+	struct xarray *xa = &sev->pages_xarray;
+	struct page *page = pfn_to_page(pfn);
+	int ret;
+
+	/* store page at index = gfn */
+	ret = xa_insert(xa, gfn, page, GFP_ATOMIC);
+	if (ret == -EBUSY) {
+		/*
+		 * If xa_insert returned -EBUSY, the  gfn was already associated
+		 * with a struct page *.
+		 */
+		struct page *cur_page;
+
+		cur_page = xa_load(xa, gfn);
+		/* If cur_page == page, no change is needed, so return 0 */
+		if (cur_page == page)
+			return 0;
+
+		/* Release the page that was stored at index = gfn */
+		put_page(cur_page);
+
+		/* Return result of attempting to store page at index = gfn */
+		ret = xa_err(xa_store(xa, gfn, page, GFP_ATOMIC));
+		WARN_ON(ret != 0);
+	}
+
+	if (ret)
+		return ret;
+
+	get_page(page);
+
+	return 0;
+}
+
 static int sev_launch_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
 {
 	unsigned long vaddr, vaddr_end, next_vaddr, npages, pages, size, i;
@@ -1085,6 +1124,8 @@ void sev_vm_destroy(struct kvm *kvm)
 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
 	struct list_head *head = &sev->regions_list;
 	struct list_head *pos, *q;
+	XA_STATE(xas, &sev->pages_xarray, 0);
+	struct page *xa_page;
 
 	if (!sev_guest(kvm))
 		return;
@@ -1109,6 +1150,12 @@ void sev_vm_destroy(struct kvm *kvm)
 		}
 	}
 
+	/* Release each pinned page that SEV tracked in sev->pages_xarray. */
+	xas_for_each(&xas, xa_page, ULONG_MAX) {
+		put_page(xa_page);
+	}
+	xa_destroy(&sev->pages_xarray);
+
 	mutex_unlock(&kvm->lock);
 
 	sev_unbind_asid(kvm, sev->handle);
@@ -1193,3 +1240,24 @@ void pre_sev_run(struct vcpu_svm *svm, int cpu)
 	svm->vmcb->control.tlb_ctl = TLB_CONTROL_FLUSH_ASID;
 	vmcb_mark_dirty(svm->vmcb, VMCB_ASID);
 }
+
+int sev_pin_page(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn,
+		 int level, u64 *spte)
+{
+	int rc;
+
+	if (!sev_guest(vcpu->kvm))
+		return 0;
+
+	rc = sev_get_page(vcpu->kvm, gfn, pfn);
+	if (rc)
+		return rc;
+
+	/*
+	 * Flush any cached lines of the page being added since "ownership" of
+	 * it will be transferred from the host to an encrypted guest.
+	 */
+	clflush_cache_range(__va(pfn << PAGE_SHIFT), page_level_size(level));
+
+	return 0;
+}
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 535ad311ad02..adb308631416 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -4130,6 +4130,8 @@ static struct kvm_x86_ops svm_x86_ops __initdata = {
 	.need_emulation_on_page_fault = svm_need_emulation_on_page_fault,
 
 	.apic_init_signal_blocked = svm_apic_init_signal_blocked,
+
+	.pin_page = sev_pin_page,
 };
 
 static struct kvm_x86_init_ops svm_init_ops __initdata = {
diff --git a/arch/x86/kvm/svm/svm.h b/arch/x86/kvm/svm/svm.h
index 121b198b51e9..278c46bc52aa 100644
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@ -65,6 +65,7 @@ struct kvm_sev_info {
 	int fd;			/* SEV device fd */
 	unsigned long pages_locked; /* Number of pages locked */
 	struct list_head regions_list;  /* List of registered regions */
+	struct xarray pages_xarray; /* List of PFN locked */
 };
 
 struct kvm_svm {
@@ -488,5 +489,7 @@ int svm_unregister_enc_region(struct kvm *kvm,
 void pre_sev_run(struct vcpu_svm *svm, int cpu);
 int __init sev_hardware_setup(void);
 void sev_hardware_teardown(void);
+int sev_pin_page(struct kvm_vcpu *vcpu, gfn_t gfn, kvm_pfn_t pfn,
+		 int level, u64 *spte);
 
 #endif

From patchwork Wed Aug 19 15:17:41 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: eric van tassell <Eric.VanTassell@amd.com>
X-Patchwork-Id: 11724413
Return-Path: <SRS0=Yqqy=B5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 61E0415E4
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:18:38 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id 440EF207FF
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:18:38 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=amdcloud.onmicrosoft.com
 header.i=@amdcloud.onmicrosoft.com header.b="KEamFOrd"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1728740AbgHSPSb (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 19 Aug 2020 11:18:31 -0400
Received: from mail-bn7nam10on2044.outbound.protection.outlook.com
 ([40.107.92.44]:48186
        "EHLO NAM10-BN7-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726951AbgHSPRq (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 19 Aug 2020 11:17:46 -0400
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=j7Ze09sw1lzpKbMSgr4SaZTzAu6B4ExsoyxO7ZPUHPtDX1DEF5ICxdw0whakPfOBo8QlezpUTUh72nwYn+3R+4Z/CYJUDphzypZFsUG+vEzgveVyftk5E+B0wLxXb1bREwB9PFAwdMZa2LRxLUVIrRzF8pqzDQkaLn22s91B3G6qvVGBjWleE43nLaui7bZQJM+HIATTDCscaShfWRjVia39i9gCzNprmxx01XJZWQuzAyZEOuDRyX3ql0kkTPyb+pkb1/oMWv6FJij/kQNaKSU0rgCUqX1CSBytICsoskisbDFzTw3/D3VoH2981TJooOXhTeoTTtDbrgCMKj7mYQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Xz0EjzPbtP7r/WHnhnHVKye2vpfYurUcEZzPObigktI=;
 b=L8oNNrJy4eRtOKMSfTshyNa3+9erPUkSFLmd/WB5/O/FAdj1UjdU7AZKU2GVzRL0sHoR1alLN2qCKj7nUokDx5qbtMK2LUkgq64DQAWVcZRwom4AFahjslfqVMM04WdKzOwlGBFP/7lsnqDFHQX8KaXboarJWydm/HSRQXIusQSKUVT1AWdY266IPu+q0AyW+fHThQrTLWTJL2YnIhor6Dny9NQSw0MxmljFfgRBjaevkSK3W0LIIrTHx/iyAMaubPC2MhOidiV7bbARkh5DxqK0RgwOVUWXHLQwP9QQ8xNqqvrdbUMEkfDxtYH3oX81bQGmbTMNslwUX97lUpHB6w==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Xz0EjzPbtP7r/WHnhnHVKye2vpfYurUcEZzPObigktI=;
 b=KEamFOrdRSQDTyn7cJngiydWfaBl3wnYBnELNOlpeHf/rFp4+UrzdVrSV0LCZREaCRxzYndjRTvV3BRAF+TD/Vae6bkc+gf4ta0p+FHDjShyQkGC6ZCGOPB6OCS0/tgH3RR7o9Etob/an6cGNtijmheFyjiP6S9ZaKzo8JNS2fo=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from DM5PR12MB1307.namprd12.prod.outlook.com (2603:10b6:3:79::21) by
 DM6PR12MB3227.namprd12.prod.outlook.com (2603:10b6:5:18d::14) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.3305.24; Wed, 19 Aug 2020 15:17:00 +0000
Received: from DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162]) by DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162%11]) with mapi id 15.20.3283.028; Wed, 19 Aug
 2020 15:17:00 +0000
From: eric van tassell <Eric.VanTassell@amd.com>
To: kvm@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, bp@alien8.de, hpa@zytor.com,
        mingo@redhat.com, jmattson@google.com, joro@8bytes.org,
        pbonzini@redhat.com, sean.j.christopherson@intel.com,
        tglx@linutronix.de, vkuznets@redhat.com, wanpengli@tencent.com,
        x86@kernel.org, rientjes@google.com, junaids@google.com,
        evantass@amd.com
Subject: [Patch v2 3/4] KVM:SVM: Pin sev_launch_update_data() pages via
 sev_get_page()
Date: Wed, 19 Aug 2020 10:17:41 -0500
Message-Id: <20200819151742.7892-4-Eric.VanTassell@amd.com>
X-Mailer: git-send-email 2.17.1
In-Reply-To: <20200819151742.7892-1-Eric.VanTassell@amd.com>
References: <20200819151742.7892-1-Eric.VanTassell@amd.com>
X-ClientProxiedBy: DM5PR19CA0045.namprd19.prod.outlook.com
 (2603:10b6:3:9a::31) To DM5PR12MB1307.namprd12.prod.outlook.com
 (2603:10b6:3:79::21)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from evt-speedway-83bc.amd.com (165.204.78.2) by
 DM5PR19CA0045.namprd19.prod.outlook.com (2603:10b6:3:9a::31) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3305.24 via Frontend
 Transport; Wed, 19 Aug 2020 15:16:59 +0000
X-Mailer: git-send-email 2.17.1
X-Originating-IP: [165.204.78.2]
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: ee1bde45-b8a9-4e6f-5535-08d84452eb59
X-MS-TrafficTypeDiagnostic: DM6PR12MB3227:
X-MS-Exchange-Transport-Forked: True
X-Microsoft-Antispam-PRVS: 
 <DM6PR12MB32272BFDF16C720FBDF39700E75D0@DM6PR12MB3227.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:7219;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 Z7IVoySYaUmQUu3Yeh7HvMYR8rDw5N9rCB25aqKZ6PqMOStgTKcQ3NK8fRvKcvgfzvp+4b+8mz2cI7OsZBP0/DdVC1ccO0QuQlhV4ZfpabBFO81F4htuih9ap8yGTqB7QwfAMGZ1gVIhjkZhydXdGXRA2QthgQwFdM8BwWwWHyNEW/ghC71Sc+z3MGwSY3LmntcfNEeXxFCMIheBAJ8pV8PhB2cykhwLULfDVg9A4JoKajaDmkKFVIDsH4wQ0pzcI5amZyDiAAebItLxsrLGIL/QEzEbYpzZVBU7gmM4cJFahLIAz5JSH+/ddIb8j3kd5WpfVH85LxEpZ2izY5Agfw==
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:DM5PR12MB1307.namprd12.prod.outlook.com;PTR:;CAT:NONE;SFS:(4636009)(346002)(376002)(136003)(396003)(366004)(39860400002)(66556008)(66476007)(8676002)(66946007)(26005)(86362001)(1076003)(5660300002)(478600001)(6486002)(36756003)(316002)(83380400001)(6666004)(7416002)(2906002)(8936002)(6916009)(4326008)(2616005)(7696005)(16526019)(52116002)(186003)(956004);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData: 
 w3N3JBp/MLyhSkF+aHd8MTDb8A0C2z7Yt2pjJIO6kKu7Y3nJG/B4kkEsWjc3YpXag52CHF0N9B7qpAafeaNlw5VGpmd36pBSty7dcTySDyOUHVKriT/WitRDFeo4j5o/E/KAKpxLamYWpHkB4VW/AhLgLruEkldKKIvq6cHeNtpQ6SUc9r1BsDLLCXXE78BhiSmxS34ac0tTutN4uBht/Q39SP9R/wbICp2t+e/VyITfDoOtFBgGtGIfXZEG1ZKC3kxrI0xx0eFf7FsP3mPsPDJFU3d19fT8rqrzhm0/aOnxYmk9IS2na3oT2GXL3gpjJxz2ayX5gVm3Sym9xgX2VUxc0ayfWkSOfXO+C0oRJe3ZFYD3rMFob6Aa8Nw2J9s4HzBZuXjeeaf3P/JofEstiD/NlCZFnQ5Au0bP8MMb/u2kX93KVLuGI6H3aBNApmIcrExSTz8j2AXgCqQGPCmSSvSgNQwObE95E2BJJ9t8C2KlZmn210eYuy5xEMxnWNLHyXxG74RtaF7CtmZY0HwWfuRjV1oUkIYzIlIKRzjHsy8AVS8X6zfdX8bxPy/SGDMSYAhDVaFBTdqlmKOFO98A3KR46uzptbDUV0CUw0I5vH7EaQYztBRl7+PpvKthr7IKo2btYXIvSHgaOVyZS3wQdg==
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 ee1bde45-b8a9-4e6f-5535-08d84452eb59
X-MS-Exchange-CrossTenant-AuthSource: DM5PR12MB1307.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Aug 2020 15:17:00.1251
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 2ZQenWGgSMu6y87EliofdQlPCledpGkF+Ubfj8qHvdngbGuaogYd0ZLbylvXgY//IM6+eLupMnOZ/OnprKhyUw==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM6PR12MB3227
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Add 2 small infrastructure functions here which to enable pinning the SEV
guest pages used for sev_launch_update_data() using sev_get_page().

Pin the memory for the data being passed to launch_update_data() because it
gets encrypted before the guest is first run and must not be moved which
would corrupt it.

Co-developed-by: Brijesh Singh <brijesh.singh@amd.com>
Signed-off-by: eric van tassell <Eric.VanTassell@amd.com>
---
 arch/x86/kvm/svm/sev.c | 57 ++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 57 insertions(+)

diff --git a/arch/x86/kvm/svm/sev.c b/arch/x86/kvm/svm/sev.c
index 8d56d1afb33e..4a0157254fef 100644
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@ -454,6 +454,37 @@ static int sev_get_page(struct kvm *kvm, gfn_t gfn, kvm_pfn_t pfn)
 	return 0;
 }
 
+static struct kvm_memory_slot *hva_to_memslot(struct kvm *kvm,
+					      unsigned long hva)
+{
+	struct kvm_memslots *slots = kvm_memslots(kvm);
+	struct kvm_memory_slot *memslot;
+
+	kvm_for_each_memslot(memslot, slots) {
+		if (hva >= memslot->userspace_addr &&
+		    hva < memslot->userspace_addr +
+			      (memslot->npages << PAGE_SHIFT))
+			return memslot;
+	}
+
+	return NULL;
+}
+
+static bool hva_to_gfn(struct kvm *kvm, unsigned long hva, gfn_t *gfn)
+{
+	struct kvm_memory_slot *memslot;
+	gpa_t gpa_offset;
+
+	memslot = hva_to_memslot(kvm, hva);
+	if (!memslot)
+		return false;
+
+	gpa_offset = hva - memslot->userspace_addr;
+	*gfn = ((memslot->base_gfn << PAGE_SHIFT) + gpa_offset) >> PAGE_SHIFT;
+
+	return true;
+}
+
 static int sev_launch_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
 {
 	unsigned long vaddr, vaddr_end, next_vaddr, npages, pages, size, i;
@@ -462,6 +493,7 @@ static int sev_launch_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
 	struct sev_data_launch_update_data *data;
 	struct page **inpages;
 	int ret;
+	int srcu_idx;
 
 	if (!sev_guest(kvm))
 		return -ENOTTY;
@@ -484,6 +516,31 @@ static int sev_launch_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
 		goto e_free;
 	}
 
+	/*
+	 * Increment the page ref count so that the pages do not get migrated or
+	 * moved after we are done from the LAUNCH_UPDATE_DATA.
+	 */
+
+	/* ensure hva_to_gfn translations remain valid */
+	srcu_idx = srcu_read_lock(&kvm->srcu);
+
+	for (i = 0; i < npages; i++) {
+		gfn_t gfn;
+
+		if (!hva_to_gfn(kvm, (vaddr + (i * PAGE_SIZE)) & PAGE_MASK, &gfn)) {
+			ret = -EFAULT;
+			break;
+		}
+
+		ret = sev_get_page(kvm, gfn, page_to_pfn(inpages[i]));
+		if (ret)
+			break;
+	}
+
+	srcu_read_unlock(&kvm->srcu, srcu_idx);
+	if (ret)
+		goto e_unpin;
+
 	/*
 	 * The LAUNCH_UPDATE command will perform in-place encryption of the
 	 * memory content (i.e it will write the same memory region with C=1).

From patchwork Wed Aug 19 15:17:42 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: eric van tassell <Eric.VanTassell@amd.com>
X-Patchwork-Id: 11724415
Return-Path: <SRS0=Yqqy=B5=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id E3B5815E4
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:18:56 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id C2A0A207FF
	for <patchwork-kvm@patchwork.kernel.org>;
 Wed, 19 Aug 2020 15:18:56 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=amdcloud.onmicrosoft.com
 header.i=@amdcloud.onmicrosoft.com header.b="hKpJhA2c"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726689AbgHSPSv (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Wed, 19 Aug 2020 11:18:51 -0400
Received: from mail-bn7nam10on2070.outbound.protection.outlook.com
 ([40.107.92.70]:43520
        "EHLO NAM10-BN7-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726899AbgHSPSG (ORCPT <rfc822;kvm@vger.kernel.org>);
        Wed, 19 Aug 2020 11:18:06 -0400
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=c98hZ5t/E0/7Ty2ow6uPCljrFqsD1iDN+MzkAQ+/FsqND+MZIdvuOeZA60G8eNSaBB1qRnIPbooZ1I7PawvASpI2AgUJ7HSDNe/47gJ2u7TIyxa1jw/JxEFY7rSz6A8c00kmP4q+b6MeyYvd0tojvAgUADDrN4tD8yyS21nmhqDB637zdOkxterwLJAltGMg+UkIcx7gFUw9lawIPW93xkhLFfZsShKnPWSpmd0ru7lqFxpj943H25+oVqCHpxDXgt31Dc6O14dyBbe6JUlZRib6O9tdMS3PITEIyKwn3UAl26m01RneU+2PTZ4stXvzrZqFzHt8EkJLaMni4JVXLA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Rru6mtAXlN5E8gXsyipj4kkroTm6SYVGUkafE46L2y8=;
 b=WW+jQrhZjwkG2nHIeAWZrQ344bsIWZnuYQWScic4jIrdt6Uu2EEeSBELqtR6ovBDOzZFuc1Tqz1K5131OPpsP8WKvr0LHwghxc84R3oBR27n3Wh6gFRL630EY/5zEO+722AvkXXLK45LUPeDB62C37IWFbITZrWFeF4tc/pknSj96EjEZaBnHAR4Jtnfly+OtjZ5GTm+3Phc/OQqtsfEj9TngguOmL+4Vh02A5E2ekpYjjMd7PySZemfTBXLgBtj50poVg9Fwvd1tOrk6Hf2Gi+2/pSTcv4xc1b9/aEUx3kNQ/Xkxi/vFKzdm3kR9RCVxiS/1vgoANzgKm/h004mLQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Rru6mtAXlN5E8gXsyipj4kkroTm6SYVGUkafE46L2y8=;
 b=hKpJhA2cVT80aZLe/JPxY6n+LS1wmAiR2ebsL+afhTkgDwLpY4Ts72g4vmJ3eeYePI/Z+yhOMCrGC/7sFtpcE4bV/xKRfHyFi67p3DZPbvvRM9khaSYe5d61kmlDTLesPQNxF2UyUi32RONydyadxJPaBKNsWJX6BZ0fP9rHdDU=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from DM5PR12MB1307.namprd12.prod.outlook.com (2603:10b6:3:79::21) by
 DM6PR12MB3227.namprd12.prod.outlook.com (2603:10b6:5:18d::14) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.3305.24; Wed, 19 Aug 2020 15:17:01 +0000
Received: from DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162]) by DM5PR12MB1307.namprd12.prod.outlook.com
 ([fe80::15d7:c2da:d92a:2162%11]) with mapi id 15.20.3283.028; Wed, 19 Aug
 2020 15:17:01 +0000
From: eric van tassell <Eric.VanTassell@amd.com>
To: kvm@vger.kernel.org
Cc: linux-kernel@vger.kernel.org, bp@alien8.de, hpa@zytor.com,
        mingo@redhat.com, jmattson@google.com, joro@8bytes.org,
        pbonzini@redhat.com, sean.j.christopherson@intel.com,
        tglx@linutronix.de, vkuznets@redhat.com, wanpengli@tencent.com,
        x86@kernel.org, rientjes@google.com, junaids@google.com,
        evantass@amd.com
Subject: [Patch v2 4/4] KVM:SVM: Remove struct enc_region and associated
 pinned page tracking.
Date: Wed, 19 Aug 2020 10:17:42 -0500
Message-Id: <20200819151742.7892-5-Eric.VanTassell@amd.com>
X-Mailer: git-send-email 2.17.1
In-Reply-To: <20200819151742.7892-1-Eric.VanTassell@amd.com>
References: <20200819151742.7892-1-Eric.VanTassell@amd.com>
X-ClientProxiedBy: DM5PR19CA0045.namprd19.prod.outlook.com
 (2603:10b6:3:9a::31) To DM5PR12MB1307.namprd12.prod.outlook.com
 (2603:10b6:3:79::21)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from evt-speedway-83bc.amd.com (165.204.78.2) by
 DM5PR19CA0045.namprd19.prod.outlook.com (2603:10b6:3:9a::31) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3305.24 via Frontend
 Transport; Wed, 19 Aug 2020 15:17:00 +0000
X-Mailer: git-send-email 2.17.1
X-Originating-IP: [165.204.78.2]
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: 0fa65ef9-2ee5-4f31-08d4-08d84452ec36
X-MS-TrafficTypeDiagnostic: DM6PR12MB3227:
X-MS-Exchange-Transport-Forked: True
X-Microsoft-Antispam-PRVS: 
 <DM6PR12MB3227D3A455C3C2420847BDFBE75D0@DM6PR12MB3227.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:1775;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 Po+u5wpRRRHZQv4NTKs/khatu4hjcRFF683QnsERsGBw5XX+2+aeT69ooqRsuiC/Nkmvsu6J2JMI6WgJRv66eGwhx2CVbQNVBfkGWSus3r6QFDOPjCjSpbH2g7QI/YPhyJkIUALrR3ejRefaz1Z4POpJg4XgpJWxDvd1c88fY/kXjIMpWfozdc6sRChMssR7e7Fu5zjoXdK4MRXf6oTpwG8kOmK0bR7evlhjxxUbafwvh4VR6JB8nBuTJh4WRhG17CFM+qGNaalIiXtNht3WucK/rGrJFsn6VlopcGWhd/HssCm0dDfDBS0V3GOpvhhxF8saA8j46oYfbjXdoyXOiA==
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:DM5PR12MB1307.namprd12.prod.outlook.com;PTR:;CAT:NONE;SFS:(4636009)(346002)(376002)(136003)(396003)(366004)(39860400002)(66556008)(66476007)(8676002)(66946007)(26005)(86362001)(1076003)(5660300002)(478600001)(6486002)(36756003)(316002)(83380400001)(6666004)(7416002)(2906002)(8936002)(6916009)(4326008)(2616005)(7696005)(16526019)(52116002)(186003)(956004);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData: 
 sCaN32J7itaeTySZkdVZXuD/v82Uq2nlIRuwQu6kvELKAr5xGmshp4JjxZOonuWhpr3oSK6mIDOgavZ52fO7KvSVbPQ1LKr8+1U4IHmkmnjT8OELTlyuMYoPfExhQIh+UZFpRq7V2u58JjU3g5izlBr4pkMDY24bf2/lPAvc41+F4dVGng0eXY4WfML7HyE+hEHI01q76PD+NpTsdADQsyG8Vt+KL2Vk/Ch5y2NGvT7NieXGJFRQ1UtUKYPnnOOlWPz09PrBFRvSA0Bimo3d6vr4qbppRayFUenGSuRl4LxtqnwKKvjFHuikDQ9WsnA7PTrag3nx/x1a6Q9dMVjPEKJwaRXfkOOvW6vc+YhXQuvnG3Sr1yyXSy38H6fNGzJzzEfHYaxGLONP2iCNnKRzeNWHekV43tO0w3udjAE5efwDIWlm2N65XZF8wki0IWZw3Kqt7zgAd8Hxc8duOwYQs5zm8KSsCuTswmfLqNIn0RxLN/rAcoLha+gRS5c9ldLV81qkYpUjV5jy8A7hp2tb5ePiIOZMJeCYTRsD5BeoUPn7C8JXjuaBVDgBYs/LTBkawLVjHiYIx73nL95Mwq9SDXqgn/8U5nFCZsl8ojj9z99/ZiY6Zf74Pi6nHKIL/wi9D0jSTSTAR78Wlb+/WhEYoA==
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 0fa65ef9-2ee5-4f31-08d4-08d84452ec36
X-MS-Exchange-CrossTenant-AuthSource: DM5PR12MB1307.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 19 Aug 2020 15:17:01.7774
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 a7oGajuq7FdJ1aAGUMZuN6NwZ1+orhESBNSJPNTZrxognrLyzriRGD8i7mGQ4/Vxf5IX+zrE4PLQD4zoYvEqPQ==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM6PR12MB3227
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Remove the enc_region structure definition and the code which maintained
it, as they are no longer needed in view of the xarray support we added in
the previous patch.

Leave svm_register_enc_region() and svm_unregister_enc_region() as stubs
since the ioctl is used by qemu and qemu will crash if they do not
return 0.

Co-developed-by: Brijesh Singh <brijesh.singh@amd.com>
Signed-off-by: eric van tassell <Eric.VanTassell@amd.com>
---
 arch/x86/kvm/svm/sev.c | 117 +----------------------------------------
 arch/x86/kvm/svm/svm.h |   1 -
 2 files changed, 1 insertion(+), 117 deletions(-)

diff --git a/arch/x86/kvm/svm/sev.c b/arch/x86/kvm/svm/sev.c
index 4a0157254fef..635e15f01edb 100644
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@ -27,14 +27,6 @@ static unsigned long *sev_asid_bitmap;
 static unsigned long *sev_reclaim_asid_bitmap;
 #define __sme_page_pa(x) __sme_set(page_to_pfn(x) << PAGE_SHIFT)
 
-struct enc_region {
-	struct list_head list;
-	unsigned long npages;
-	struct page **pages;
-	unsigned long uaddr;
-	unsigned long size;
-};
-
 static int sev_flush_asids(void)
 {
 	int ret, error = 0;
@@ -182,7 +174,6 @@ static int sev_guest_init(struct kvm *kvm, struct kvm_sev_cmd *argp)
 
 	sev->active = true;
 	sev->asid = asid;
-	INIT_LIST_HEAD(&sev->regions_list);
 
 	xa_init(&sev->pages_xarray);
 
@@ -1074,113 +1065,18 @@ int svm_mem_enc_op(struct kvm *kvm, void __user *argp)
 int svm_register_enc_region(struct kvm *kvm,
 			    struct kvm_enc_region *range)
 {
-	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
-	struct enc_region *region;
-	int ret = 0;
-
-	if (!sev_guest(kvm))
-		return -ENOTTY;
-
-	if (range->addr > ULONG_MAX || range->size > ULONG_MAX)
-		return -EINVAL;
-
-	region = kzalloc(sizeof(*region), GFP_KERNEL_ACCOUNT);
-	if (!region)
-		return -ENOMEM;
-
-	region->pages = sev_pin_memory(kvm, range->addr, range->size, &region->npages, 1);
-	if (IS_ERR(region->pages)) {
-		ret = PTR_ERR(region->pages);
-		goto e_free;
-	}
-
-	/*
-	 * The guest may change the memory encryption attribute from C=0 -> C=1
-	 * or vice versa for this memory range. Lets make sure caches are
-	 * flushed to ensure that guest data gets written into memory with
-	 * correct C-bit.
-	 */
-	sev_clflush_pages(region->pages, region->npages);
-
-	region->uaddr = range->addr;
-	region->size = range->size;
-
-	mutex_lock(&kvm->lock);
-	list_add_tail(&region->list, &sev->regions_list);
-	mutex_unlock(&kvm->lock);
-
-	return ret;
-
-e_free:
-	kfree(region);
-	return ret;
-}
-
-static struct enc_region *
-find_enc_region(struct kvm *kvm, struct kvm_enc_region *range)
-{
-	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
-	struct list_head *head = &sev->regions_list;
-	struct enc_region *i;
-
-	list_for_each_entry(i, head, list) {
-		if (i->uaddr == range->addr &&
-		    i->size == range->size)
-			return i;
-	}
-
-	return NULL;
-}
-
-static void __unregister_enc_region_locked(struct kvm *kvm,
-					   struct enc_region *region)
-{
-	sev_unpin_memory(kvm, region->pages, region->npages);
-	list_del(&region->list);
-	kfree(region);
+	return 0;
 }
 
 int svm_unregister_enc_region(struct kvm *kvm,
 			      struct kvm_enc_region *range)
 {
-	struct enc_region *region;
-	int ret;
-
-	mutex_lock(&kvm->lock);
-
-	if (!sev_guest(kvm)) {
-		ret = -ENOTTY;
-		goto failed;
-	}
-
-	region = find_enc_region(kvm, range);
-	if (!region) {
-		ret = -EINVAL;
-		goto failed;
-	}
-
-	/*
-	 * Ensure that all guest tagged cache entries are flushed before
-	 * releasing the pages back to the system for use. CLFLUSH will
-	 * not do this, so issue a WBINVD.
-	 */
-	wbinvd_on_all_cpus();
-
-	__unregister_enc_region_locked(kvm, region);
-
-	mutex_unlock(&kvm->lock);
 	return 0;
-
-failed:
-	mutex_unlock(&kvm->lock);
-	return ret;
 }
 
 void sev_vm_destroy(struct kvm *kvm)
 {
 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
-	struct list_head *head = &sev->regions_list;
-	struct list_head *pos, *q;
 	XA_STATE(xas, &sev->pages_xarray, 0);
 	struct page *xa_page;
 
@@ -1196,17 +1092,6 @@ void sev_vm_destroy(struct kvm *kvm)
 	 */
 	wbinvd_on_all_cpus();
 
-	/*
-	 * if userspace was terminated before unregistering the memory regions
-	 * then lets unpin all the registered memory.
-	 */
-	if (!list_empty(head)) {
-		list_for_each_safe(pos, q, head) {
-			__unregister_enc_region_locked(kvm,
-				list_entry(pos, struct enc_region, list));
-		}
-	}
-
 	/* Release each pinned page that SEV tracked in sev->pages_xarray. */
 	xas_for_each(&xas, xa_page, ULONG_MAX) {
 		put_page(xa_page);
diff --git a/arch/x86/kvm/svm/svm.h b/arch/x86/kvm/svm/svm.h
index 278c46bc52aa..98d3d7b299cb 100644
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@ -64,7 +64,6 @@ struct kvm_sev_info {
 	unsigned int handle;	/* SEV firmware handle */
 	int fd;			/* SEV device fd */
 	unsigned long pages_locked; /* Number of pages locked */
-	struct list_head regions_list;  /* List of registered regions */
 	struct xarray pages_xarray; /* List of PFN locked */
 };
 
