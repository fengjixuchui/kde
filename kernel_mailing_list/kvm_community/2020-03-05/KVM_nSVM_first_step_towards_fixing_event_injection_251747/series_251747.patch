From patchwork Thu Mar  5 10:13:44 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Paolo Bonzini <pbonzini@redhat.com>
X-Patchwork-Id: 11421495
Return-Path: <SRS0=eotC=4W=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id BE57C138D
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:01 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 9BE7F21556
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:01 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=fail reason="signature verification failed" (2048-bit key)
 header.d=gmail.com header.i=@gmail.com header.b="k7VCsKw3"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727070AbgCEKNz (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 5 Mar 2020 05:13:55 -0500
Received: from mail-wr1-f68.google.com ([209.85.221.68]:45595 "EHLO
        mail-wr1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725816AbgCEKNy (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 5 Mar 2020 05:13:54 -0500
Received: by mail-wr1-f68.google.com with SMTP id v2so6233311wrp.12;
        Thu, 05 Mar 2020 02:13:52 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=N8hO5OsCpxWuOROH3axUS5MYcS8LdG5MKkBcvb8lPiI=;
        b=k7VCsKw36KHwV++K8F4b0/Ji76zJCnV+jm7l6g7L9fch4EzkCd0ZmEZKIxW/5LxowI
         r9TYDLVpBcHcNM3xoHfCHMWaAB1ylrVOZ4wrrtLToqQYWDVzubYWqM14kePDG4F/j9sy
         LJgA0n5tLzcvKZGNtTpnmw4F6bEyMaqus/IpJh6lNVyQHgSDKZj1NyG2uHhXlprIOzgB
         TY61lVEP6KoT7oKBgbq6qbIM8fLGZSAwQ2Z56BrWAY1vEav4BiBzmMEXkZ0MbWSV0w7Z
         ei+Y0KwbJ/jAuB2XwzDzHkrdo8S8JK7Dawv1uca/0m87PZgx1xls6hq+2h726WB47mun
         Py/Q==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
         :in-reply-to:references;
        bh=N8hO5OsCpxWuOROH3axUS5MYcS8LdG5MKkBcvb8lPiI=;
        b=qfcW6+kDj/w9cWSCn0DVrvsOOuyzYxISFlYCZUliCftkFKVEDEdFgAHTdRkvadxgOP
         Q2frFncXUWJHaTtUrOEKcfYsHPssa4iwYzt/DmV6X9/vJJcYoxY1eb9ihy6Ao/S3gqyu
         18Y2sCpv6H/f2bGLfJVqkxLgCIsarXXLZBVvU1fQ3rMT0+h90qzN4ilBvIPoYlPuMU6k
         uB5odjVYHafES/8fLhSjMTzizVtnTz8eTDRpX77ZMaujoiAoHKuFRzPirGACzCIG8Lsj
         4kJ+5LE2fhr8NwHffNSSlsWwfsXHVabuUiPX6XqhiLfSiuGWWljwIQ6FbkIVypEc+Gig
         kIYw==
X-Gm-Message-State: ANhLgQ1H9mZJcFs8fAQ4sXC+/reTouRVDM0ZoufgPLVxHzJMGNIKeDhe
        kIb0wQ3N7wF01NbOT5/cDfRuqlrp
X-Google-Smtp-Source: 
 ADFU+vu1GR7uwsHOWLQOZhzN5rk63Bcdi98Dk/283VeBS36I6xrBrZLZ4VLn8guP/UUC8RmFGJ94zA==
X-Received: by 2002:adf:a50b:: with SMTP id i11mr10151797wrb.60.1583403231224;
        Thu, 05 Mar 2020 02:13:51 -0800 (PST)
Received: from 640k.localdomain.com ([93.56.166.5])
        by smtp.gmail.com with ESMTPSA id
 p15sm8331066wma.40.2020.03.05.02.13.50
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 05 Mar 2020 02:13:50 -0800 (PST)
From: Paolo Bonzini <pbonzini@redhat.com>
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: cavery@redhat.com, vkuznets@redhat.com, jan.kiszka@siemens.com,
        wei.huang2@amd.com
Subject: [PATCH 1/4] KVM: nSVM: do not change host intercepts while nested VM
 is running
Date: Thu,  5 Mar 2020 11:13:44 +0100
Message-Id: <1583403227-11432-2-git-send-email-pbonzini@redhat.com>
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
References: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Instead of touching the host intercepts so that the bitwise OR in
recalc_intercepts just works, mask away uninteresting intercepts
directly in recalc_intercepts.

This is cleaner and keeps the logic in one place even for intercepts
that can change even while L2 is running.

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---
 arch/x86/kvm/svm.c | 31 ++++++++++++++++++-------------
 1 file changed, 18 insertions(+), 13 deletions(-)

diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index 247e31d21b96..14cb5c194008 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -519,10 +519,24 @@ static void recalc_intercepts(struct vcpu_svm *svm)
 	h = &svm->nested.hsave->control;
 	g = &svm->nested;
 
-	c->intercept_cr = h->intercept_cr | g->intercept_cr;
-	c->intercept_dr = h->intercept_dr | g->intercept_dr;
-	c->intercept_exceptions = h->intercept_exceptions | g->intercept_exceptions;
-	c->intercept = h->intercept | g->intercept;
+	c->intercept_cr = h->intercept_cr;
+	c->intercept_dr = h->intercept_dr;
+	c->intercept_exceptions = h->intercept_exceptions;
+	c->intercept = h->intercept;
+
+	if (svm->vcpu.arch.hflags & HF_VINTR_MASK) {
+		/* We only want the cr8 intercept bits of L1 */
+		c->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);
+		c->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);
+	}
+
+	/* We don't want to see VMMCALLs from a nested guest */
+	c->intercept &= ~(1ULL << INTERCEPT_VMMCALL);
+
+	c->intercept_cr |= g->intercept_cr;
+	c->intercept_dr |= g->intercept_dr;
+	c->intercept_exceptions |= g->intercept_exceptions;
+	c->intercept |= g->intercept;
 }
 
 static inline struct vmcb *get_host_vmcb(struct vcpu_svm *svm)
@@ -3590,15 +3604,6 @@ static void enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,
 	else
 		svm->vcpu.arch.hflags &= ~HF_VINTR_MASK;
 
-	if (svm->vcpu.arch.hflags & HF_VINTR_MASK) {
-		/* We only want the cr8 intercept bits of the guest */
-		clr_cr_intercept(svm, INTERCEPT_CR8_READ);
-		clr_cr_intercept(svm, INTERCEPT_CR8_WRITE);
-	}
-
-	/* We don't want to see VMMCALLs from a nested guest */
-	clr_intercept(svm, INTERCEPT_VMMCALL);
-
 	svm->vcpu.arch.tsc_offset += nested_vmcb->control.tsc_offset;
 	svm->vmcb->control.tsc_offset = svm->vcpu.arch.tsc_offset;
 

From patchwork Thu Mar  5 10:13:45 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Paolo Bonzini <pbonzini@redhat.com>
X-Patchwork-Id: 11421499
Return-Path: <SRS0=eotC=4W=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 0B43B92A
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:09 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id DFFA12146E
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:08 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=fail reason="signature verification failed" (2048-bit key)
 header.d=gmail.com header.i=@gmail.com header.b="TMjNNRPk"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727186AbgCEKOC (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 5 Mar 2020 05:14:02 -0500
Received: from mail-wr1-f66.google.com ([209.85.221.66]:36972 "EHLO
        mail-wr1-f66.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727002AbgCEKNz (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 5 Mar 2020 05:13:55 -0500
Received: by mail-wr1-f66.google.com with SMTP id 6so823402wre.4;
        Thu, 05 Mar 2020 02:13:53 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=Mf4pftpvyE6QdpnD7ythbs31rkJp2p0e3/GL3dyXTKY=;
        b=TMjNNRPkuZqL1OUT6F3LQqioqjXpbLmmSD9PM6lTfVCJi/S29CNaQY7PjskmJta6/r
         FVUN1JuszSkUelJbwCeaA8v9mYxolCX1ORkg5jwLyVFo9b2IHGRYodB9V+eZOXJXDbaL
         ahgg0LUPx+k79nWEIysdzjsUF/tjRogeYCA32QH7y5/03bAHMufMVV3qgReKjsv5BZqI
         CWAVu0plJphfIg9aYGhHxurPS7IFxf8a/Ur6zP/2Pgu7VDYeG8dGsrnYMcWC8yKC98E2
         konL7JwnxAnMi6nB1NvVBBP63lq5snkBocyg9rmZ8N4IzebqroJ8GHvMvzL2313/VXqt
         cD9w==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
         :in-reply-to:references;
        bh=Mf4pftpvyE6QdpnD7ythbs31rkJp2p0e3/GL3dyXTKY=;
        b=gpk2Rx94bPNR9yza3uL6IIK+Wp+7QEs8FbPhNhbtzzH5fN8Z+JV08JkjDdkIkT9nWR
         rZyPkVSWGQeppnAQQMqQyk+tjj3nW1jDfFncBICYNHFBzzwZRbrM7HQdTG9JJIbqYZDh
         HEAwcctX1KGBTU56LVBaR8uPwu5+y1xidWLd5m+YbaFnIZWhgT3tuTHTcPoPZQGiqjCv
         hWxgFokwKkYDOAmBKJ4VQHtp5uR8G5pk3HF4Wi+NfMUG5O+vYpXRiDzhJZzeo01DdKeO
         kO+ml2oLY2dUNAfZEI7rIqp5f8oLI17Qb5dD8rwhwqv7NwQiykhnw4ou2RftZGhShF4o
         m0DA==
X-Gm-Message-State: ANhLgQ3AoGO0bcEN/NUSQkmAo88RlWzxrZDCXwq4EJGJ2/EPes/Hi+4N
        ASeSwIrbCJuvNZzGxLWkJ8BRo6y2
X-Google-Smtp-Source: 
 ADFU+vtBxUZ2RbZNU0ecQ0/Lseev5+Lmswm5zJoQ6lkgU/Q5UOzqOI0ZNkDysB8Qjn7mUEi/njloZg==
X-Received: by 2002:a5d:5041:: with SMTP id h1mr9668627wrt.143.1583403232210;
        Thu, 05 Mar 2020 02:13:52 -0800 (PST)
Received: from 640k.localdomain.com ([93.56.166.5])
        by smtp.gmail.com with ESMTPSA id
 p15sm8331066wma.40.2020.03.05.02.13.51
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 05 Mar 2020 02:13:51 -0800 (PST)
From: Paolo Bonzini <pbonzini@redhat.com>
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: cavery@redhat.com, vkuznets@redhat.com, jan.kiszka@siemens.com,
        wei.huang2@amd.com
Subject: [PATCH 2/4] KVM: nSVM: ignore L1 interrupt window while running L2
 with V_INTR_MASKING=1
Date: Thu,  5 Mar 2020 11:13:45 +0100
Message-Id: <1583403227-11432-3-git-send-email-pbonzini@redhat.com>
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
References: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

If a nested VM is started while an IRQ was pending and with
V_INTR_MASKING=1, the behavior of the guest depends on host IF.  If it
is 1, the VM should exit immediately, before executing the first
instruction of the guest, because VMRUN sets GIF back to 1.

If it is 0 and the host has VGIF, however, at the time of the VMRUN
instruction L0 is running the guest with a pending interrupt window
request.  This interrupt window request is completely irrelevant to
L2, since IF only controls virtual interrupts, so this patch drops
INTERCEPT_VINTR from the VMCB while running L2 under these circumstances.
To simplify the code, both steps of enabling the interrupt window
(setting the VINTR intercept and requesting a fake virtual interrupt
in svm_inject_irq) are grouped in the svm_set_vintr function, and
likewise for dismissing the interrupt window request in svm_clear_vintr.

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---
 arch/x86/kvm/svm.c | 55 ++++++++++++++++++++++++++++++++++++------------------
 1 file changed, 37 insertions(+), 18 deletions(-)

diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index 14cb5c194008..25827b79cf96 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -528,6 +528,13 @@ static void recalc_intercepts(struct vcpu_svm *svm)
 		/* We only want the cr8 intercept bits of L1 */
 		c->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);
 		c->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);
+
+		/*
+		 * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not
+		 * affect any interrupt we may want to inject; therefore,
+		 * interrupt window vmexits are irrelevant to L0.
+		 */
+		c->intercept &= ~(1ULL << INTERCEPT_VINTR);
 	}
 
 	/* We don't want to see VMMCALLs from a nested guest */
@@ -641,6 +648,11 @@ static inline void clr_intercept(struct vcpu_svm *svm, int bit)
 	recalc_intercepts(svm);
 }
 
+static inline bool is_intercept(struct vcpu_svm *svm, int bit)
+{
+	return (svm->vmcb->control.intercept & (1ULL << bit)) != 0;
+}
+
 static inline bool vgif_enabled(struct vcpu_svm *svm)
 {
 	return !!(svm->vmcb->control.int_ctl & V_GIF_ENABLE_MASK);
@@ -2438,14 +2450,38 @@ static void svm_cache_reg(struct kvm_vcpu *vcpu, enum kvm_reg reg)
 	}
 }
 
+static inline void svm_enable_vintr(struct vcpu_svm *svm)
+{
+	struct vmcb_control_area *control;
+
+	/* The following fields are ignored when AVIC is enabled */
+	WARN_ON(kvm_vcpu_apicv_active(&svm->vcpu));
+
+	/*
+	 * This is just a dummy VINTR to actually cause a vmexit to happen.
+	 * Actual injection of virtual interrupts happens through EVENTINJ.
+	 */
+	control = &svm->vmcb->control;
+	control->int_vector = 0x0;
+	control->int_ctl &= ~V_INTR_PRIO_MASK;
+	control->int_ctl |= V_IRQ_MASK |
+		((/*control->int_vector >> 4*/ 0xf) << V_INTR_PRIO_SHIFT);
+	mark_dirty(svm->vmcb, VMCB_INTR);
+}
+
 static void svm_set_vintr(struct vcpu_svm *svm)
 {
 	set_intercept(svm, INTERCEPT_VINTR);
+	if (is_intercept(svm, INTERCEPT_VINTR))
+		svm_enable_vintr(svm);
 }
 
 static void svm_clear_vintr(struct vcpu_svm *svm)
 {
 	clr_intercept(svm, INTERCEPT_VINTR);
+
+	svm->vmcb->control.int_ctl &= ~V_IRQ_MASK;
+	mark_dirty(svm->vmcb, VMCB_INTR);
 }
 
 static struct vmcb_seg *svm_seg(struct kvm_vcpu *vcpu, int seg)
@@ -3833,11 +3869,8 @@ static int clgi_interception(struct vcpu_svm *svm)
 	disable_gif(svm);
 
 	/* After a CLGI no interrupts should come */
-	if (!kvm_vcpu_apicv_active(&svm->vcpu)) {
+	if (!kvm_vcpu_apicv_active(&svm->vcpu))
 		svm_clear_vintr(svm);
-		svm->vmcb->control.int_ctl &= ~V_IRQ_MASK;
-		mark_dirty(svm->vmcb, VMCB_INTR);
-	}
 
 	return ret;
 }
@@ -5123,19 +5156,6 @@ static void svm_inject_nmi(struct kvm_vcpu *vcpu)
 	++vcpu->stat.nmi_injections;
 }
 
-static inline void svm_inject_irq(struct vcpu_svm *svm, int irq)
-{
-	struct vmcb_control_area *control;
-
-	/* The following fields are ignored when AVIC is enabled */
-	control = &svm->vmcb->control;
-	control->int_vector = irq;
-	control->int_ctl &= ~V_INTR_PRIO_MASK;
-	control->int_ctl |= V_IRQ_MASK |
-		((/*control->int_vector >> 4*/ 0xf) << V_INTR_PRIO_SHIFT);
-	mark_dirty(svm->vmcb, VMCB_INTR);
-}
-
 static void svm_set_irq(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
@@ -5559,7 +5579,6 @@ static void enable_irq_window(struct kvm_vcpu *vcpu)
 		 */
 		svm_toggle_avic_for_irq_window(vcpu, false);
 		svm_set_vintr(svm);
-		svm_inject_irq(svm, 0x0);
 	}
 }
 

From patchwork Thu Mar  5 10:13:46 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Paolo Bonzini <pbonzini@redhat.com>
X-Patchwork-Id: 11421497
Return-Path: <SRS0=eotC=4W=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 36592138D
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:08 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 0EAA321556
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:14:08 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=fail reason="signature verification failed" (2048-bit key)
 header.d=gmail.com header.i=@gmail.com header.b="VLqnB4nk"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727196AbgCEKOC (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 5 Mar 2020 05:14:02 -0500
Received: from mail-wr1-f66.google.com ([209.85.221.66]:40013 "EHLO
        mail-wr1-f66.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725937AbgCEKNz (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 5 Mar 2020 05:13:55 -0500
Received: by mail-wr1-f66.google.com with SMTP id r17so6252252wrj.7;
        Thu, 05 Mar 2020 02:13:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=+xwiBse4pt803geshkaqIXQfeBC3a/woHHPXS73g1eU=;
        b=VLqnB4nk88ex/qSKxOlbqQDpn9SK79T8EeMOmTOAIHiNWtuNHzoDFTUSfKgTv1cSxM
         9s+UNG6EUf7SGkvNruSZVZX2Et95Uu527qR6zQ67s+nkIWU6vcpo2tUV+74Dw7kAJIUz
         hj6KBM0ulmhTuF4H5GvXcmtwZuzUFWmL1XoPiO1jZaR/LNY5aMsVZrCKRBLe0Oltt/JP
         lIOX2Mh+rFGVtQeEdNCQUyc2Hxcw8NWiFuuwk26x67I1AElNcxdNI9bsIMAn2qRissYR
         4zbpBy07hY9gXBx5bYXN3p50pqTSuvxUZ1hqNkSv+IKGpw1Wstp8kcM9+GdP8gL/7h2n
         Pyqg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
         :in-reply-to:references;
        bh=+xwiBse4pt803geshkaqIXQfeBC3a/woHHPXS73g1eU=;
        b=txtYuoLdq2sSxmBEGFzvz2oex6eYC6V7mjLbp3rNRrpAWlpOjkZHt+d2N6c90BaxPh
         1+ZzHO+s/SMjtC6Nr/OJDRoiRVWjd0Uf6hODNGCdp6KU8B9Z/PA1Z5klqxgKTBw3pD9D
         WJrP7gCxYxJfY6on8n1m9D5FfSOkC9FH6FFiX5dBhAepHmveLoyO+zOEcOLaBcAqw71T
         gMwD3To1Jheu7VAkQ9Dy2jA3MFdO93rFkVIcbCmduA8awvsbVadIn/JcKQUhjISBiaD2
         Mkx+3C2ZpfFk5eLhTn6WRAEX5TcSW+/noJCdK0s5KDt1uo98uhqiZeAP53cYMRApmXB4
         uwpA==
X-Gm-Message-State: ANhLgQ39F+05yp7WPSWKXU1xUXNVTE+frrSpARLH6oJZ5aOAuPKz46Rz
        O3swg2RxM9y6++7kqDqsnV44Wz6u
X-Google-Smtp-Source: 
 ADFU+vsPhWayDDOue3Jq3I6tyJGpRlf2qH1ww5lksQll8aEO2W8Q812D1c9EDi+tZ49GFkp3XY+q2w==
X-Received: by 2002:adf:de85:: with SMTP id w5mr8852269wrl.323.1583403233213;
        Thu, 05 Mar 2020 02:13:53 -0800 (PST)
Received: from 640k.localdomain.com ([93.56.166.5])
        by smtp.gmail.com with ESMTPSA id
 p15sm8331066wma.40.2020.03.05.02.13.52
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 05 Mar 2020 02:13:52 -0800 (PST)
From: Paolo Bonzini <pbonzini@redhat.com>
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: cavery@redhat.com, vkuznets@redhat.com, jan.kiszka@siemens.com,
        wei.huang2@amd.com
Subject: [PATCH 3/4] KVM: nSVM: implement check_nested_events for interrupts
Date: Thu,  5 Mar 2020 11:13:46 +0100
Message-Id: <1583403227-11432-4-git-send-email-pbonzini@redhat.com>
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
References: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

The current implementation of physical interrupt delivery to a nested guest
is quite broken.  It relies on svm_interrupt_allowed returning false if
VINTR=1 so that the interrupt can be injected from enable_irq_window,
but this does not work for guests that do not intercept HLT or that rely
on clearing the host IF to block physical interrupts while L2 runs.

This patch can be split in two logical parts, but including only
one breaks tests so I am combining both changes together.

The first and easiest is simply to return true for svm_interrupt_allowed
if HF_VINTR_MASK is set and HIF is set.  This way the semantics of
svm_interrupt_allowed are respected: svm_interrupt_allowed being false
does not mean "call enable_irq_window", it means "interrupts cannot
be injected now".

After doing this, however, we need another place to inject the
interrupt, and fortunately we already have one, check_nested_events,
which nested SVM does not implement but which is meant exactly for this
purpose.  It is called before interrupts are injected, and it can
therefore do the L2->L1 switch while leaving inject_pending_event
none the wiser.

This patch was developed together with Cathy Avery, who wrote the
test and did a lot of the initial debugging.

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---
 arch/x86/kvm/svm.c | 68 ++++++++++++++++++++++++------------------------------
 1 file changed, 30 insertions(+), 38 deletions(-)

diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index 25827b79cf96..0d773406f7ac 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -3133,43 +3133,36 @@ static int nested_svm_check_exception(struct vcpu_svm *svm, unsigned nr,
 	return vmexit;
 }
 
-/* This function returns true if it is save to enable the irq window */
-static inline bool nested_svm_intr(struct vcpu_svm *svm)
+static void nested_svm_intr(struct vcpu_svm *svm)
 {
-	if (!is_guest_mode(&svm->vcpu))
-		return true;
-
-	if (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))
-		return true;
-
-	if (!(svm->vcpu.arch.hflags & HF_HIF_MASK))
-		return false;
-
-	/*
-	 * if vmexit was already requested (by intercepted exception
-	 * for instance) do not overwrite it with "external interrupt"
-	 * vmexit.
-	 */
-	if (svm->nested.exit_required)
-		return false;
-
 	svm->vmcb->control.exit_code   = SVM_EXIT_INTR;
 	svm->vmcb->control.exit_info_1 = 0;
 	svm->vmcb->control.exit_info_2 = 0;
 
-	if (svm->nested.intercept & 1ULL) {
-		/*
-		 * The #vmexit can't be emulated here directly because this
-		 * code path runs with irqs and preemption disabled. A
-		 * #vmexit emulation might sleep. Only signal request for
-		 * the #vmexit here.
-		 */
-		svm->nested.exit_required = true;
-		trace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);
-		return false;
+	/* nested_svm_vmexit this gets called afterwards from handle_exit */
+	svm->nested.exit_required = true;
+	trace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);
+}
+
+static bool nested_exit_on_intr(struct vcpu_svm *svm)
+{
+	return (svm->nested.intercept & 1ULL);
+}
+
+static int svm_check_nested_events(struct kvm_vcpu *vcpu)
+{
+	struct vcpu_svm *svm = to_svm(vcpu);
+	bool block_nested_events =
+		kvm_event_needs_reinjection(vcpu) || svm->nested.exit_required;
+
+	if (kvm_cpu_has_interrupt(vcpu) && nested_exit_on_intr(svm)) {
+		if (block_nested_events)
+			return -EBUSY;
+		nested_svm_intr(svm);
+		return 0;
 	}
 
-	return true;
+	return 0;
 }
 
 /* This function returns true if it is save to enable the nmi window */
@@ -5544,18 +5537,15 @@ static int svm_interrupt_allowed(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
 	struct vmcb *vmcb = svm->vmcb;
-	int ret;
 
 	if (!gif_set(svm) ||
 	     (vmcb->control.int_state & SVM_INTERRUPT_SHADOW_MASK))
 		return 0;
 
-	ret = !!(kvm_get_rflags(vcpu) & X86_EFLAGS_IF);
-
-	if (is_guest_mode(vcpu))
-		return ret && !(svm->vcpu.arch.hflags & HF_VINTR_MASK);
-
-	return ret;
+	if (is_guest_mode(vcpu) && (svm->vcpu.arch.hflags & HF_VINTR_MASK))
+		return !!(svm->vcpu.arch.hflags & HF_HIF_MASK);
+	else
+		return !!(kvm_get_rflags(vcpu) & X86_EFLAGS_IF);
 }
 
 static void enable_irq_window(struct kvm_vcpu *vcpu)
@@ -5570,7 +5560,7 @@ static void enable_irq_window(struct kvm_vcpu *vcpu)
 	 * enabled, the STGI interception will not occur. Enable the irq
 	 * window under the assumption that the hardware will set the GIF.
 	 */
-	if ((vgif_enabled(svm) || gif_set(svm)) && nested_svm_intr(svm)) {
+	if (vgif_enabled(svm) || gif_set(svm)) {
 		/*
 		 * IRQ window is not needed when AVIC is enabled,
 		 * unless we have pending ExtINT since it cannot be injected
@@ -7465,6 +7455,8 @@ static void svm_pre_update_apicv_exec_ctrl(struct kvm *kvm, bool activate)
 	.need_emulation_on_page_fault = svm_need_emulation_on_page_fault,
 
 	.apic_init_signal_blocked = svm_apic_init_signal_blocked,
+
+	.check_nested_events = svm_check_nested_events,
 };
 
 static int __init svm_init(void)

From patchwork Thu Mar  5 10:13:47 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Paolo Bonzini <pbonzini@redhat.com>
X-Patchwork-Id: 11421493
Return-Path: <SRS0=eotC=4W=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 9F2EA92A
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:13:59 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 7FA612146E
	for <patchwork-kvm@patchwork.kernel.org>;
 Thu,  5 Mar 2020 10:13:59 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=fail reason="signature verification failed" (2048-bit key)
 header.d=gmail.com header.i=@gmail.com header.b="OafLWsUn"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727130AbgCEKN4 (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Thu, 5 Mar 2020 05:13:56 -0500
Received: from mail-wr1-f68.google.com ([209.85.221.68]:42477 "EHLO
        mail-wr1-f68.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727067AbgCEKN4 (ORCPT <rfc822;kvm@vger.kernel.org>);
        Thu, 5 Mar 2020 05:13:56 -0500
Received: by mail-wr1-f68.google.com with SMTP id v11so4294300wrm.9;
        Thu, 05 Mar 2020 02:13:55 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=sender:from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=4cPtlreV3CL6qZiIeDzuws4IJav/mV5BaDJqKCbYawY=;
        b=OafLWsUnM/1kmPD7KtLMTHejoDLDAvnms9/3ZbzBlWKee3Zicmg1F73LefZ7elPMlq
         Z8x04BrZcjpbZz9DUK/q9OgvNsLvhCsFRCzzWQEw9bc2rDXXchnxYwrOFzYtWm4HZ4uo
         C+MGtkCjmRUTxzwFfqA3Ta5mq6zV23DX3faEbbdKBXJpdf3Gwq585c9w/HEWAgDXA7oO
         5D1N0DkvMZdIcXi9RyFqHJLgQVxBOWGq/ImVGaMmmH5p6bWdK0JNJCWP2dVG0sWBAkYx
         79r8lbDslttu4ojkE5tYJMzi2b1Za7eV6JH3xWavBpn1w7c8nAEbc9aDUwLl8Pw7Ra1l
         PRlA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:sender:from:to:cc:subject:date:message-id
         :in-reply-to:references;
        bh=4cPtlreV3CL6qZiIeDzuws4IJav/mV5BaDJqKCbYawY=;
        b=R4GBxXIYMis/1XdAgK4ylSxwrwA4TwQssHUPDos5+es4XH9KkBnanxGh9hlv+BkWvj
         CCakUhuZO720mhUxDflTnYtdnco1RgGx+ZY5kPmTtP8ojua4/vaL9cbdGrzNguZlt9Bd
         M9jT/iP+Hjg5RFm5vqaQeuT5iKOKUqlWXcquux5FEb2UveCycyjpFQ2dojRb69MIFSHe
         mdqX4hXKErvDXbjrkRC5f+bFKsRqa9+7vJL0SP0f+ilR/Yq/4+tDf/SPyrm+VgL/ERBj
         gSYgZM/mQxd6vcCX55lntbu4f4fjEFOAy1cpnh/M6wd8JX/JnnsUODX8MQUanmpi39VR
         5PSg==
X-Gm-Message-State: ANhLgQ0rFYT0GxKymdpP3LI+ucHcBFzANyephwaZENjFJeQdJQrNBrRM
        a5Lw/gKXD1uS7zvcjNlETIrQ+BfC
X-Google-Smtp-Source: 
 ADFU+vtBqAdjgrLdjZSQ1LmtNj/Y8C3TvswtEHlbg8pHuojHh8FqT20A+MXnh+tXxQKDYNku+ouoRQ==
X-Received: by 2002:adf:fcc2:: with SMTP id f2mr9342392wrs.199.1583403234220;
        Thu, 05 Mar 2020 02:13:54 -0800 (PST)
Received: from 640k.localdomain.com ([93.56.166.5])
        by smtp.gmail.com with ESMTPSA id
 p15sm8331066wma.40.2020.03.05.02.13.53
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 05 Mar 2020 02:13:53 -0800 (PST)
From: Paolo Bonzini <pbonzini@redhat.com>
To: linux-kernel@vger.kernel.org, kvm@vger.kernel.org
Cc: cavery@redhat.com, vkuznets@redhat.com, jan.kiszka@siemens.com,
        wei.huang2@amd.com
Subject: [PATCH 4/4] KVM: nSVM: avoid loss of pending IRQ/NMI before entering
 L2
Date: Thu,  5 Mar 2020 11:13:47 +0100
Message-Id: <1583403227-11432-5-git-send-email-pbonzini@redhat.com>
X-Mailer: git-send-email 1.8.3.1
In-Reply-To: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
References: <1583403227-11432-1-git-send-email-pbonzini@redhat.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

This patch reproduces for nSVM the change that was made for nVMX in
commit b5861e5cf2fc ("KVM: nVMX: Fix loss of pending IRQ/NMI before
entering L2").  While I do not have a test that breaks without it, I
cannot see why it would not be necessary since all events are unblocked
by VMRUN's setting of GIF back to 1.

Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
---
 arch/x86/kvm/svm.c | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index 0d773406f7ac..3df62257889a 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -3574,6 +3574,10 @@ static bool nested_vmcb_checks(struct vmcb *vmcb)
 static void enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,
 				 struct vmcb *nested_vmcb, struct kvm_host_map *map)
 {
+	bool evaluate_pending_interrupts =
+		is_intercept(svm, INTERCEPT_VINTR) ||
+		is_intercept(svm, INTERCEPT_IRET);
+
 	if (kvm_get_rflags(&svm->vcpu) & X86_EFLAGS_IF)
 		svm->vcpu.arch.hflags |= HF_HIF_MASK;
 	else
@@ -3660,7 +3664,21 @@ static void enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,
 
 	svm->nested.vmcb = vmcb_gpa;
 
+	/*
+	 * If L1 had a pending IRQ/NMI before executing VMRUN,
+	 * which wasn't delivered because it was disallowed (e.g.
+	 * interrupts disabled), L0 needs to evaluate if this pending
+	 * event should cause an exit from L2 to L1 or be delivered
+	 * directly to L2.
+	 *
+	 * Usually this would be handled by the processor noticing an
+	 * IRQ/NMI window request.  However, VMRUN can unblock interrupts
+	 * by implicitly setting GIF, so force L0 to perform pending event
+	 * evaluation by requesting a KVM_REQ_EVENT.
+	 */
 	enable_gif(svm);
+	if (unlikely(evaluate_pending_interrupts))
+		kvm_make_request(KVM_REQ_EVENT, &svm->vcpu);
 
 	mark_all_dirty(svm->vmcb);
 }
