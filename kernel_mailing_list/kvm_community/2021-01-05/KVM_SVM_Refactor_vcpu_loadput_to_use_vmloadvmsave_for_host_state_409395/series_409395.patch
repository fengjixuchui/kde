From patchwork Tue Jan  5 14:37:48 2021
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Michael Roth <michael.roth@amd.com>
X-Patchwork-Id: 11999161
Return-Path: <kvm-owner@kernel.org>
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	aws-us-west-2-korg-lkml-1.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-16.8 required=3.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,HEADER_FROM_DIFFERENT_DOMAINS,INCLUDES_CR_TRAILER,INCLUDES_PATCH,
	MAILING_LIST_MULTI,MSGID_FROM_MTA_HEADER,SPF_HELO_NONE,SPF_PASS,
	USER_AGENT_GIT autolearn=unavailable autolearn_force=no version=3.4.0
Received: from mail.kernel.org (mail.kernel.org [198.145.29.99])
	by smtp.lore.kernel.org (Postfix) with ESMTP id 26F48C433E9
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:39:58 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id DCC7022BED
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:39:57 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727559AbhAEOjn (ORCPT <rfc822;kvm@archiver.kernel.org>);
        Tue, 5 Jan 2021 09:39:43 -0500
Received: from mail-bn8nam11hn2203.outbound.protection.outlook.com
 ([52.100.171.203]:62816
        "EHLO NAM11-BN8-obe.outbound.protection.outlook.com"
        rhost-flags-OK-FAIL-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726352AbhAEOjl (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Jan 2021 09:39:41 -0500
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=ABzoZnkbzlXcT4n4ucU2KP5/p8S2o501uOiozV/w6BJwyXea+NrHBuyjiMo7BYBvtN5j3u2J1vTErjXfnIsWH0OBlEzbUCSPKOWqacTPa/WX4HjbLXEkekGhnZcRYYx4WtKoNVpbMOAcxA2wU+Y+D69UCDp2VVLoZwwyphCjrbDzUxMgkCjZxZQlASdKxJ9NTbXS9Veawny0ZoYGDB1wpNEWKyWl0U2hjaIEJ1bVjRD7Y0MxP8PJA02sf4xClYw9oIQwbLQo1H8WUVwsvBB7lmAKFDSL+/FtBSCRwMIAA12tIXpFMN8m+IOaxjyCCr2OD4NK7LUk5PAjULQ97gyhjQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=ASThIUSUvobyLczmMW3lew/MzA6MTfONcQv8fMoHdRA=;
 b=XtC5cpfqa1O+kO4viffEMWwn6r+x7apPUiW1Y2j+RlfO++8df9nmnA3yuv64t+kJjaHoAiNtscyuyMC6xSI498RqNBKdXiyDXhb6PUs7o8cLYnyhhPdn5IggHtwqIHkcTx9rdMy8nsLJ+DJEagdbMatzqo5JZs/6ZI3/FiK5MQA8nOTVemDGTWoKn7jqm3BFiIELnlNfTp/KNHpBQmvDSrRk74jFypMRM1dhx8s+V9mkFiIG8B360LRUNCUNPHOX94kcb1wrpLkDo2htEguX2Rfzt3X7yCotwSIm1vATRWOSQaf0rYI4A+XzUmJLxl69vvLvWXdrcTAIu9iipPCQdQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=ASThIUSUvobyLczmMW3lew/MzA6MTfONcQv8fMoHdRA=;
 b=Z0E3dX9XswRuhVRpKB9VXsWQR0ugEwWdDZ6NScxoYNwiEWtTQkMLqZcobzHJhK+kYlB84aGsQqXBA2iLcB97jGKsQFzS4WF0U74LIt/mZ+wz9oYhZ3kxULCJpV+YIG+GnppMBmv347rLC04/l+LjrrFQadwBTdwsM/AjzEDuC+o=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from CH2PR12MB4133.namprd12.prod.outlook.com (2603:10b6:610:7a::13)
 by CH2PR12MB4134.namprd12.prod.outlook.com (2603:10b6:610:a7::15) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3721.19; Tue, 5 Jan
 2021 14:38:52 +0000
Received: from CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e]) by CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e%7]) with mapi id 15.20.3721.024; Tue, 5 Jan 2021
 14:38:52 +0000
From: Michael Roth <michael.roth@amd.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <seanjc@google.com>,
        Andy Lutomirski <luto@amacapital.net>,
        Vitaly Kuznetsov <vkuznets@redhat.com>,
        Wanpeng Li <wanpengli@tencent.com>,
        Jim Mattson <jmattson@google.com>,
        Joerg Roedel <joro@8bytes.org>,
        Thomas Gleixner <tglx@linutronix.de>,
        Ingo Molnar <mingo@redhat.com>, Borislav Petkov <bp@alien8.de>,
        x86@kernel.org, "H . Peter Anvin" <hpa@zytor.com>,
        linux-kernel@vger.kernel.org,
        Tom Lendacky <thomas.lendacky@amd.com>
Subject: [PATCH v3 1/3] KVM: SVM: use vmsave/vmload for saving/restoring
 additional host state
Date: Tue,  5 Jan 2021 08:37:48 -0600
Message-Id: <20210105143749.557054-2-michael.roth@amd.com>
X-Mailer: git-send-email 2.25.1
In-Reply-To: <20210105143749.557054-1-michael.roth@amd.com>
References: <20210105143749.557054-1-michael.roth@amd.com>
X-Originating-IP: [165.204.54.211]
X-ClientProxiedBy: YT1PR01CA0077.CANPRD01.PROD.OUTLOOK.COM
 (2603:10b6:b01:2d::16) To CH2PR12MB4133.namprd12.prod.outlook.com
 (2603:10b6:610:7a::13)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from localhost (165.204.54.211) by
 YT1PR01CA0077.CANPRD01.PROD.OUTLOOK.COM (2603:10b6:b01:2d::16) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3742.6 via Frontend
 Transport; Tue, 5 Jan 2021 14:38:51 +0000
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: b5b973be-a9a8-417b-2849-08d8b1879f58
X-MS-TrafficTypeDiagnostic: CH2PR12MB4134:
X-MS-Exchange-Transport-Forked: True
X-Microsoft-Antispam-PRVS: 
 <CH2PR12MB413444E136437AC679D946BA95D10@CH2PR12MB4134.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:10000;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 Z4F0wG4GjTmZX2A84dkPJS6qH94KOLLA3ZXZV7ncj77XDhFeJHjr/0H2pppQf9xStNKOG+0CYO5+24SiOalcBniuw6w3Ncg6+BxiJwgpzVg0+yuxlkw2E6pUajMXvsH+CEWqvGfbam1oYRZdGUwUO7OyfnqAflTaNSNTdaOErXr3bWvLmcGcWwqmbG2ZL/zmNXkjpqpEslHdXk50W+jlCf4lnAzyK9wGgGFnUiTwj58Fr2vpSvW3OXssqLgkcwL8xEL2Jj2Cw2Jp0RCf/KpKLP3lUWPc0OnyjLjU69ogKnOUEp0ephLwkQme9VWcyYxPrc9GkwFxNPdB4/Q1LZNq20O5eMqx5MHX5Fe2UqQJ696AA4egJGnBlljlwX1IaP/VxrK2uC6Vhg/8CDrm0DSkX9Qf8C++RvSs8wuKR7bhF2XJrPuWbuaNHVSYYqDVaO832sSGKXK60lGqwFxl16jcvydmg8ODt315uFoL23Ao++Qu7fJDgBCBP2EEivnAdJvCL6noI9wwM9XD1i6rT0coAUwASlGbS1+nhHcWH9tmulysjY6L9NVS/RaQcVkZwSatLwyTzfIWuesF7dseuHC9jmQdfrIcb/oWGn9htnR9Xz9bixSP9+y+skG0OEYAIxQ1krHgAJ6Fkyt7CGVA/DbZ0Zmm417kT7GITUVFPrLUJ+WM6ND6l0DgOsMZ2slESL9aBg8OCgO4nPB6fw4HsD2shLKAukLUeKeZgc05aIrc9HkX5GksxgEaNTNxryjmRm1B
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:5;SRV:;IPV:NLI;SFV:SPM;H:CH2PR12MB4133.namprd12.prod.outlook.com;PTR:;CAT:OSPM;SFS:(4636009)(376002)(346002)(136003)(396003)(366004)(39860400002)(6496006)(52116002)(16526019)(956004)(2616005)(66946007)(54906003)(186003)(6916009)(2906002)(6486002)(26005)(86362001)(8936002)(1076003)(44832011)(4326008)(5660300002)(7416002)(83380400001)(478600001)(66556008)(316002)(6666004)(8676002)(66476007)(36756003)(23200700001);DIR:OUT;SFP:1501;
X-MS-Exchange-AntiSpam-MessageData: 
 NapcsAcj0ohY60L4g30hwf5YlJ0UzKvThiBmgEMTEPFlkrsR4JOy2DuxNeosKbJ4QTSbY1pwb5FdV8XUy9LB9/gcyiot5WzpIRWQGuQdsNSa7pzk0KDyKT2Sd5I+KIPrtkpAtnodlTZ/EmS9rvgO0G3KLPQjTKJFK+wTRk9Ro3FGc9a5/tD6g3Ji/Tl8QK63XTpcVO0ahNtD88/OPjpiSkwf638RAg1WRJh0XgwRQdHML8AGhkthhS6CMdY0D/1NBy2hX39F4342CCsQAOSfAg2YyeBMMaNAhCLHadd+iZfRFP4zlaN/3mHWZboRAQeVLfJXxVSeF8s1RzG55YqBwPvCZussRSUtn8B6jt/F+4PALC5dsEqHhJlz3H901DCwnNRWPXe5v29/3MSh9TRrYiUdfKdZo8yGCEOAjMqbcFJlHGe2SZNvRATjNAI+xNj5t3MXDEybzCR+rf+07QJLjm3nqzD6X7L2gC7iuTCNSVX39y854kcO+gOFAfWOZQqhhvkz6XcgVPCpAL9ztjh4AG+UQ+8PIshZ8uBhFtjtGWfal4PkWWu4RT6YiT9dnbVKz2Cxgy+6RLU0JKhxXYIn9CiWyEQ9QanB3PGUldFzdwn4bqfmHhFfjD+HLpq+vZ0exNxOJ9MYwHqP3aQzINX8GiLBJ/u6j+JsJTlf89hOm9Wn+NnduRdqlK2seG1JbCJkMpmPpfv0OvVDiy5k7kwlOrobHD6vtN1mZ9qLe1ezGrUw3LlziA1jAGUTkh5OrzoNiJi2bGNowgcZO072ONTvqY7P7I0Fv+ZtAJrGpgB0m7jSdWeUB5MjVNRmQd2RV18rbQzMARZAyWh7Phgy0+PZbY7pBrBbGbxqtNFgpGIUeVM7BCM90WcCv+hKR7/V3XZW00ARao4WxafF9gzHwBzSw9rAfNRvMJscOKULIhy3cBS4JOw0+NP2K3cJ/CyglY3gGBmU/YWNY9UOb7yxtx3zstfYWskIWjDUA1doSk2VZQy/+mo1aNn8mxSe03+Cvs1l
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-AuthSource: CH2PR12MB4133.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 05 Jan 2021 14:38:52.3677
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 b5b973be-a9a8-417b-2849-08d8b1879f58
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 QhbTViAdXONf6m2FfWfSGr7Ca/GuCaW8oeWVKAp3TbTfFwf++qGLkhjCGuI3W+J/C7VklBRZ7sq1TNMXFUXFDw==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CH2PR12MB4134
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Using a guest workload which simply issues 'hlt' in a tight loop to
generate VMEXITs, it was observed (on a recent EPYC processor) that a
significant amount of the VMEXIT overhead measured on the host was the
result of MSR reads/writes in svm_vcpu_load/svm_vcpu_put according to
perf:

  67.49%--kvm_arch_vcpu_ioctl_run
          |
          |--23.13%--vcpu_put
          |          kvm_arch_vcpu_put
          |          |
          |          |--21.31%--native_write_msr
          |          |
          |           --1.27%--svm_set_cr4
          |
          |--16.11%--vcpu_load
          |          |
          |           --15.58%--kvm_arch_vcpu_load
          |                     |
          |                     |--13.97%--svm_set_cr4
          |                     |          |
          |                     |          |--12.64%--native_read_msr

Most of these MSRs relate to 'syscall'/'sysenter' and segment bases, and
can be saved/restored using 'vmsave'/'vmload' instructions rather than
explicit MSR reads/writes. In doing so there is a significant reduction
in the svm_vcpu_load/svm_vcpu_put overhead measured for the above
workload:

  50.92%--kvm_arch_vcpu_ioctl_run
          |
          |--19.28%--disable_nmi_singlestep
          |
          |--13.68%--vcpu_load
          |          kvm_arch_vcpu_load
          |          |
          |          |--9.19%--svm_set_cr4
          |          |          |
          |          |           --6.44%--native_read_msr
          |          |
          |           --3.55%--native_write_msr
          |
          |--6.05%--kvm_inject_nmi
          |--2.80%--kvm_sev_es_mmio_read
          |--2.19%--vcpu_put
          |          |
          |           --1.25%--kvm_arch_vcpu_put
          |                     native_write_msr

Quantifying this further, if we look at the raw cycle counts for a
normal iteration of the above workload (according to 'rdtscp'),
kvm_arch_vcpu_ioctl_run() takes ~4600 cycles from start to finish with
the current behavior. Using 'vmsave'/'vmload', this is reduced to
~2800 cycles, a savings of 39%.

While this approach doesn't seem to manifest in any noticeable
improvement for more realistic workloads like UnixBench, netperf, and
kernel builds, likely due to their exit paths generally involving IO
with comparatively high latencies, it does improve overall overhead
of KVM_RUN significantly, which may still be noticeable for certain
situations. It also simplifies some aspects of the code.

With this change, explicit save/restore is no longer needed for the
following host MSRs, since they are documented[1] as being part of the
VMCB State Save Area:

  MSR_STAR, MSR_LSTAR, MSR_CSTAR,
  MSR_SYSCALL_MASK, MSR_KERNEL_GS_BASE,
  MSR_IA32_SYSENTER_CS,
  MSR_IA32_SYSENTER_ESP,
  MSR_IA32_SYSENTER_EIP,
  MSR_FS_BASE, MSR_GS_BASE

and only the following MSR needs individual handling in
svm_vcpu_put/svm_vcpu_load:

  MSR_TSC_AUX

We could drop the host_save_user_msrs array/loop and instead handle
MSR read/write of MSR_TSC_AUX directly, but we leave that for now as
a potential follow-up.

Since 'vmsave'/'vmload' also handles the LDTR and FS/GS segment
registers (and associated hidden state)[2], some of the code
previously used to handle this is no longer needed, so we drop it
as well.

The first public release of the SVM spec[3] also documents the same
handling for the host state in question, so we make these changes
unconditionally.

Also worth noting is that we 'vmsave' to the same page that is
subsequently used by 'vmrun' to record some host additional state. This
is okay, since, in accordance with the spec[2], the additional state
written to the page by 'vmrun' does not overwrite any fields written by
'vmsave'. This has also been confirmed through testing (for the above
CPU, at least).

[1] AMD64 Architecture Programmer's Manual, Rev 3.33, Volume 2, Appendix B, Table B-2
[2] AMD64 Architecture Programmer's Manual, Rev 3.31, Volume 3, Chapter 4, VMSAVE/VMLOAD
[3] Secure Virtual Machine Architecture Reference Manual, Rev 3.01

Suggested-by: Tom Lendacky <thomas.lendacky@amd.com>
Signed-off-by: Michael Roth <michael.roth@amd.com>
---
 arch/x86/kvm/svm/svm.c     | 36 +++++++-----------------------------
 arch/x86/kvm/svm/svm.h     | 19 +------------------
 arch/x86/kvm/svm/vmenter.S | 10 ++++++++++
 3 files changed, 18 insertions(+), 47 deletions(-)

diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 941e5251e13f..7a7e9b7d47a7 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1420,16 +1420,12 @@ static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 	if (sev_es_guest(svm->vcpu.kvm)) {
 		sev_es_vcpu_load(svm, cpu);
 	} else {
-#ifdef CONFIG_X86_64
-		rdmsrl(MSR_GS_BASE, to_svm(vcpu)->host.gs_base);
-#endif
-		savesegment(fs, svm->host.fs);
-		savesegment(gs, svm->host.gs);
-		svm->host.ldt = kvm_read_ldt();
-
 		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
 			rdmsrl(host_save_user_msrs[i].index,
 			       svm->host_user_msrs[i]);
+
+		asm volatile(__ex("vmsave %%"_ASM_AX)
+			     : : "a" (page_to_phys(sd->save_area)) : "memory");
 	}
 
 	if (static_cpu_has(X86_FEATURE_TSCRATEMSR)) {
@@ -1461,17 +1457,6 @@ static void svm_vcpu_put(struct kvm_vcpu *vcpu)
 	if (sev_es_guest(svm->vcpu.kvm)) {
 		sev_es_vcpu_put(svm);
 	} else {
-		kvm_load_ldt(svm->host.ldt);
-#ifdef CONFIG_X86_64
-		loadsegment(fs, svm->host.fs);
-		wrmsrl(MSR_KERNEL_GS_BASE, current->thread.gsbase);
-		load_gs_index(svm->host.gs);
-#else
-#ifdef CONFIG_X86_32_LAZY_GS
-		loadsegment(gs, svm->host.gs);
-#endif
-#endif
-
 		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
 			wrmsrl(host_save_user_msrs[i].index,
 			       svm->host_user_msrs[i]);
@@ -3675,7 +3660,7 @@ static fastpath_t svm_exit_handlers_fastpath(struct kvm_vcpu *vcpu)
 	return EXIT_FASTPATH_NONE;
 }
 
-void __svm_vcpu_run(unsigned long vmcb_pa, unsigned long *regs);
+void __svm_vcpu_run(unsigned long vmcb_pa, unsigned long *regs, unsigned long hostsa_pa);
 
 static noinstr void svm_vcpu_enter_exit(struct kvm_vcpu *vcpu,
 					struct vcpu_svm *svm)
@@ -3703,16 +3688,9 @@ static noinstr void svm_vcpu_enter_exit(struct kvm_vcpu *vcpu,
 	if (sev_es_guest(svm->vcpu.kvm)) {
 		__svm_sev_es_vcpu_run(svm->vmcb_pa);
 	} else {
-		__svm_vcpu_run(svm->vmcb_pa, (unsigned long *)&svm->vcpu.arch.regs);
-
-#ifdef CONFIG_X86_64
-		native_wrmsrl(MSR_GS_BASE, svm->host.gs_base);
-#else
-		loadsegment(fs, svm->host.fs);
-#ifndef CONFIG_X86_32_LAZY_GS
-		loadsegment(gs, svm->host.gs);
-#endif
-#endif
+		__svm_vcpu_run(svm->vmcb_pa, (unsigned long *)&svm->vcpu.arch.regs,
+			       page_to_phys(per_cpu(svm_data,
+						    vcpu->cpu)->save_area));
 	}
 
 	/*
diff --git a/arch/x86/kvm/svm/svm.h b/arch/x86/kvm/svm/svm.h
index 5431e6335e2e..1f4460508036 100644
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@ -27,17 +27,6 @@ static const struct svm_host_save_msrs {
 	u32 index;		/* Index of the MSR */
 	bool sev_es_restored;	/* True if MSR is restored on SEV-ES VMEXIT */
 } host_save_user_msrs[] = {
-#ifdef CONFIG_X86_64
-	{ .index = MSR_STAR,			.sev_es_restored = true },
-	{ .index = MSR_LSTAR,			.sev_es_restored = true },
-	{ .index = MSR_CSTAR,			.sev_es_restored = true },
-	{ .index = MSR_SYSCALL_MASK,		.sev_es_restored = true },
-	{ .index = MSR_KERNEL_GS_BASE,		.sev_es_restored = true },
-	{ .index = MSR_FS_BASE,			.sev_es_restored = true },
-#endif
-	{ .index = MSR_IA32_SYSENTER_CS,	.sev_es_restored = true },
-	{ .index = MSR_IA32_SYSENTER_ESP,	.sev_es_restored = true },
-	{ .index = MSR_IA32_SYSENTER_EIP,	.sev_es_restored = true },
 	{ .index = MSR_TSC_AUX,			.sev_es_restored = false },
 };
 #define NR_HOST_SAVE_USER_MSRS ARRAY_SIZE(host_save_user_msrs)
@@ -130,12 +119,6 @@ struct vcpu_svm {
 	u64 next_rip;
 
 	u64 host_user_msrs[NR_HOST_SAVE_USER_MSRS];
-	struct {
-		u16 fs;
-		u16 gs;
-		u16 ldt;
-		u64 gs_base;
-	} host;
 
 	u64 spec_ctrl;
 	/*
@@ -595,6 +578,6 @@ void sev_es_vcpu_put(struct vcpu_svm *svm);
 /* vmenter.S */
 
 void __svm_sev_es_vcpu_run(unsigned long vmcb_pa);
-void __svm_vcpu_run(unsigned long vmcb_pa, unsigned long *regs);
+void __svm_vcpu_run(unsigned long vmcb_pa, unsigned long *regs, unsigned long hostsa_pa);
 
 #endif
diff --git a/arch/x86/kvm/svm/vmenter.S b/arch/x86/kvm/svm/vmenter.S
index 6feb8c08f45a..89f4e8e7bf0e 100644
--- a/arch/x86/kvm/svm/vmenter.S
+++ b/arch/x86/kvm/svm/vmenter.S
@@ -33,6 +33,7 @@
  * __svm_vcpu_run - Run a vCPU via a transition to SVM guest mode
  * @vmcb_pa:	unsigned long
  * @regs:	unsigned long * (to guest registers)
+ * @hostsa_pa:	unsigned long
  */
 SYM_FUNC_START(__svm_vcpu_run)
 	push %_ASM_BP
@@ -47,6 +48,9 @@ SYM_FUNC_START(__svm_vcpu_run)
 #endif
 	push %_ASM_BX
 
+	/* Save @hostsa_pa */
+	push %_ASM_ARG3
+
 	/* Save @regs. */
 	push %_ASM_ARG2
 
@@ -154,6 +158,12 @@ SYM_FUNC_START(__svm_vcpu_run)
 	xor %r15d, %r15d
 #endif
 
+	/* "POP" @hostsa_pa to RAX. */
+	pop %_ASM_AX
+
+	/* Restore host user state and FS/GS base */
+	vmload %_ASM_AX
+
 	pop %_ASM_BX
 
 #ifdef CONFIG_X86_64

From patchwork Tue Jan  5 14:37:49 2021
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Michael Roth <michael.roth@amd.com>
X-Patchwork-Id: 11999167
Return-Path: <kvm-owner@kernel.org>
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	aws-us-west-2-korg-lkml-1.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-16.8 required=3.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,HEADER_FROM_DIFFERENT_DOMAINS,INCLUDES_CR_TRAILER,INCLUDES_PATCH,
	MAILING_LIST_MULTI,MSGID_FROM_MTA_HEADER,SPF_HELO_NONE,SPF_PASS,
	USER_AGENT_GIT autolearn=unavailable autolearn_force=no version=3.4.0
Received: from mail.kernel.org (mail.kernel.org [198.145.29.99])
	by smtp.lore.kernel.org (Postfix) with ESMTP id 7DE30C433E6
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:40:30 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id 4D18C22B4B
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:40:30 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727851AbhAEOkQ (ORCPT <rfc822;kvm@archiver.kernel.org>);
        Tue, 5 Jan 2021 09:40:16 -0500
Received: from mail-dm6nam12hn2247.outbound.protection.outlook.com
 ([52.100.166.247]:56129
        "EHLO NAM12-DM6-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726846AbhAEOkP (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Jan 2021 09:40:15 -0500
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=UgSbLeZ1DhfyNTKPtZZ5yvFxXiT/qrx1qT9qtdY2DpCyxPc6aKQxIWeraVwSOrNxNnAV8OKSDxM/Wq/3+7Yzhr/4df5ZYhKMQ6W4J2M8du+bxudQODNjNnWEwOrzoGzzGR202dCi24s7b1E2mG/4yiNNmWiS5Y4Wu71WIUes7MozBVaVyylDPVbwwlQiiPLCd1uSTmTe+Z5fWGUgZK5414khDb+5o1I6A3Y9Iu2vDOs8iE5aKsS55Ggxd0OC4QwkDeUaBEjScRxo0lCKI664SYZtzZgTqGbCnu8oFJD1TiYib6HKOCbGZPgRIjQ3Wz34qski1jIwkgh7YSqR5aUTfA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=jY0o6/URRyZq57WzkAJw7mo2KVO0Y5KD5J4LxUciOjE=;
 b=IPMod21Igtm4s2QZdx0EOEU2Htd2GlUekze1HSC5YLl9Wnbl83vRA7qKRyv/iQmIrr+DjO4uoLouYIcVFnyQLkAq+S3+LTC4C5u+ObT5/0l/5hjirxNzJ77yIq+v9OgpvhKzCf1wmZkbVzRjMtSodnFyQGQ+aoG4K+eVuodpzh9FwOv94TOCFqFdL/ZUEfyJDWRwl+Of53hu0ezadEgJz9FprxTVouvyRr2rB+ueZ2OFBZG5GH3HZD2F+IeJIM1YM7BG4A1iQOqrCIIKgS5vAhxsAFDqrWe6KT1yfELCPzUlSWgspkQbj/jbQkWs8tAb08eZpa45TqOOfudfpv51wg==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=jY0o6/URRyZq57WzkAJw7mo2KVO0Y5KD5J4LxUciOjE=;
 b=ayCHO7lWyw7Rwo6vH+WkVqmmTeoKU21N/vxiqYnGq1uBFvvP19TRNM6NrC/by9aTqJwfCeDxrdWzg9PDpxikXWs3jTkRjSDQAf85Gk3ue5wDpGOVC5V8mFASPNy/jAnU0csx6SCKHRWJ7WQT++0NV6YweNxHZbLYGt81N6KKHjE=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from CH2PR12MB4133.namprd12.prod.outlook.com (2603:10b6:610:7a::13)
 by CH2PR12MB4134.namprd12.prod.outlook.com (2603:10b6:610:a7::15) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3721.19; Tue, 5 Jan
 2021 14:38:55 +0000
Received: from CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e]) by CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e%7]) with mapi id 15.20.3721.024; Tue, 5 Jan 2021
 14:38:55 +0000
From: Michael Roth <michael.roth@amd.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <seanjc@google.com>,
        Andy Lutomirski <luto@amacapital.net>,
        Vitaly Kuznetsov <vkuznets@redhat.com>,
        Wanpeng Li <wanpengli@tencent.com>,
        Jim Mattson <jmattson@google.com>,
        Joerg Roedel <joro@8bytes.org>,
        Thomas Gleixner <tglx@linutronix.de>,
        Ingo Molnar <mingo@redhat.com>, Borislav Petkov <bp@alien8.de>,
        x86@kernel.org, "H . Peter Anvin" <hpa@zytor.com>,
        linux-kernel@vger.kernel.org
Subject: [PATCH v3 2/3] KVM: SVM: remove uneeded fields from
 host_save_users_msrs
Date: Tue,  5 Jan 2021 08:37:49 -0600
Message-Id: <20210105143749.557054-3-michael.roth@amd.com>
X-Mailer: git-send-email 2.25.1
In-Reply-To: <20210105143749.557054-1-michael.roth@amd.com>
References: <20210105143749.557054-1-michael.roth@amd.com>
X-Originating-IP: [165.204.54.211]
X-ClientProxiedBy: YT1PR01CA0073.CANPRD01.PROD.OUTLOOK.COM
 (2603:10b6:b01:2d::12) To CH2PR12MB4133.namprd12.prod.outlook.com
 (2603:10b6:610:7a::13)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from localhost (165.204.54.211) by
 YT1PR01CA0073.CANPRD01.PROD.OUTLOOK.COM (2603:10b6:b01:2d::12) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3721.19 via Frontend
 Transport; Tue, 5 Jan 2021 14:38:55 +0000
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: 669309ad-fde9-4fcd-f9ba-08d8b187a13f
X-MS-TrafficTypeDiagnostic: CH2PR12MB4134:
X-Microsoft-Antispam-PRVS: 
 <CH2PR12MB413418DC1641C40D212A423495D10@CH2PR12MB4134.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:6430;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 FNltrtZVTcORKpaI7nr1sbkZJVu37cuVKBHjH5OEwHpw3hEyXB4GIBatMeSPz+aTsobWiGLyWJHI9YUx6gvSPGr5Sb60HFtNkmgkNzVH7tqWp7RyXevhabm4XfByevBu7T52Mqk0qNG8bxEvUdG+0jE5D26dafewlOyKzClGq8M+tyaaeNWOAo9LNM35pS4Z3JrXmctY41ONHdrhtCcANBBzU9iCTDjIKMUIRwzWwzgVnG3QqOJdU7q+uN9aIz2VzGsOXoAfxqYl3/Q/6xN0kYkqezXl5qaaM1IfHugq3JYa4nB30DJzt0Gd2x79Hw3ocIPdzyFbccG2ETP/g8r5jQhyL8ZV+PDquPuPHzA2BD1s7tE7aD610YxdJXcNfy2Q89438Pdi6xx60KbbcxzFbkRJXqabllGTFCUzG56l2MAI4KpYB3jk2IZfvslJTHUF0Nec6G2NTdB5M/vfrY8rZuH1+pqDLkqS8eln/YK33FAKfkMf23X2C7r6YmxHzSP6Uf91DjgWCpkx3GXdBxvxPPPCHTlpwE4e1UrEXGOSZpYymg+MHpISQt340l5EVW6K43sj8UlatzOlLWp0w1ukQOVmzrp3VmoQnfkR26PZWymQrZ+CmPSZZgWdRw6B4ZRik6raOlB9xbk84+4f3N5U5sOBQkUF7JfwfG1rLEhFYvJ+kTyzLLfHfwnyMBPchmPSORBry0IK6SUqcEIPwG7wgFqbHG/TJBtnuONGx6UqV/w/JCgSU5JK6obRoxoEfeZa
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:5;SRV:;IPV:NLI;SFV:SPM;H:CH2PR12MB4133.namprd12.prod.outlook.com;PTR:;CAT:OSPM;SFS:(4636009)(376002)(346002)(136003)(396003)(366004)(39860400002)(6496006)(52116002)(16526019)(956004)(2616005)(66946007)(54906003)(186003)(6916009)(2906002)(6486002)(26005)(86362001)(8936002)(1076003)(44832011)(4326008)(5660300002)(7416002)(83380400001)(478600001)(66556008)(316002)(6666004)(8676002)(66476007)(36756003)(23200700001);DIR:OUT;SFP:1501;
X-MS-Exchange-AntiSpam-MessageData: 
 gyYKZkbraNbYFbUPMS33/oMXNw2UJO2hzRDDzLT+FwIXZXM+VuTHrX9AEtMXFhYIpi0nQUQ9hN1bnpCOZJDDHyLrkGGigG2bcUTNh4Mt0vaDp6uVgJDC0jyk4rPTKG403OhsmQrUW935bpjajRQOnNPuH5yEd5UinGyiYdjKWN7DO1aY9whR9Kf+ULxvKFyxVTSYkeOE1uZMlrJtu6AKM9D6Vu7Lhlv/Ey9GCfUnEMY6cFXa+8ZJo8YwtMgHSNgDYsE5yUOi3nrDQDuqnevemAjIguvyxMg5e1LJ8DY6rh841w0eUUU/+XIlz+oGj5rLC9alWFJfrHXCh7Vz9HP1CxhzBlmGxtS+j3CzeEzFw99aIGePijNOduGbOCLK+I7P7WI50kcAj1y6A+eHr3V4BHoUih2ZU4k7b41nbqGYyjwEmrnVP2ce9AbToj+pi2e13aKIwSPnsaRkUDpSwlZTZXb4dtpgFv84ud6Lo0CRNlcgR+cv63p7FeEZ8mkSBgjaViG7q+mB5XQXVsonBVeyscJCOr2qfgqaRQMZ3CQuL2o8VhKoRVunfOfwNl+cXsLipyaE6WT//b+XMCW8Qgr747cZBG/L9Ew7DWidtkjNr71a2gaFyG7tqnLU2utv2IWT5Fy7eXGoUuI+jpcGw4LNd8x9G0km9Og31jid/4pX0Y2Drn9+ajnf1zTJo3snsRggVgqaGqQIIrvmDM/6WsM2k9/afAKFfT3ew0Thqvf/TfKtfXoHy6uZ9ifTFYVmt9byhJPaPssEuhoyyMKzlCPQXIhpBE685FIZK7dS4e0dKI/zrTrCKvmwtfoVBeqLXz+LGV3AnuiMlnHwPaUwIQFzjsu1Rlrt+tUlNLp3yezA4TfSN0S8y5ixFzd5MtWVGwCEzWMVZXIDbeSFbZB7TuhXnsFqmoG5pe+2BWyrubk2vkS7bOEMFp7loxt/ajYTIK+JTluBkQYYM5HxT90MoGPaQRLxsfYl3YrlyCy0xOBPznOvegy3IAbozVx0WO76ePAi
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-AuthSource: CH2PR12MB4133.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 05 Jan 2021 14:38:55.6054
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 669309ad-fde9-4fcd-f9ba-08d8b187a13f
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 CH07Leu8M0xmvLQVUjXTxn5lkZ5I8CXnuj77laBsAv+/QH1rm204zOlFjjbcq9B9peZECRqv5KVNjrUzlSMLuQ==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CH2PR12MB4134
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Now that the set of host user MSRs that need to be individually
saved/restored are the same with/without SEV-ES, we can drop the
.sev_es_restored flag and just iterate through the list unconditionally
for both cases. A subsequent patch can then move these loops to a
common path.

Signed-off-by: Michael Roth <michael.roth@amd.com>
---
 arch/x86/kvm/svm/sev.c | 16 ++++------------
 arch/x86/kvm/svm/svm.c |  6 ++----
 arch/x86/kvm/svm/svm.h |  7 ++-----
 3 files changed, 8 insertions(+), 21 deletions(-)

diff --git a/arch/x86/kvm/svm/sev.c b/arch/x86/kvm/svm/sev.c
index e57847ff8bd2..2a93b63322f4 100644
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@ -2007,12 +2007,8 @@ void sev_es_vcpu_load(struct vcpu_svm *svm, int cpu)
 	 * Certain MSRs are restored on VMEXIT, only save ones that aren't
 	 * restored.
 	 */
-	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++) {
-		if (host_save_user_msrs[i].sev_es_restored)
-			continue;
-
-		rdmsrl(host_save_user_msrs[i].index, svm->host_user_msrs[i]);
-	}
+	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
+		rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
 
 	/* XCR0 is restored on VMEXIT, save the current host value */
 	hostsa = (struct vmcb_save_area *)(page_address(sd->save_area) + 0x400);
@@ -2033,10 +2029,6 @@ void sev_es_vcpu_put(struct vcpu_svm *svm)
 	 * Certain MSRs are restored on VMEXIT and were saved with vmsave in
 	 * sev_es_vcpu_load() above. Only restore ones that weren't.
 	 */
-	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++) {
-		if (host_save_user_msrs[i].sev_es_restored)
-			continue;
-
-		wrmsrl(host_save_user_msrs[i].index, svm->host_user_msrs[i]);
-	}
+	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
+		wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
 }
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 7a7e9b7d47a7..7e1b5b452244 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1421,8 +1421,7 @@ static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 		sev_es_vcpu_load(svm, cpu);
 	} else {
 		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-			rdmsrl(host_save_user_msrs[i].index,
-			       svm->host_user_msrs[i]);
+			rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
 
 		asm volatile(__ex("vmsave %%"_ASM_AX)
 			     : : "a" (page_to_phys(sd->save_area)) : "memory");
@@ -1458,8 +1457,7 @@ static void svm_vcpu_put(struct kvm_vcpu *vcpu)
 		sev_es_vcpu_put(svm);
 	} else {
 		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-			wrmsrl(host_save_user_msrs[i].index,
-			       svm->host_user_msrs[i]);
+			wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
 	}
 }
 
diff --git a/arch/x86/kvm/svm/svm.h b/arch/x86/kvm/svm/svm.h
index 1f4460508036..a476449862f8 100644
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@ -23,11 +23,8 @@
 
 #define __sme_page_pa(x) __sme_set(page_to_pfn(x) << PAGE_SHIFT)
 
-static const struct svm_host_save_msrs {
-	u32 index;		/* Index of the MSR */
-	bool sev_es_restored;	/* True if MSR is restored on SEV-ES VMEXIT */
-} host_save_user_msrs[] = {
-	{ .index = MSR_TSC_AUX,			.sev_es_restored = false },
+static const u32 host_save_user_msrs[] = {
+	MSR_TSC_AUX,
 };
 #define NR_HOST_SAVE_USER_MSRS ARRAY_SIZE(host_save_user_msrs)
 

From patchwork Tue Jan  5 14:37:50 2021
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Michael Roth <michael.roth@amd.com>
X-Patchwork-Id: 11999165
Return-Path: <kvm-owner@kernel.org>
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
	aws-us-west-2-korg-lkml-1.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-16.8 required=3.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,HEADER_FROM_DIFFERENT_DOMAINS,INCLUDES_CR_TRAILER,INCLUDES_PATCH,
	MAILING_LIST_MULTI,MSGID_FROM_MTA_HEADER,SPF_HELO_NONE,SPF_PASS,
	USER_AGENT_GIT autolearn=ham autolearn_force=no version=3.4.0
Received: from mail.kernel.org (mail.kernel.org [198.145.29.99])
	by smtp.lore.kernel.org (Postfix) with ESMTP id 281F6C433E0
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:40:30 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id E2258225AC
	for <kvm@archiver.kernel.org>; Tue,  5 Jan 2021 14:40:29 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727780AbhAEOj7 (ORCPT <rfc822;kvm@archiver.kernel.org>);
        Tue, 5 Jan 2021 09:39:59 -0500
Received: from mail-bgr052100133013.outbound.protection.outlook.com
 ([52.100.133.13]:23221
        "EHLO NAM02-SN1-obe.outbound.protection.outlook.com"
        rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org with ESMTP
        id S1726306AbhAEOj7 (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 5 Jan 2021 09:39:59 -0500
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=RTF2ieNNvNJgPKpmaJlzB7idAg4srA+ora5JtPwgRuD9Jv9JQ6H/GUnUnwSIuEP1Tfp2Z5vrHaxQzkB/R2MacECXAVOkqks78QEJX/0NhN7660KIyr1fiH+z5I/AmKp7Szr/B9X3yKDCLN6/HAWsmI0oj6CuiLKb+EpRZ2m2Wx6zL7uJ66ZC//FCDhPcjxP4ATxO2sGde1cSpwqhNELBJ5N9rUMK4LV38qIRnY7s8+cBtUOBmRPM/rfWtg7KcQ0hBvijQc9ArrvpDmxRh7om92zZnidrS5QjQ9qYrRjYKOoJPX8xY/6rSUkGNCBr8EUJyigSPFG7BteH997KefiLxw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=WWmtXyeDvdenIHo7jonu6FVstVSnTi5ke72Mn65Onzg=;
 b=eeCexQObmKcR4bjWFQUCU862Pv5YkqwgygAQ2UBYWJaJPy9v76MgSp0NpTIBQLIs6+3l3s8JG82gT6YSHv6SVU+FYcCKMUJFrfItYFfEnUyYVx6IzJAefJKirxt9cDKyABU1rotZlmHZyYtN2vPUJpYlZqG/aQFw+YFAm8MVnTyrFqLhScky28bufsC4QQ35w6L+1o//EOTVG/9f466Ppf1KNZgKocoZTymPEC/zZIrCERL7A4ezadU3ME2P8+SU+rGDu3pkGY4PXzQtCuAzP6xJ23JXkHNAzxNyIMM0YYWy+DWyKY236/UJteHRLvkEVCcokKLGx1DUhaqq/7vRHQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=amd.com; dmarc=pass action=none header.from=amd.com; dkim=pass
 header.d=amd.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
 d=amdcloud.onmicrosoft.com; s=selector2-amdcloud-onmicrosoft-com;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=WWmtXyeDvdenIHo7jonu6FVstVSnTi5ke72Mn65Onzg=;
 b=hodJkFUF1lBRdTxwRrygXwhu+urH/rSZb1k1AxW28Uyp6w5JpkZ+PhPa8L+PLoKDjoWBffpcdQqhpDbLeIapkVTDMc9bEzFXLr9LlR6XqoPSEphoRRwjh9b2WdiKLBAo/cBZyMLHRucbOU786WxLgtG4Ow0phHcMVMqyC9r1Jk4=
Authentication-Results: vger.kernel.org; dkim=none (message not signed)
 header.d=none;vger.kernel.org; dmarc=none action=none header.from=amd.com;
Received: from CH2PR12MB4133.namprd12.prod.outlook.com (2603:10b6:610:7a::13)
 by CH2PR12MB5001.namprd12.prod.outlook.com (2603:10b6:610:61::18) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3742.6; Tue, 5 Jan
 2021 14:39:01 +0000
Received: from CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e]) by CH2PR12MB4133.namprd12.prod.outlook.com
 ([fe80::b965:3158:a370:d81e%7]) with mapi id 15.20.3721.024; Tue, 5 Jan 2021
 14:39:01 +0000
From: Michael Roth <michael.roth@amd.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Sean Christopherson <seanjc@google.com>,
        Andy Lutomirski <luto@amacapital.net>,
        Vitaly Kuznetsov <vkuznets@redhat.com>,
        Wanpeng Li <wanpengli@tencent.com>,
        Jim Mattson <jmattson@google.com>,
        Joerg Roedel <joro@8bytes.org>,
        Thomas Gleixner <tglx@linutronix.de>,
        Ingo Molnar <mingo@redhat.com>, Borislav Petkov <bp@alien8.de>,
        x86@kernel.org, "H . Peter Anvin" <hpa@zytor.com>,
        linux-kernel@vger.kernel.org
Subject: [PATCH v3 3/3] KVM: SVM: use .prepare_guest_switch() to handle CPU
 register save/setup
Date: Tue,  5 Jan 2021 08:37:50 -0600
Message-Id: <20210105143749.557054-4-michael.roth@amd.com>
X-Mailer: git-send-email 2.25.1
In-Reply-To: <20210105143749.557054-1-michael.roth@amd.com>
References: <20210105143749.557054-1-michael.roth@amd.com>
X-Originating-IP: [165.204.54.211]
X-ClientProxiedBy: YT1PR01CA0129.CANPRD01.PROD.OUTLOOK.COM
 (2603:10b6:b01:2f::8) To CH2PR12MB4133.namprd12.prod.outlook.com
 (2603:10b6:610:7a::13)
MIME-Version: 1.0
X-MS-Exchange-MessageSentRepresentingType: 1
Received: from localhost (165.204.54.211) by
 YT1PR01CA0129.CANPRD01.PROD.OUTLOOK.COM (2603:10b6:b01:2f::8) with Microsoft
 SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.3742.6 via Frontend
 Transport; Tue, 5 Jan 2021 14:39:00 +0000
X-MS-PublicTrafficType: Email
X-MS-Office365-Filtering-HT: Tenant
X-MS-Office365-Filtering-Correlation-Id: 66648cd1-8b70-43ab-c824-08d8b187a4dd
X-MS-TrafficTypeDiagnostic: CH2PR12MB5001:
X-Microsoft-Antispam-PRVS: 
 <CH2PR12MB50010348D6042CA18326A2E495D10@CH2PR12MB5001.namprd12.prod.outlook.com>
X-MS-Oob-TLC-OOBClassifiers: OLM:4125;
X-MS-Exchange-SenderADCheck: 1
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 
 gOCAkyBzJRLIqE6cbjf0GSAgCnCPtQuH1dxnFdCDRRhCXDGjYKAeu32VPM10OQriygoBdMaNOaFbResdDGI5eYpQpQxTKdLcL7gfxTfYodWLk9u/91+rDOwf+gnObF+4INXKa2SDPYuRcKMDBNB0ZweYE0My7RsARiFkBCK0mZDm5Gh+SL2t+ypmEhspB37xazfT2BGUT4Um6t46mzW0xVrib9kOTNOVPInkGe14HxaWKB43c0Ua4FdCKFh5iYbt04eJ+yUi2Y1L6E+4/bI27wZlCv354mKOqCQxCBUUezT0l87nybeDPTjggRzPo3vAY6kUH+VAe3y8PC2cpvmXFl8+FQswxS5r1MljY2iGgde5DM3b0RqCN5AibYLmv5o9zyb5HLjKkBV8O2POJ7UAUClC6T8TLZ+v4vtq4TzLSRXdU3F8fwSuMNFcaG9p94hISnlE/XN4buteujdF7+MdN5yb3XDd8r3eH1qM4xnscoBswYRg3YvTfR993ZEPYxAeHr85kALVbFuEJ6n8NCOrkhv8K92IhnW+YsrIQngZXhpGDoxiVFuzRRMXUsjP/5sTCt5+5ejMvYdhaL1aiinhaElfO9tX3/1Q2DZOfOyWfPD95HNIfLEUirDy/FESTWl8wmCMlfUIq6tYabbYKuJbCDj1SXEKqo+c9MeSSt67bR1dAp034pc1tYrq855cIcceoWXsPlDpbIzD9mWnqPOT0VrIhg1W896q8fxxGrdBnTBnW1S0zqqAMQhqfcwH4kM0
X-Forefront-Antispam-Report: 
 CIP:255.255.255.255;CTRY:;LANG:en;SCL:5;SRV:;IPV:NLI;SFV:SPM;H:CH2PR12MB4133.namprd12.prod.outlook.com;PTR:;CAT:OSPM;SFS:(4636009)(366004)(396003)(376002)(136003)(39860400002)(346002)(2616005)(956004)(36756003)(186003)(6666004)(2906002)(44832011)(6486002)(478600001)(8936002)(54906003)(7416002)(8676002)(316002)(1076003)(6496006)(26005)(4326008)(66476007)(6916009)(66556008)(52116002)(86362001)(83380400001)(16526019)(66946007)(5660300002)(23200700001);DIR:OUT;SFP:1501;
X-MS-Exchange-AntiSpam-MessageData: 
 HIyTkghe3R5KOwLoY3Km+0masD3airYmbb4J8QoaZl1eLNGLGIC/WOqgEtxQh1aHw6ZPFx0YoC4xwYofzkpqY5e7X+oIBYy8i+zhp0fp8Zmss73P9QDCN7wagI+DNhG8aOYuNLVuKIDA+BxtKUz5JB4yJ2Fzw05dvsuFv0untDWoFdBupA6COQA8+pYwcKHYdMMu1t6nJyN4k5CYAM0StCfc4ZKNjWr3Cx7GXOymZvZEWfA0o+tc1gBGeufedmyNqdG3mCo+pBC7Ho1xL4oZYd6r2vSGoTcEnOQGFGWY1kZvwMLvEsiRIHStHglp6lEuiTGREVnSjUNHVNe+5Es1K8hJjLEfYTc7hjyTMov4lToM8qetW0BY+Uwr5nuqwXoFKhnjH6CfTPLMOK8NR8MhozSQdLpViUMirmG5nC6naPdch1Gn41VeWftKZLm2bzKJtlqJswfw87JK/OIGz9+0n+6wj4bPYDT4xnIMcLw1vlDdA1fuK34LfHONUeH/Br7Qz9UAjOQDW0w7fai4+OVzqRvMmME5lu7Zg6qdTkmWkm2QvjRwmci4G1B2M1vMQVgCDYA8QQdMK89UiaxxWA1rD3coIqtqpm6jJCcaQHqx6DEpisQ1S1A7rovcpUkrx2lOCHNsfdOrYlDGREe5sSmaaRNVmeuRrGi1/jdyDUcNc4GTrB4LUkIVVO7JQ1dA68gowP1zImx/DUHCp+7tvGz3waAykil8CHia9jaH45g5xRhnftIc7OhueakNYAX8siDVI/KRowtzhojOIk6e8tjlSmLPQrGgdrL2lN45Iq2Gh0hjPXviuA0IawrYxYICF4V22c/FHpNDqqU2WoewcUdkPkOkg5E7WPsba5iW+JMpV2oSM04KSTmZayYWLzv5rLHvKmdHwBTp9vswDebMlj2CxhbBBWDL6BRVpU90JBE5owexAWymgWgSnOHnIBpPinUjll0/DMn1zqxD2DTMAAsRf8l3XfcpUlP9T093xQtFe838rsGCt2LeGUsw+EWtmkST
X-OriginatorOrg: amd.com
X-MS-Exchange-CrossTenant-AuthSource: CH2PR12MB4133.namprd12.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 05 Jan 2021 14:39:01.4408
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 3dd8961f-e488-4e60-8e11-a82d994e183d
X-MS-Exchange-CrossTenant-Network-Message-Id: 
 66648cd1-8b70-43ab-c824-08d8b187a4dd
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 
 ++TBYmOZ0V0i9/Sk65JTxs57InrsF1lL+/JcyWSQanYMfN+tcrQ4lPuZAlN3vPE0FC6643YYXiguZWHsTumnaw==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CH2PR12MB5001
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Currently we save host state like user-visible host MSRs, and do some
initial guest register setup for MSR_TSC_AUX and MSR_AMD64_TSC_RATIO
in svm_vcpu_load(). Defer this until just before we enter the guest by
moving the handling to kvm_x86_ops.prepare_guest_switch() similarly to
how it is done for the VMX implementation.

Additionally, since handling of saving/restoring host user MSRs is the
same both with/without SEV-ES enabled, move that handling to common
code.

Suggested-by: Sean Christopherson <seanjc@google.com>
Signed-off-by: Michael Roth <michael.roth@amd.com>
---
 arch/x86/kvm/svm/sev.c | 22 +-----------
 arch/x86/kvm/svm/svm.c | 76 +++++++++++++++++++++++++++++-------------
 arch/x86/kvm/svm/svm.h |  5 +--
 3 files changed, 56 insertions(+), 47 deletions(-)

diff --git a/arch/x86/kvm/svm/sev.c b/arch/x86/kvm/svm/sev.c
index 2a93b63322f4..9e7272adf861 100644
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@ -1990,11 +1990,10 @@ void sev_es_create_vcpu(struct vcpu_svm *svm)
 					    sev_enc_bit));
 }
 
-void sev_es_vcpu_load(struct vcpu_svm *svm, int cpu)
+void sev_es_prepare_guest_switch(struct vcpu_svm *svm, unsigned int cpu)
 {
 	struct svm_cpu_data *sd = per_cpu(svm_data, cpu);
 	struct vmcb_save_area *hostsa;
-	unsigned int i;
 
 	/*
 	 * As an SEV-ES guest, hardware will restore the host state on VMEXIT,
@@ -2003,13 +2002,6 @@ void sev_es_vcpu_load(struct vcpu_svm *svm, int cpu)
 	 */
 	asm volatile(__ex("vmsave") : : "a" (__sme_page_pa(sd->save_area)) : "memory");
 
-	/*
-	 * Certain MSRs are restored on VMEXIT, only save ones that aren't
-	 * restored.
-	 */
-	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-		rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
-
 	/* XCR0 is restored on VMEXIT, save the current host value */
 	hostsa = (struct vmcb_save_area *)(page_address(sd->save_area) + 0x400);
 	hostsa->xcr0 = xgetbv(XCR_XFEATURE_ENABLED_MASK);
@@ -2020,15 +2012,3 @@ void sev_es_vcpu_load(struct vcpu_svm *svm, int cpu)
 	/* MSR_IA32_XSS is restored on VMEXIT, save the currnet host value */
 	hostsa->xss = host_xss;
 }
-
-void sev_es_vcpu_put(struct vcpu_svm *svm)
-{
-	unsigned int i;
-
-	/*
-	 * Certain MSRs are restored on VMEXIT and were saved with vmsave in
-	 * sev_es_vcpu_load() above. Only restore ones that weren't.
-	 */
-	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-		wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
-}
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 7e1b5b452244..8f16402019e7 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -1359,6 +1359,7 @@ static int svm_create_vcpu(struct kvm_vcpu *vcpu)
 		svm->vmsa = page_address(vmsa_page);
 
 	svm->asid_generation = 0;
+	svm->guest_state_loaded = false;
 	init_vmcb(svm);
 
 	svm_init_osvw(vcpu);
@@ -1406,23 +1407,30 @@ static void svm_free_vcpu(struct kvm_vcpu *vcpu)
 	__free_pages(virt_to_page(svm->msrpm), MSRPM_ALLOC_ORDER);
 }
 
-static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
+static void svm_prepare_guest_switch(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
-	struct svm_cpu_data *sd = per_cpu(svm_data, cpu);
-	int i;
+	struct svm_cpu_data *sd = per_cpu(svm_data, vcpu->cpu);
+	unsigned int i;
 
-	if (unlikely(cpu != vcpu->cpu)) {
-		svm->asid_generation = 0;
-		vmcb_mark_all_dirty(svm->vmcb);
-	}
+	if (svm->guest_state_loaded)
+		return;
+
+	/*
+	 * Certain MSRs are restored on VMEXIT (sev-es), or vmload of host save
+	 * area (non-sev-es). Save ones that aren't so we can restore them
+	 * individually later.
+	 */
+	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
+		rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
 
+	/*
+	 * Save additional host state that will be restored on VMEXIT (sev-es)
+	 * or subsequent vmload of host save area.
+	 */
 	if (sev_es_guest(svm->vcpu.kvm)) {
-		sev_es_vcpu_load(svm, cpu);
+		sev_es_prepare_guest_switch(svm, vcpu->cpu);
 	} else {
-		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-			rdmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
-
 		asm volatile(__ex("vmsave %%"_ASM_AX)
 			     : : "a" (page_to_phys(sd->save_area)) : "memory");
 	}
@@ -1434,10 +1442,42 @@ static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 			wrmsrl(MSR_AMD64_TSC_RATIO, tsc_ratio);
 		}
 	}
+
 	/* This assumes that the kernel never uses MSR_TSC_AUX */
 	if (static_cpu_has(X86_FEATURE_RDTSCP))
 		wrmsrl(MSR_TSC_AUX, svm->tsc_aux);
 
+	svm->guest_state_loaded = true;
+}
+
+static void svm_prepare_host_switch(struct kvm_vcpu *vcpu)
+{
+	struct vcpu_svm *svm = to_svm(vcpu);
+	unsigned int i;
+
+	if (!svm->guest_state_loaded)
+		return;
+
+	/*
+	 * Certain MSRs are restored on VMEXIT (sev-es), or vmload of host save
+	 * area (non-sev-es). Restore the ones that weren't.
+	 */
+	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
+		wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
+
+	svm->guest_state_loaded = false;
+}
+
+static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
+{
+	struct vcpu_svm *svm = to_svm(vcpu);
+	struct svm_cpu_data *sd = per_cpu(svm_data, cpu);
+
+	if (unlikely(cpu != vcpu->cpu)) {
+		svm->asid_generation = 0;
+		vmcb_mark_all_dirty(svm->vmcb);
+	}
+
 	if (sd->current_vmcb != svm->vmcb) {
 		sd->current_vmcb = svm->vmcb;
 		indirect_branch_prediction_barrier();
@@ -1447,18 +1487,10 @@ static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
 
 static void svm_vcpu_put(struct kvm_vcpu *vcpu)
 {
-	struct vcpu_svm *svm = to_svm(vcpu);
-	int i;
-
 	avic_vcpu_put(vcpu);
+	svm_prepare_host_switch(vcpu);
 
 	++vcpu->stat.host_state_reload;
-	if (sev_es_guest(svm->vcpu.kvm)) {
-		sev_es_vcpu_put(svm);
-	} else {
-		for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
-			wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
-	}
 }
 
 static unsigned long svm_get_rflags(struct kvm_vcpu *vcpu)
@@ -3536,10 +3568,6 @@ static void svm_flush_tlb_gva(struct kvm_vcpu *vcpu, gva_t gva)
 	invlpga(gva, svm->vmcb->control.asid);
 }
 
-static void svm_prepare_guest_switch(struct kvm_vcpu *vcpu)
-{
-}
-
 static inline void sync_cr8_to_lapic(struct kvm_vcpu *vcpu)
 {
 	struct vcpu_svm *svm = to_svm(vcpu);
diff --git a/arch/x86/kvm/svm/svm.h b/arch/x86/kvm/svm/svm.h
index a476449862f8..52d30a6e879c 100644
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@ -171,6 +171,8 @@ struct vcpu_svm {
 	u64 ghcb_sa_len;
 	bool ghcb_sa_sync;
 	bool ghcb_sa_free;
+
+	bool guest_state_loaded;
 };
 
 struct svm_cpu_data {
@@ -569,8 +571,7 @@ int sev_handle_vmgexit(struct vcpu_svm *svm);
 int sev_es_string_io(struct vcpu_svm *svm, int size, unsigned int port, int in);
 void sev_es_init_vmcb(struct vcpu_svm *svm);
 void sev_es_create_vcpu(struct vcpu_svm *svm);
-void sev_es_vcpu_load(struct vcpu_svm *svm, int cpu);
-void sev_es_vcpu_put(struct vcpu_svm *svm);
+void sev_es_prepare_guest_switch(struct vcpu_svm *svm, unsigned int cpu);
 
 /* vmenter.S */
 
