From patchwork Tue Jan 28 09:27:11 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Oliver Upton <oupton@google.com>
X-Patchwork-Id: 11353861
Return-Path: <SRS0=gQxY=3R=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id D4D55138C
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:31 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id B2EB324688
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:31 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="k4wersvP"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725953AbgA1J1b (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 28 Jan 2020 04:27:31 -0500
Received: from mail-pj1-f73.google.com ([209.85.216.73]:44855 "EHLO
        mail-pj1-f73.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725922AbgA1J1a (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 28 Jan 2020 04:27:30 -0500
Received: by mail-pj1-f73.google.com with SMTP id c31so1128595pje.9
        for <kvm@vger.kernel.org>; Tue, 28 Jan 2020 01:27:30 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=nioYHgWtzuJX0bGGHSnAcIx7clPoYS+RyTzHFfHLiC0=;
        b=k4wersvPQpScFKgypDDZhrTlz2Tiv91+qRRQMaNpNlAHjISZCuXpObMYK6G8w4xJ9U
         77ZWAhVxTCXsoMsx6kkhPFBAQNLE5EyJcHJpTw8KlHyoSwZK9lNsLFOkpM0GgNuWlilC
         DJbXzCjv+/ux8RyJP+p3CcVQXGcLwx6A7OFKG/du4GJehbgZkYahCD7vIiF/esJOO7s9
         IbxIjkmqmuETjqHytNnsoxUHAqxYBiXrn/8mq//XMeqzl96BiWT5Ns8d7M150bNCzuOj
         D8kVvv+azEBzZNX+xAnvTPGPCbB0p2qRp5sqrgFh+FyYCCNtzE4Eh9EvigzEk07zRWLV
         +Fag==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=nioYHgWtzuJX0bGGHSnAcIx7clPoYS+RyTzHFfHLiC0=;
        b=qanlwMKinkAOKSphOQKrZ9QOnrx272CeIhnEFDSNH/cCx6wHqG5DvyyJYVAC8ppnVo
         sN28GrKOdRow6tRyospkjgPEqL0dUfpi+Y9NQYFfJ7kyyIBDmANIOTcXnpE8p7eAqMXA
         mFdCet8IyKEdeUyKO/jTssaCzvNBKImYUNZv6aHhC2Ps/NwaLyLcfIDGStAabKhJSPqP
         i7wLmfM/A1ifqKGmtdkgPILlAMXOspLNPOvQ1g5GPdFYmMordLFjkN4YzAXjelMdwSJY
         GG5ymOf7a8CXAz/HsnENzodO+QX89PQ0yKEc07qO9+A2VgnPuYvs8oPo3IrrqAl0Zjpf
         LScw==
X-Gm-Message-State: APjAAAW/fRhooOip+I3lgZFtf+tfIkxBThYl1r6pQVodLSK7wCw5dUmj
        SLDyRiFflUQJEMc8YciHZOdpq8uJ+j8yxWQP7qjrtYcO7QyMSxxokk/Dyl8a+shtqySWiF4vWyW
        NWTrtB04AA15FrzXUVixlR4WOMJO1HvUQcpyt+ygBf4y435pNFQ3T/z1SSA==
X-Google-Smtp-Source: 
 APXvYqy0cehjxUbWNumChAd1siL4XK+9M6zowjeV4zuou3ingY61ee2Z+Hjbqozv2qBQZ4wdtqm9RR46lmc=
X-Received: by 2002:a63:78b:: with SMTP id 133mr23439750pgh.379.1580203649548;
 Tue, 28 Jan 2020 01:27:29 -0800 (PST)
Date: Tue, 28 Jan 2020 01:27:11 -0800
In-Reply-To: <20200128092715.69429-1-oupton@google.com>
Message-Id: <20200128092715.69429-2-oupton@google.com>
Mime-Version: 1.0
References: <20200128092715.69429-1-oupton@google.com>
X-Mailer: git-send-email 2.25.0.341.g760bfbb309-goog
Subject: [PATCH v2 1/5] KVM: x86: Mask off reserved bit from #DB exception
 payload
From: Oliver Upton <oupton@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Peter Shier <pshier@google.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>,
        Oliver Upton <oupton@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

KVM defines the #DB payload as compatible with the 'pending debug
exceptions' field under VMX, not DR6. Mask off bit 12 when applying the
payload to DR6, as it is reserved on DR6 but not the 'pending debug
exceptions' field.

Fixes: f10c729ff965 ("kvm: vmx: Defer setting of DR6 until #DB delivery")
Signed-off-by: Oliver Upton <oupton@google.com>
---
 arch/x86/kvm/x86.c | 8 ++++++++
 1 file changed, 8 insertions(+)

diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 7e118883d8f1..7a341c0c978a 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -437,6 +437,14 @@ void kvm_deliver_exception_payload(struct kvm_vcpu *vcpu)
 		 * for #DB exceptions under VMX.
 		 */
 		vcpu->arch.dr6 ^= payload & DR6_RTM;
+
+		/*
+		 * The #DB payload is defined as compatible with the 'pending
+		 * debug exceptions' field under VMX, not DR6. While bit 12 is
+		 * defined in the 'pending debug exceptions' field (enabled
+		 * breakpoint), it is reserved and must be zero in DR6.
+		 */
+		vcpu->arch.dr6 &= ~BIT(12);
 		break;
 	case PF_VECTOR:
 		vcpu->arch.cr2 = payload;

From patchwork Tue Jan 28 09:27:12 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Oliver Upton <oupton@google.com>
X-Patchwork-Id: 11353863
Return-Path: <SRS0=gQxY=3R=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 03F8A138C
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:35 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id D124624686
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:34 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="HShU2nYd"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725974AbgA1J1e (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 28 Jan 2020 04:27:34 -0500
Received: from mail-pf1-f201.google.com ([209.85.210.201]:35447 "EHLO
        mail-pf1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725937AbgA1J1d (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 28 Jan 2020 04:27:33 -0500
Received: by mail-pf1-f201.google.com with SMTP id q1so6539900pfg.2
        for <kvm@vger.kernel.org>; Tue, 28 Jan 2020 01:27:33 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=IHJ86SLN1S+rfmJdnpXkVr/JXWTzVlGoYtPFiC2EzRQ=;
        b=HShU2nYds5BLgnrEtuSkTv7LhPwkCIK0fartLoQDsKIr7bbDzn4nPvt2ZREGdAPx4H
         xeLtNOjjgn/C2Mh/lHskcrwZPLifquUdI28UypQItDJ/9QIqx2ixu0JuaBu0R5NxUF/F
         ViUC4yHnUr1yN1CkoNdVbp+zQlEYjmoOhMhcr9xO5l3gwKq+CnzioGlv+ybNC/PeJ7md
         gPd72QWNeg8kn6EAHTeEZKp0ad6fJw1i741In1NWGsWrAGkIeM2ATQkygIoD+Ajw8v8P
         stqc/zL4JNPyyMrTd+4gYmbnnsYzuXPYt+F95yLGzkQbiXKD1miNiutQsOJkP9wSvEEN
         k0MQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=IHJ86SLN1S+rfmJdnpXkVr/JXWTzVlGoYtPFiC2EzRQ=;
        b=H0mpGB46bNvUgP9BkpIJn5WjH3qzShL+O/QkmnR0Dv7uid3mUFjSmf96iaW77egik2
         1PF11adhm+xBjQZ6ML9F1aCOuEjKqsdV7iq6wT4yw46zY7zbEv3nNnzGl9+i76YHHuD2
         syU711nlKVW1XijQRqQQQ+1Ams8N/yTLNdL5StCoNmjEYPSfvg8f+FLGt7t0NteBapuo
         E0q130gC182F85JO/I61EMWNo8P7xtb2NSLt/HKrmrf5dZy5xGUzHRFk8wlEIk1wpSxt
         idyEZgxIlfu0B/N9d866aOvQsXCw4s8FCxO0M+ZkYJSkcETIN9ccJCbNKvRQtYnqT5q1
         li5g==
X-Gm-Message-State: APjAAAXIBLfL2ZgBdhwVZdqJx8OgvRHWiw2R+4mFOMiiT0LtCNmkxRc+
        J9EQb+bLcd8FkFwTpyyy1o68H/erG7iW/Tubb86PEWSqQRpDdLgV/S/1s2WFpHIR3alcKCrhXmJ
        qbd6vDECgLcaJZSNAgIo/AdoyLqrd+/HtB7i+P3GhBmcVu2RhtxL07u2EQQ==
X-Google-Smtp-Source: 
 APXvYqx3N4YqPZwVJ1OaHJ0OfL2nhGkNKI5Np+iz9vF2WUbLlIqvIrNJeTcsXINtIESnsYgoJWcZ61ZWUpo=
X-Received: by 2002:a63:1c1d:: with SMTP id c29mr24245332pgc.14.1580203652850;
 Tue, 28 Jan 2020 01:27:32 -0800 (PST)
Date: Tue, 28 Jan 2020 01:27:12 -0800
In-Reply-To: <20200128092715.69429-1-oupton@google.com>
Message-Id: <20200128092715.69429-3-oupton@google.com>
Mime-Version: 1.0
References: <20200128092715.69429-1-oupton@google.com>
X-Mailer: git-send-email 2.25.0.341.g760bfbb309-goog
Subject: [PATCH v2 2/5] KVM: nVMX: Handle pending #DB when injecting INIT
 VM-exit
From: Oliver Upton <oupton@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Peter Shier <pshier@google.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>,
        Oliver Upton <oupton@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

SDM 27.3.4 states that the 'pending debug exceptions' VMCS field will
be populated if a VM-exit caused by an INIT signal takes priority over a
debug-trap. Emulate this behavior when synthesizing an INIT signal
VM-exit into L1.

Fixes: 558b8d50dbff ("KVM: x86: Fix INIT signal handling in various CPU states")
Signed-off-by: Oliver Upton <oupton@google.com>
---
 arch/x86/kvm/vmx/nested.c | 23 +++++++++++++++++++++++
 1 file changed, 23 insertions(+)

diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index 95b3f4306ac2..aba16599ca69 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -3572,6 +3572,27 @@ static void nested_vmx_inject_exception_vmexit(struct kvm_vcpu *vcpu,
 	nested_vmx_vmexit(vcpu, EXIT_REASON_EXCEPTION_NMI, intr_info, exit_qual);
 }
 
+static inline bool nested_vmx_check_pending_dbg(struct kvm_vcpu *vcpu)
+{
+	return vcpu->arch.exception.nr == DB_VECTOR &&
+			vcpu->arch.exception.pending &&
+			vcpu->arch.exception.has_payload;
+}
+
+/*
+ * If a higher priority VM-exit is delivered before a debug-trap, hardware will
+ * set the 'pending debug exceptions' field appropriately for reinjection on the
+ * next VM-entry.
+ */
+static void nested_vmx_set_pending_dbg(struct kvm_vcpu *vcpu)
+{
+	vmcs_writel(GUEST_PENDING_DBG_EXCEPTIONS, vcpu->arch.exception.payload);
+	vcpu->arch.exception.has_payload = false;
+	vcpu->arch.exception.payload = 0;
+	vcpu->arch.exception.pending = false;
+	vcpu->arch.exception.injected = true;
+}
+
 static int vmx_check_nested_events(struct kvm_vcpu *vcpu, bool external_intr)
 {
 	struct vcpu_vmx *vmx = to_vmx(vcpu);
@@ -3584,6 +3605,8 @@ static int vmx_check_nested_events(struct kvm_vcpu *vcpu, bool external_intr)
 		test_bit(KVM_APIC_INIT, &apic->pending_events)) {
 		if (block_nested_events)
 			return -EBUSY;
+		if (nested_vmx_check_pending_dbg(vcpu))
+			nested_vmx_set_pending_dbg(vcpu);
 		clear_bit(KVM_APIC_INIT, &apic->pending_events);
 		nested_vmx_vmexit(vcpu, EXIT_REASON_INIT_SIGNAL, 0, 0);
 		return 0;

From patchwork Tue Jan 28 09:27:13 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Oliver Upton <oupton@google.com>
X-Patchwork-Id: 11353865
Return-Path: <SRS0=gQxY=3R=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id E48ED138C
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:36 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id C371924688
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:36 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="FMJiwLj+"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725971AbgA1J1g (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 28 Jan 2020 04:27:36 -0500
Received: from mail-pf1-f201.google.com ([209.85.210.201]:51696 "EHLO
        mail-pf1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725920AbgA1J1f (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 28 Jan 2020 04:27:35 -0500
Received: by mail-pf1-f201.google.com with SMTP id z19so8246739pfn.18
        for <kvm@vger.kernel.org>; Tue, 28 Jan 2020 01:27:35 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=4hAb+9+PFKE4UE+q8aj578+DRIxxwyVpmw+zN6tI7Xc=;
        b=FMJiwLj+Fwn2zTkI0mDxkWt05sWOgN+9HTOnO4H5LZIEaNYiq4e5rXw5ZQgiu15n09
         AXjaw2rFOa79n7v2KWbWLgLf0IVY0SJe1pnr59d+j9uz+qCvPx8WiU6YK4R7Wle5k3sm
         BqzZsepJE98smqnaxAWeHmVU9dPvn61a+UtGx1UXEecIxIIAMNNeyId+r19F4G4Bcug+
         /qkwtMLRwOkF/TKZE6tHQBp/AUJ7eYaClu3iOYl9TS6TOUYr9pLYMqt0I+Lk9JifND9j
         6su/dKYmLr3XFiw4uNb0xG3IazC6SCIDBPed8p83KbBOaA8QOw3gbb2krkiFRxsRcz6g
         EqGA==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=4hAb+9+PFKE4UE+q8aj578+DRIxxwyVpmw+zN6tI7Xc=;
        b=Bnq+cmxB0ePSRjo1Ds5JlnOt2qzmpggpn/G3cwDvAFJ95+urzg/vQLfeTxrcEmytFS
         9jOOpaye4Ra8JbnEf0WRWKih+BvzOKfrk3QbB5j79phnF7DWMHAD7TbLQuK5mIV3gtAo
         Z3EKfVgWNLQYEkQAnqLQaFuvKQNj9pfK+zm8G6T5ZHGsaXafGlHEEOzuGt3IedvGgFmD
         VhUooM7pzf9OCOqZA64E80kDqdb/Xp1TRrX+Xodh05xVezPO6MzY7QPe4b5GznIrDqhm
         IyI3LKqZ33uNroRJV4xQ/svt2OyivaNyxLKEMbc3mfMg0PM02UtqQq2izFB7NORUGmZu
         sdPA==
X-Gm-Message-State: APjAAAXGAthc4jLZGJ6KBd2MTPaE5OWziBl58XcxaynCUqoulksxdDvJ
        NiMtt95pILceavDCSDX5xLRuUfLCtAfRWwlJ9M5hvs5hve4m7zl1Vdnk8NpDIh1LEy4YMLv0BE6
        Ov1rNAzLAP7uOHroAaX3Y9Q7FUHhu4NoaV/MALr8jjbDeMQ5MS/jRnwG4vQ==
X-Google-Smtp-Source: 
 APXvYqxN5CBDtyuh7Tgk8FQ9N7ZpzWeBwhIyHBexcSEK+NUjANqNputcSiLTxAQ1DawMlrMt8Ph+3wqN9G0=
X-Received: by 2002:a63:874a:: with SMTP id i71mr10592621pge.55.1580203654909;
 Tue, 28 Jan 2020 01:27:34 -0800 (PST)
Date: Tue, 28 Jan 2020 01:27:13 -0800
In-Reply-To: <20200128092715.69429-1-oupton@google.com>
Message-Id: <20200128092715.69429-4-oupton@google.com>
Mime-Version: 1.0
References: <20200128092715.69429-1-oupton@google.com>
X-Mailer: git-send-email 2.25.0.341.g760bfbb309-goog
Subject: [PATCH v2 3/5] KVM: x86: Deliver exception payload on
 KVM_GET_VCPU_EVENTS
From: Oliver Upton <oupton@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Peter Shier <pshier@google.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>,
        Oliver Upton <oupton@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

KVM doesn't utilize exception payloads by default, as this behavior
diverges from the expectations of the userspace API. However, this
constraint only applies if KVM is servicing a KVM_GET_VCPU_EVENTS ioctl
before delivering the exception.

Use exception payloads unconditionally if the vcpu is in guest mode.
Deliver the exception payload before completing a KVM_GET_VCPU_EVENTS
to ensure API compatibility.

Signed-off-by: Oliver Upton <oupton@google.com>
---
 arch/x86/kvm/x86.c | 29 ++++++++++++++++-------------
 1 file changed, 16 insertions(+), 13 deletions(-)

diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 7a341c0c978a..9f080101618c 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -497,19 +497,7 @@ static void kvm_multiple_exception(struct kvm_vcpu *vcpu,
 		vcpu->arch.exception.error_code = error_code;
 		vcpu->arch.exception.has_payload = has_payload;
 		vcpu->arch.exception.payload = payload;
-		/*
-		 * In guest mode, payload delivery should be deferred,
-		 * so that the L1 hypervisor can intercept #PF before
-		 * CR2 is modified (or intercept #DB before DR6 is
-		 * modified under nVMX).  However, for ABI
-		 * compatibility with KVM_GET_VCPU_EVENTS and
-		 * KVM_SET_VCPU_EVENTS, we can't delay payload
-		 * delivery unless userspace has enabled this
-		 * functionality via the per-VM capability,
-		 * KVM_CAP_EXCEPTION_PAYLOAD.
-		 */
-		if (!vcpu->kvm->arch.exception_payload_enabled ||
-		    !is_guest_mode(vcpu))
+		if (!is_guest_mode(vcpu))
 			kvm_deliver_exception_payload(vcpu);
 		return;
 	}
@@ -3790,6 +3778,21 @@ static void kvm_vcpu_ioctl_x86_get_vcpu_events(struct kvm_vcpu *vcpu,
 {
 	process_nmi(vcpu);
 
+	/*
+	 * In guest mode, payload delivery should be deferred,
+	 * so that the L1 hypervisor can intercept #PF before
+	 * CR2 is modified (or intercept #DB before DR6 is
+	 * modified under nVMX).  However, for ABI
+	 * compatibility with KVM_GET_VCPU_EVENTS and
+	 * KVM_SET_VCPU_EVENTS, we can't delay payload
+	 * delivery unless userspace has enabled this
+	 * functionality via the per-VM capability,
+	 * KVM_CAP_EXCEPTION_PAYLOAD.
+	 */
+	if (!vcpu->kvm->arch.exception_payload_enabled &&
+	    vcpu->arch.exception.pending && vcpu->arch.exception.has_payload)
+		kvm_deliver_exception_payload(vcpu);
+
 	/*
 	 * The API doesn't provide the instruction length for software
 	 * exceptions, so don't report them. As long as the guest RIP

From patchwork Tue Jan 28 09:27:14 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Oliver Upton <oupton@google.com>
X-Patchwork-Id: 11353867
Return-Path: <SRS0=gQxY=3R=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 3ACE014B4
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:39 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 04E0D24686
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:39 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="SiHKu362"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726002AbgA1J1i (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 28 Jan 2020 04:27:38 -0500
Received: from mail-pf1-f201.google.com ([209.85.210.201]:37401 "EHLO
        mail-pf1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725937AbgA1J1i (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 28 Jan 2020 04:27:38 -0500
Received: by mail-pf1-f201.google.com with SMTP id x10so2801879pfn.4
        for <kvm@vger.kernel.org>; Tue, 28 Jan 2020 01:27:37 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=HrQ7Xb+2RL2sh5BvvV+ZT/NUwQME3QA1PNFd1x3Wr/g=;
        b=SiHKu362nEj+DrksWKTsF1+54qvk/5CQyF1kFafq7LIskQLFPBZsPGMfgqXsuJrjIp
         66pWtmUPrUSoLCikOWS6SX8Yf00EjHLVEIwBxtloomcqzBcKzgNzOMN4nQ36x2EWVuk2
         5pY30J0tX79ihqlMk72h8Fq273WwqcoOLXr1MCLdcHl59bDlo330tb2DLigrkglRS62g
         L2Drik096dnFRw6AVPjRIAS+DIHjMpTmqPkCTQmkPg/qDKGVvnTv48aKCe/Fr+NWLy91
         JxzpDq3Hj/BhCS4TbhiZDy1qeebPDHG+XZc/wMb+Ed3jUQP0dWlhUEFT5QEjfuQtsCGS
         gFqQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=HrQ7Xb+2RL2sh5BvvV+ZT/NUwQME3QA1PNFd1x3Wr/g=;
        b=PbwInHleRLo4gP6mG/wJT3UUagtWgd1m0rawf61qWXgBg3DbNIIIPk98dVbBoVOvPP
         k1PleQYoU6aiW62TMXz92MTw3IXn2G7MmevLSvkGCf2TVZvpEHpz1a15rSruuHaE+Czm
         BGxJJJCsEHdLGQqVe6f4zPFQnRPTaZPJew6NvepiyWUjV/bbYwstu9EnE1Gy1vb0RbDW
         tizMaGhfonG8LhpK3zfWazWCMsXX6L9mrcjUFvEbk0A+4nL8OdKUBPKdVEWQlD+3JGlg
         mld029eLrgb84I6iUxZIE5CGXUNNTbg3HNSma6bfWgHQ7Y5qSgykTY9Zk2MEjvEOHKyW
         1JkA==
X-Gm-Message-State: APjAAAXI7y2NpbZmixNzi+L7pPi1h8w6j170LZPGU2Ltfkte2cf3rm9n
        Mo4g8pxaPzg8NNw5nmqR5mqh0cEfTfWTelQPd+EJuuyUng+zF/+8S0AcEvDoRp9P1gji9PE3JSb
        mCezV1bvvHIVXlFLKgb+AHCK+mfMlgAvKXWMpWFSIu3jELYgx5E8rxn2Vwg==
X-Google-Smtp-Source: 
 APXvYqxxsHVHjLZMSKMcRkRC0Elu3jFuGtJKBmqrSv+uscnfcv51U5fpvOpqQMb7DRcrRX61s8MlNS2NI0Q=
X-Received: by 2002:a63:6ac1:: with SMTP id
 f184mr23595577pgc.133.1580203656953;
 Tue, 28 Jan 2020 01:27:36 -0800 (PST)
Date: Tue, 28 Jan 2020 01:27:14 -0800
In-Reply-To: <20200128092715.69429-1-oupton@google.com>
Message-Id: <20200128092715.69429-5-oupton@google.com>
Mime-Version: 1.0
References: <20200128092715.69429-1-oupton@google.com>
X-Mailer: git-send-email 2.25.0.341.g760bfbb309-goog
Subject: [PATCH v2 4/5] KVM: nVMX: Emulate MTF when performing instruction
 emulation
From: Oliver Upton <oupton@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Peter Shier <pshier@google.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>,
        Oliver Upton <oupton@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Since commit 5f3d45e7f282 ("kvm/x86: add support for
MONITOR_TRAP_FLAG"), KVM has allowed an L1 guest to use the monitor trap
flag processor-based execution control for its L2 guest. KVM simply
forwards any MTF VM-exits to the L1 guest, which works for normal
instruction execution.

However, when KVM needs to emulate an instruction on the behalf of an L2
guest, the monitor trap flag is not emulated. Add the necessary logic to
kvm_skip_emulated_instruction() to synthesize an MTF VM-exit to L1 upon
instruction emulation for L2.

Fixes: 5f3d45e7f282 ("kvm/x86: add support for MONITOR_TRAP_FLAG")
Signed-off-by: Oliver Upton <oupton@google.com>
---
 arch/x86/include/asm/kvm_host.h |  1 +
 arch/x86/include/uapi/asm/kvm.h |  1 +
 arch/x86/kvm/svm.c              |  1 +
 arch/x86/kvm/vmx/nested.c       | 37 ++++++++++++++++++++++++++++++++-
 arch/x86/kvm/vmx/nested.h       |  5 +++++
 arch/x86/kvm/vmx/vmx.c          | 22 ++++++++++++++++++++
 arch/x86/kvm/vmx/vmx.h          |  3 +++
 arch/x86/kvm/x86.c              | 15 +++++++------
 8 files changed, 78 insertions(+), 7 deletions(-)

diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 69e31dbdfdc2..e1061ebc1b4b 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1103,6 +1103,7 @@ struct kvm_x86_ops {
 	int (*handle_exit)(struct kvm_vcpu *vcpu,
 		enum exit_fastpath_completion exit_fastpath);
 	int (*skip_emulated_instruction)(struct kvm_vcpu *vcpu);
+	void (*do_singlestep)(struct kvm_vcpu *vcpu);
 	void (*set_interrupt_shadow)(struct kvm_vcpu *vcpu, int mask);
 	u32 (*get_interrupt_shadow)(struct kvm_vcpu *vcpu);
 	void (*patch_hypercall)(struct kvm_vcpu *vcpu,
diff --git a/arch/x86/include/uapi/asm/kvm.h b/arch/x86/include/uapi/asm/kvm.h
index 503d3f42da16..3f3f780c8c65 100644
--- a/arch/x86/include/uapi/asm/kvm.h
+++ b/arch/x86/include/uapi/asm/kvm.h
@@ -390,6 +390,7 @@ struct kvm_sync_regs {
 #define KVM_STATE_NESTED_GUEST_MODE	0x00000001
 #define KVM_STATE_NESTED_RUN_PENDING	0x00000002
 #define KVM_STATE_NESTED_EVMCS		0x00000004
+#define KVM_STATE_NESTED_MTF_PENDING	0x00000008
 
 #define KVM_STATE_NESTED_SMM_GUEST_MODE	0x00000001
 #define KVM_STATE_NESTED_SMM_VMXON	0x00000002
diff --git a/arch/x86/kvm/svm.c b/arch/x86/kvm/svm.c
index 9dbb990c319a..3653e230d3d5 100644
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -7316,6 +7316,7 @@ static struct kvm_x86_ops svm_x86_ops __ro_after_init = {
 	.run = svm_vcpu_run,
 	.handle_exit = handle_exit,
 	.skip_emulated_instruction = skip_emulated_instruction,
+	.do_singlestep = NULL,
 	.set_interrupt_shadow = svm_set_interrupt_shadow,
 	.get_interrupt_shadow = svm_get_interrupt_shadow,
 	.patch_hypercall = svm_patch_hypercall,
diff --git a/arch/x86/kvm/vmx/nested.c b/arch/x86/kvm/vmx/nested.c
index aba16599ca69..0de71b207b2a 100644
--- a/arch/x86/kvm/vmx/nested.c
+++ b/arch/x86/kvm/vmx/nested.c
@@ -3599,8 +3599,15 @@ static int vmx_check_nested_events(struct kvm_vcpu *vcpu, bool external_intr)
 	unsigned long exit_qual;
 	bool block_nested_events =
 	    vmx->nested.nested_run_pending || kvm_event_needs_reinjection(vcpu);
+	bool mtf_pending = vmx->nested.mtf_pending;
 	struct kvm_lapic *apic = vcpu->arch.apic;
 
+	/*
+	 * Clear the MTF state. If a higher priority VM-exit is delivered first,
+	 * this state is discarded.
+	 */
+	vmx->nested.mtf_pending = false;
+
 	if (lapic_in_kernel(vcpu) &&
 		test_bit(KVM_APIC_INIT, &apic->pending_events)) {
 		if (block_nested_events)
@@ -3612,8 +3619,30 @@ static int vmx_check_nested_events(struct kvm_vcpu *vcpu, bool external_intr)
 		return 0;
 	}
 
+	/*
+	 * Process non-debug exceptions first before MTF.
+	 */
 	if (vcpu->arch.exception.pending &&
-		nested_vmx_check_exception(vcpu, &exit_qual)) {
+	    !nested_vmx_check_pending_dbg(vcpu) &&
+	    nested_vmx_check_exception(vcpu, &exit_qual)) {
+		if (block_nested_events)
+			return -EBUSY;
+		nested_vmx_inject_exception_vmexit(vcpu, exit_qual);
+		return 0;
+	}
+
+	if (mtf_pending) {
+		if (block_nested_events)
+			return -EBUSY;
+		if (nested_vmx_check_pending_dbg(vcpu))
+			nested_vmx_set_pending_dbg(vcpu);
+		nested_vmx_vmexit(vcpu, EXIT_REASON_MONITOR_TRAP_FLAG, 0, 0);
+		return 0;
+	}
+
+	if (vcpu->arch.exception.pending &&
+	    nested_vmx_check_pending_dbg(vcpu) &&
+	    nested_vmx_check_exception(vcpu, &exit_qual)) {
 		if (block_nested_events)
 			return -EBUSY;
 		nested_vmx_inject_exception_vmexit(vcpu, exit_qual);
@@ -5705,6 +5734,9 @@ static int vmx_get_nested_state(struct kvm_vcpu *vcpu,
 
 			if (vmx->nested.nested_run_pending)
 				kvm_state.flags |= KVM_STATE_NESTED_RUN_PENDING;
+
+			if (vmx->nested.mtf_pending)
+				kvm_state.flags |= KVM_STATE_NESTED_MTF_PENDING;
 		}
 	}
 
@@ -5885,6 +5917,9 @@ static int vmx_set_nested_state(struct kvm_vcpu *vcpu,
 	vmx->nested.nested_run_pending =
 		!!(kvm_state->flags & KVM_STATE_NESTED_RUN_PENDING);
 
+	vmx->nested.mtf_pending =
+		!!(kvm_state->flags & KVM_STATE_NESTED_MTF_PENDING);
+
 	ret = -EINVAL;
 	if (nested_cpu_has_shadow_vmcs(vmcs12) &&
 	    vmcs12->vmcs_link_pointer != -1ull) {
diff --git a/arch/x86/kvm/vmx/nested.h b/arch/x86/kvm/vmx/nested.h
index fc874d4ead0f..e12461776151 100644
--- a/arch/x86/kvm/vmx/nested.h
+++ b/arch/x86/kvm/vmx/nested.h
@@ -175,6 +175,11 @@ static inline bool nested_cpu_has_virtual_nmis(struct vmcs12 *vmcs12)
 	return vmcs12->pin_based_vm_exec_control & PIN_BASED_VIRTUAL_NMIS;
 }
 
+static inline int nested_cpu_has_mtf(struct vmcs12 *vmcs12)
+{
+	return nested_cpu_has(vmcs12, CPU_BASED_MONITOR_TRAP_FLAG);
+}
+
 static inline int nested_cpu_has_ept(struct vmcs12 *vmcs12)
 {
 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_ENABLE_EPT);
diff --git a/arch/x86/kvm/vmx/vmx.c b/arch/x86/kvm/vmx/vmx.c
index 802ba97ac7f2..5735d1a1af05 100644
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@ -1601,6 +1601,27 @@ static int skip_emulated_instruction(struct kvm_vcpu *vcpu)
 	return 1;
 }
 
+static void vmx_do_singlestep(struct kvm_vcpu *vcpu)
+{
+	struct vcpu_vmx *vmx;
+
+	if (!(is_guest_mode(vcpu) &&
+	      nested_cpu_has_mtf(get_vmcs12(vcpu))))
+		return;
+
+	vmx = to_vmx(vcpu);
+
+	/*
+	 * Per the SDM, MTF takes priority over debug-trap exception besides
+	 * T-bit traps. As instruction emulation is completed (i.e. at the end
+	 * of an instruction boundary), any #DB exception pending delivery must
+	 * be a debug-trap. Record the pending MTF state to be delivered in
+	 * vmx_check_nested_events().
+	 */
+	vmx->nested.mtf_pending = (!vcpu->arch.exception.pending ||
+				   vcpu->arch.exception.nr == DB_VECTOR);
+}
+
 static void vmx_clear_hlt(struct kvm_vcpu *vcpu)
 {
 	/*
@@ -7797,6 +7818,7 @@ static struct kvm_x86_ops vmx_x86_ops __ro_after_init = {
 	.run = vmx_vcpu_run,
 	.handle_exit = vmx_handle_exit,
 	.skip_emulated_instruction = skip_emulated_instruction,
+	.do_singlestep = vmx_do_singlestep,
 	.set_interrupt_shadow = vmx_set_interrupt_shadow,
 	.get_interrupt_shadow = vmx_get_interrupt_shadow,
 	.patch_hypercall = vmx_patch_hypercall,
diff --git a/arch/x86/kvm/vmx/vmx.h b/arch/x86/kvm/vmx/vmx.h
index a4f7f737c5d4..401e9ca23779 100644
--- a/arch/x86/kvm/vmx/vmx.h
+++ b/arch/x86/kvm/vmx/vmx.h
@@ -150,6 +150,9 @@ struct nested_vmx {
 	/* L2 must run next, and mustn't decide to exit to L1. */
 	bool nested_run_pending;
 
+	/* Pending MTF VM-exit into L1.  */
+	bool mtf_pending;
+
 	struct loaded_vmcs vmcs02;
 
 	/*
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 9f080101618c..e5c859f9b3bf 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -6626,10 +6626,15 @@ static int kvm_vcpu_check_hw_bp(unsigned long addr, u32 type, u32 dr7,
 	return dr6;
 }
 
-static int kvm_vcpu_do_singlestep(struct kvm_vcpu *vcpu)
+static int kvm_vcpu_do_singlestep(struct kvm_vcpu *vcpu, bool tf)
 {
 	struct kvm_run *kvm_run = vcpu->run;
 
+	if (kvm_x86_ops->do_singlestep)
+		kvm_x86_ops->do_singlestep(vcpu);
+	if (!tf)
+		return 1;
+
 	if (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP) {
 		kvm_run->debug.arch.dr6 = DR6_BS | DR6_FIXED_1 | DR6_RTM;
 		kvm_run->debug.arch.pc = vcpu->arch.singlestep_rip;
@@ -6658,9 +6663,7 @@ int kvm_skip_emulated_instruction(struct kvm_vcpu *vcpu)
 	 * processor will not generate this exception after the instruction
 	 * that sets the TF flag".
 	 */
-	if (unlikely(rflags & X86_EFLAGS_TF))
-		r = kvm_vcpu_do_singlestep(vcpu);
-	return r;
+	return kvm_vcpu_do_singlestep(vcpu, rflags & X86_EFLAGS_TF);
 }
 EXPORT_SYMBOL_GPL(kvm_skip_emulated_instruction);
 
@@ -6876,8 +6879,8 @@ int x86_emulate_instruction(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,
 		if (!ctxt->have_exception ||
 		    exception_type(ctxt->exception.vector) == EXCPT_TRAP) {
 			kvm_rip_write(vcpu, ctxt->eip);
-			if (r && ctxt->tf)
-				r = kvm_vcpu_do_singlestep(vcpu);
+			if (r)
+				r = kvm_vcpu_do_singlestep(vcpu, ctxt->tf);
 			__kvm_set_rflags(vcpu, ctxt->eflags);
 		}
 

From patchwork Tue Jan 28 09:27:15 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Oliver Upton <oupton@google.com>
X-Patchwork-Id: 11353869
Return-Path: <SRS0=gQxY=3R=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 4886514B4
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:41 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.kernel.org (Postfix) with ESMTP id 1E21924688
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 28 Jan 2020 09:27:41 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (2048-bit key) header.d=google.com header.i=@google.com
 header.b="wM7pV8bl"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1726024AbgA1J1k (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 28 Jan 2020 04:27:40 -0500
Received: from mail-pf1-f201.google.com ([209.85.210.201]:42890 "EHLO
        mail-pf1-f201.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725977AbgA1J1k (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 28 Jan 2020 04:27:40 -0500
Received: by mail-pf1-f201.google.com with SMTP id z26so90646pfr.9
        for <kvm@vger.kernel.org>; Tue, 28 Jan 2020 01:27:39 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20161025;
        h=date:in-reply-to:message-id:mime-version:references:subject:from:to
         :cc;
        bh=YURPBE5ARW7OYIGG4d7Fs2AlCTzDPiK6ygILDqAYQdw=;
        b=wM7pV8blQxy505Le2miTTLzfX6MBm6/ZNgEiDb9pBlVnTCbStSHPz28bmMjDRyeNyN
         MH64cu0dc+4OKu5p6mngJjNfvt9P5/mqoPtOYFjyZGwHcBipNmug/G7Tm97/80Ce0WYc
         UjkMkQN7n2nFxPG+uziZArLTMBqCl3UC7w8Id+6oy4mVRYK5Xg8RsHja7C1Lrc7wj7tk
         NoWpsmVgQuiMPsQngIF633eYbkFDPST9nw44bgb6DR4QQjAlG4wMDgkC+gyX3LiW978m
         RJCKuUU5pM8ID5l8mElskPKD913xJMsOyv+yVbF5AIiweJ0LtWAx2kABR3+F3V7/9t6L
         fiBQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:date:in-reply-to:message-id:mime-version
         :references:subject:from:to:cc;
        bh=YURPBE5ARW7OYIGG4d7Fs2AlCTzDPiK6ygILDqAYQdw=;
        b=ctdvkET6ypKo4viF9BFPV0Ol3CoykMoJM4NZmDWsb6mXt+I7dRiFuC8Y07GlSaVxWN
         C6Q/pF6tiYjC/KO6QwjpeShGLrO19GZ2ovu2zaJzJWzSH5vyL6BFSPWTo1aDfx9JK+ua
         a1K0NYMFodfe4bKB8HIrrlhu3HSK5oowD/CvG2WDfrPRyxz30z4DQ5juDFTkiCE1bZNB
         xtaeiA8a8lV3x5SEezipBdi4NnH+UD8MUb0j6XqBTRKTmskkc4lFPb7O8RSBHv7PE7yp
         mqjXc3CmVaiUFlYiUKDy03D7llCg+vqREo/PrLVFeqNOCsAFgSGnI3FDbhf77KHtiRhv
         XLcg==
X-Gm-Message-State: APjAAAVWF3kptxaiE0Ayazx0EFgvp5DFNt/9OSoKrAasxPGfxWBqFq2C
        ERPP4u4AOz+ZV7AWfG+56rd0JWbFRs+DfVm/omKhZmbSSs3sCXcMfs+yzyUO47vw9EQvki5dofc
        UPjTqamQv8ivxl2ZwO8VJDXmFtNq9HY7+qajiHflp0WIikBaNiVYywgC1CA==
X-Google-Smtp-Source: 
 APXvYqzld6o8WgRrweIoLEAG1K5ay89zmqZwbXfs6J7rRgiGG2Jo2RuC6ItgY/oxz9Ug/s1wuGMt5fZUzw8=
X-Received: by 2002:a65:6916:: with SMTP id
 s22mr23065962pgq.244.1580203659171;
 Tue, 28 Jan 2020 01:27:39 -0800 (PST)
Date: Tue, 28 Jan 2020 01:27:15 -0800
In-Reply-To: <20200128092715.69429-1-oupton@google.com>
Message-Id: <20200128092715.69429-6-oupton@google.com>
Mime-Version: 1.0
References: <20200128092715.69429-1-oupton@google.com>
X-Mailer: git-send-email 2.25.0.341.g760bfbb309-goog
Subject: [kvm-unit-tests PATCH v2 5/5] x86: VMX: Add tests for monitor trap
 flag
From: Oliver Upton <oupton@google.com>
To: kvm@vger.kernel.org
Cc: Paolo Bonzini <pbonzini@redhat.com>,
        Jim Mattson <jmattson@google.com>,
        Peter Shier <pshier@google.com>,
        Sean Christopherson <sean.j.christopherson@intel.com>,
        Oliver Upton <oupton@google.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Test to verify that MTF VM-exits into host are synthesized when the
'monitor trap flag' processor-based VM-execution control is set under
various conditions.

Expect an MTF VM-exit if instruction execution produces no events other
than MTF. Should instruction execution produce a concurrent debug-trap
and MTF event, expect an MTF VM-exit with the 'pending debug exceptions'
VMCS field set. Expect an MTF VM-exit to follow event delivery should
instruction execution generate a higher-priority event, such as a
general-protection fault. Lastly, expect an MTF VM-exit to follow
delivery of a debug-trap software exception (INT1/INT3/INTO/INT n).

Signed-off-by: Oliver Upton <oupton@google.com>
Reviewed-by: Jim Mattson <jmattson@google.com>
---
 x86/vmx.h       |   1 +
 x86/vmx_tests.c | 157 ++++++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 158 insertions(+)

diff --git a/x86/vmx.h b/x86/vmx.h
index 6214400f2b53..6adf0916564b 100644
--- a/x86/vmx.h
+++ b/x86/vmx.h
@@ -399,6 +399,7 @@ enum Ctrl0 {
 	CPU_NMI_WINDOW		= 1ul << 22,
 	CPU_IO			= 1ul << 24,
 	CPU_IO_BITMAP		= 1ul << 25,
+	CPU_MTF			= 1ul << 27,
 	CPU_MSR_BITMAP		= 1ul << 28,
 	CPU_MONITOR		= 1ul << 29,
 	CPU_PAUSE		= 1ul << 30,
diff --git a/x86/vmx_tests.c b/x86/vmx_tests.c
index b31c360c5f3c..0e2c2f8a7d34 100644
--- a/x86/vmx_tests.c
+++ b/x86/vmx_tests.c
@@ -4970,6 +4970,162 @@ static void test_vmx_preemption_timer(void)
 	vmcs_write(EXI_CONTROLS, saved_exit);
 }
 
+extern unsigned char test_mtf1;
+extern unsigned char test_mtf2;
+extern unsigned char test_mtf3;
+
+__attribute__((noclone)) static void test_mtf_guest(void)
+{
+	asm ("vmcall;\n\t"
+	     "out %al, $0x80;\n\t"
+	     "test_mtf1:\n\t"
+	     "vmcall;\n\t"
+	     "out %al, $0x80;\n\t"
+	     "test_mtf2:\n\t"
+	     /*
+	      * Prepare for the 'MOV CR3' test. Attempt to induce a
+	      * general-protection fault by moving a non-canonical address into
+	      * CR3. The 'MOV CR3' instruction does not take an imm64 operand,
+	      * so we must MOV the desired value into a register first.
+	      *
+	      * MOV RAX is done before the VMCALL such that MTF is only enabled
+	      * for the instruction under test.
+	      */
+	     "mov $0x8000000000000000, %rax;\n\t"
+	     "vmcall;\n\t"
+	     "mov %rax, %cr3;\n\t"
+	     "test_mtf3:\n\t"
+	     "vmcall;\n\t"
+	     /*
+	      * ICEBP/INT1 instruction. Though the instruction is now
+	      * documented, don't rely on assemblers enumerating the
+	      * instruction. Resort to hand assembly.
+	      */
+	     ".byte 0xf1;\n\t");
+}
+
+static void test_mtf_gp_handler(struct ex_regs *regs)
+{
+	regs->rip = (unsigned long) &test_mtf3;
+}
+
+static void test_mtf_db_handler(struct ex_regs *regs)
+{
+}
+
+static void enable_mtf(void)
+{
+	u32 ctrl0 = vmcs_read(CPU_EXEC_CTRL0);
+
+	vmcs_write(CPU_EXEC_CTRL0, ctrl0 | CPU_MTF);
+}
+
+static void disable_mtf(void)
+{
+	u32 ctrl0 = vmcs_read(CPU_EXEC_CTRL0);
+
+	vmcs_write(CPU_EXEC_CTRL0, ctrl0 & ~CPU_MTF);
+}
+
+static void enable_tf(void)
+{
+	unsigned long rflags = vmcs_read(GUEST_RFLAGS);
+
+	vmcs_write(GUEST_RFLAGS, rflags | X86_EFLAGS_TF);
+}
+
+static void disable_tf(void)
+{
+	unsigned long rflags = vmcs_read(GUEST_RFLAGS);
+
+	vmcs_write(GUEST_RFLAGS, rflags & ~X86_EFLAGS_TF);
+}
+
+static void report_mtf(const char *insn_name, unsigned long exp_rip)
+{
+	unsigned long rip = vmcs_read(GUEST_RIP);
+
+	assert_exit_reason(VMX_MTF);
+	report(rip == exp_rip, "MTF VM-exit after %s instruction. RIP: 0x%lx (expected 0x%lx)",
+	       insn_name, rip, exp_rip);
+}
+
+static void vmx_mtf_test(void)
+{
+	unsigned long pending_dbg;
+	handler old_gp, old_db;
+
+	if (!(ctrl_cpu_rev[0].clr & CPU_MTF)) {
+		printf("CPU does not support the 'monitor trap flag' processor-based VM-execution control.\n");
+		return;
+	}
+
+	test_set_guest(test_mtf_guest);
+
+	/* Expect an MTF VM-exit after OUT instruction */
+	enter_guest();
+	skip_exit_vmcall();
+
+	enable_mtf();
+	enter_guest();
+	report_mtf("OUT", (unsigned long) &test_mtf1);
+	disable_mtf();
+
+	/*
+	 * Concurrent #DB trap and MTF on instruction boundary. Expect MTF
+	 * VM-exit with populated 'pending debug exceptions' VMCS field.
+	 */
+	enter_guest();
+	skip_exit_vmcall();
+
+	enable_mtf();
+	enable_tf();
+
+	enter_guest();
+	report_mtf("OUT", (unsigned long) &test_mtf2);
+	pending_dbg = vmcs_read(GUEST_PENDING_DEBUG);
+	report(pending_dbg & DR_STEP,
+               "'pending debug exceptions' field after MTF VM-exit: 0x%lx (expected 0x%lx)",
+	       pending_dbg, (unsigned long) DR_STEP);
+
+	disable_mtf();
+	disable_tf();
+	vmcs_write(GUEST_PENDING_DEBUG, 0);
+
+	/*
+	 * #GP exception takes priority over MTF. Expect MTF VM-exit with RIP
+	 * advanced to first instruction of #GP handler.
+	 */
+	enter_guest();
+	skip_exit_vmcall();
+
+	old_gp = handle_exception(GP_VECTOR, test_mtf_gp_handler);
+
+	enable_mtf();
+	enter_guest();
+	report_mtf("MOV CR3", (unsigned long) get_idt_addr(&boot_idt[GP_VECTOR]));
+	disable_mtf();
+
+	/*
+	 * Concurrent MTF and privileged software exception (i.e. ICEBP/INT1).
+	 * MTF should follow the delivery of #DB trap, though the SDM doesn't
+	 * provide clear indication of the relative priority.
+	 */
+	enter_guest();
+	skip_exit_vmcall();
+
+	handle_exception(GP_VECTOR, old_gp);
+	old_db = handle_exception(DB_VECTOR, test_mtf_db_handler);
+
+	enable_mtf();
+	enter_guest();
+	report_mtf("INT1", (unsigned long) get_idt_addr(&boot_idt[DB_VECTOR]));
+	disable_mtf();
+
+	enter_guest();
+	handle_exception(DB_VECTOR, old_db);
+}
+
 /*
  * Tests for VM-execution control fields
  */
@@ -9505,5 +9661,6 @@ struct vmx_test vmx_tests[] = {
 	TEST(atomic_switch_max_msrs_test),
 	TEST(atomic_switch_overflow_msrs_test),
 	TEST(rdtsc_vmexit_diff_test),
+	TEST(vmx_mtf_test),
 	{ NULL, NULL, NULL, NULL, NULL, {0} },
 };
