From patchwork Mon Aug 31 19:34:11 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eric Auger <eric.auger@redhat.com>
X-Patchwork-Id: 11746905
Return-Path: <SRS0=MvWC=CJ=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id D4A14109B
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:33 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id B19122100A
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:33 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=redhat.com header.i=@redhat.com
 header.b="ZEVX7Vb8"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729259AbgHaTec (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Mon, 31 Aug 2020 15:34:32 -0400
Received: from us-smtp-delivery-1.mimecast.com ([205.139.110.120]:22754 "EHLO
        us-smtp-1.mimecast.com" rhost-flags-OK-OK-OK-FAIL) by vger.kernel.org
        with ESMTP id S1725872AbgHaTeb (ORCPT <rfc822;kvm@vger.kernel.org>);
        Mon, 31 Aug 2020 15:34:31 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=redhat.com;
        s=mimecast20190719; t=1598902470;
        h=from:from:reply-to:subject:subject:date:date:message-id:message-id:
         to:to:cc:mime-version:mime-version:
         content-transfer-encoding:content-transfer-encoding:
         in-reply-to:in-reply-to:references:references;
        bh=vtLyg6lCGileigLzG/AbjWIpEiRqxpxwtXfCaWYW4BQ=;
        b=ZEVX7Vb8OGsWmdTqUo2StbwPKBbC1YQdExZJ4AqWa1I3n5GysXiZ2NfLxCy7FWEk9A03wh
        6zCj5uC9wPUaDBXd6oriTXjrqHyn7vaCic9xemHIW2CjqK2WWEEzRGS1SP4hYM3KP7pQyt
        IqQQKvcjQ+3eSn9nYOxbbb9sJh9vkW4=
Received: from mimecast-mx01.redhat.com (mimecast-mx01.redhat.com
 [209.132.183.4]) (Using TLS) by relay.mimecast.com with ESMTP id
 us-mta-212-IZETdFkBPgyuFjCOujLmHQ-1; Mon, 31 Aug 2020 15:34:27 -0400
X-MC-Unique: IZETdFkBPgyuFjCOujLmHQ-1
Received: from smtp.corp.redhat.com (int-mx03.intmail.prod.int.phx2.redhat.com
 [10.5.11.13])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mimecast-mx01.redhat.com (Postfix) with ESMTPS id 7FF6A802B49;
        Mon, 31 Aug 2020 19:34:25 +0000 (UTC)
Received: from laptop.redhat.com (ovpn-112-112.ams2.redhat.com
 [10.36.112.112])
        by smtp.corp.redhat.com (Postfix) with ESMTP id DB7637EB7D;
        Mon, 31 Aug 2020 19:34:22 +0000 (UTC)
From: Eric Auger <eric.auger@redhat.com>
To: eric.auger.pro@gmail.com, eric.auger@redhat.com,
        kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu,
        qemu-devel@nongnu.org, drjones@redhat.com, andrew.murray@arm.com,
        sudeep.holla@arm.com, maz@kernel.org, will@kernel.org,
        haibo.xu@linaro.org
Subject: [kvm-unit-tests RFC 1/4] arm64: Move get_id_aa64dfr0() in processor.h
Date: Mon, 31 Aug 2020 21:34:11 +0200
Message-Id: <20200831193414.6951-2-eric.auger@redhat.com>
In-Reply-To: <20200831193414.6951-1-eric.auger@redhat.com>
References: <20200831193414.6951-1-eric.auger@redhat.com>
MIME-Version: 1.0
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.13
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

We plan to use get_id_aa64dfr0() for SPE tests.
So let's move this latter in processor.h header.

Signed-off-by: Eric Auger <eric.auger@redhat.com>
---
 arm/pmu.c                 | 1 -
 lib/arm64/asm/processor.h | 5 +++++
 2 files changed, 5 insertions(+), 1 deletion(-)

diff --git a/arm/pmu.c b/arm/pmu.c
index cece53e..e2cb51e 100644
--- a/arm/pmu.c
+++ b/arm/pmu.c
@@ -167,7 +167,6 @@ static void test_overflow_interrupt(void) {}
 #define ID_DFR0_PMU_V3_8_5	0b0110
 #define ID_DFR0_PMU_IMPDEF	0b1111
 
-static inline uint32_t get_id_aa64dfr0(void) { return read_sysreg(id_aa64dfr0_el1); }
 static inline uint32_t get_pmcr(void) { return read_sysreg(pmcr_el0); }
 static inline void set_pmcr(uint32_t v) { write_sysreg(v, pmcr_el0); }
 static inline uint64_t get_pmccntr(void) { return read_sysreg(pmccntr_el0); }
diff --git a/lib/arm64/asm/processor.h b/lib/arm64/asm/processor.h
index 02665b8..11b7564 100644
--- a/lib/arm64/asm/processor.h
+++ b/lib/arm64/asm/processor.h
@@ -88,6 +88,11 @@ static inline uint64_t get_mpidr(void)
 	return read_sysreg(mpidr_el1);
 }
 
+static inline uint64_t get_id_aa64dfr0(void)
+{
+	return read_sysreg(id_aa64dfr0_el1);
+}
+
 #define MPIDR_HWID_BITMASK 0xff00ffffff
 extern int mpidr_to_cpu(uint64_t mpidr);
 

From patchwork Mon Aug 31 19:34:12 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eric Auger <eric.auger@redhat.com>
X-Patchwork-Id: 11746907
Return-Path: <SRS0=MvWC=CJ=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 61C0C109B
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:40 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id 490132145D
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:40 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=redhat.com header.i=@redhat.com
 header.b="bN8YIgLV"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1725872AbgHaTei (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Mon, 31 Aug 2020 15:34:38 -0400
Received: from us-smtp-delivery-124.mimecast.com ([216.205.24.124]:50435 "EHLO
        us-smtp-delivery-124.mimecast.com" rhost-flags-OK-OK-OK-OK)
        by vger.kernel.org with ESMTP id S1728938AbgHaTeg (ORCPT
        <rfc822;kvm@vger.kernel.org>); Mon, 31 Aug 2020 15:34:36 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=redhat.com;
        s=mimecast20190719; t=1598902474;
        h=from:from:reply-to:subject:subject:date:date:message-id:message-id:
         to:to:cc:mime-version:mime-version:
         content-transfer-encoding:content-transfer-encoding:
         in-reply-to:in-reply-to:references:references;
        bh=Dlm+r41ohHjW30i+MQ1d9KTTnOYk1vHfisVWqLyZbwo=;
        b=bN8YIgLVy7MHkbnRYEl0FCPxUYtohCWB/Qz308Uv3OxeZPe5Op8yGKd7H2aq488q1D3YcH
        df1B71+gRJhLVZNzMSZLhKjzDGRfBPiXiBsy52OlFlCd2WSD8Yw96xGVQP2OI2eOa/fwN/
        GiIAlTsH/YAC8ppZ9NoAKnZDZEcPS0Y=
Received: from mimecast-mx01.redhat.com (mimecast-mx01.redhat.com
 [209.132.183.4]) (Using TLS) by relay.mimecast.com with ESMTP id
 us-mta-569-2z1t971-N1-8k9kKIHOPfA-1; Mon, 31 Aug 2020 15:34:29 -0400
X-MC-Unique: 2z1t971-N1-8k9kKIHOPfA-1
Received: from smtp.corp.redhat.com (int-mx03.intmail.prod.int.phx2.redhat.com
 [10.5.11.13])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mimecast-mx01.redhat.com (Postfix) with ESMTPS id 4C3C3100747B;
        Mon, 31 Aug 2020 19:34:28 +0000 (UTC)
Received: from laptop.redhat.com (ovpn-112-112.ams2.redhat.com
 [10.36.112.112])
        by smtp.corp.redhat.com (Postfix) with ESMTP id D5ACA7EB69;
        Mon, 31 Aug 2020 19:34:25 +0000 (UTC)
From: Eric Auger <eric.auger@redhat.com>
To: eric.auger.pro@gmail.com, eric.auger@redhat.com,
        kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu,
        qemu-devel@nongnu.org, drjones@redhat.com, andrew.murray@arm.com,
        sudeep.holla@arm.com, maz@kernel.org, will@kernel.org,
        haibo.xu@linaro.org
Subject: [kvm-unit-tests RFC 2/4] spe: Probing and Introspection Test
Date: Mon, 31 Aug 2020 21:34:12 +0200
Message-Id: <20200831193414.6951-3-eric.auger@redhat.com>
In-Reply-To: <20200831193414.6951-1-eric.auger@redhat.com>
References: <20200831193414.6951-1-eric.auger@redhat.com>
MIME-Version: 1.0
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.13
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Test whether Statistical Profiling Extensions (SPE) are
supported and in the positive collect dimensioning data from
the IDR registers. The First test only validates those.

Signed-off-by: Eric Auger <eric.auger@redhat.com>
---
 arm/Makefile.common |   1 +
 arm/spe.c           | 163 ++++++++++++++++++++++++++++++++++++++++++++
 arm/unittests.cfg   |   8 +++
 3 files changed, 172 insertions(+)
 create mode 100644 arm/spe.c

diff --git a/arm/Makefile.common b/arm/Makefile.common
index a123e85..4e7e4eb 100644
--- a/arm/Makefile.common
+++ b/arm/Makefile.common
@@ -8,6 +8,7 @@ tests-common  = $(TEST_DIR)/selftest.flat
 tests-common += $(TEST_DIR)/spinlock-test.flat
 tests-common += $(TEST_DIR)/pci-test.flat
 tests-common += $(TEST_DIR)/pmu.flat
+tests-common += $(TEST_DIR)/spe.flat
 tests-common += $(TEST_DIR)/gic.flat
 tests-common += $(TEST_DIR)/psci.flat
 tests-common += $(TEST_DIR)/sieve.flat
diff --git a/arm/spe.c b/arm/spe.c
new file mode 100644
index 0000000..153c182
--- /dev/null
+++ b/arm/spe.c
@@ -0,0 +1,163 @@
+/*
+ * Copyright (C) 2020, Red Hat Inc, Eric Auger <eric.auger@redhat.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License version 2.1 and
+ * only version 2.1 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License
+ * for more details.
+ */
+#include "libcflat.h"
+#include "errata.h"
+#include "asm/barrier.h"
+#include "asm/sysreg.h"
+#include "asm/processor.h"
+#include "alloc_page.h"
+#include <bitops.h>
+
+struct spe {
+	int min_interval;
+	int maxsize;
+	int countsize;
+	bool fl_cap;
+	bool ft_cap;
+	bool fe_cap;
+	int align;
+	void *buffer;
+	bool unique_record_size;
+};
+
+static struct spe spe;
+
+#ifdef __arm__
+
+static bool spe_probe(void) { return false; }
+static void test_spe_introspection(void) { }
+
+#else
+
+#define ID_DFR0_PMSVER_SHIFT	32
+#define ID_DFR0_PMSVER_MASK	0xF
+
+#define PMBIDR_EL1_ALIGN_MASK	0xF
+#define PMBIDR_EL1_P		0x10
+#define PMBIDR_EL1_F		0x20
+
+#define PMSIDR_EL1_FE		0x1
+#define PMSIDR_EL1_FT		0x2
+#define PMSIDR_EL1_FL		0x4
+#define PMSIDR_EL1_ARCHINST	0x8
+#define PMSIDR_EL1_LDS		0x10
+#define PMSIDR_EL1_ERND		0x20
+#define PMSIDR_EL1_INTERVAL_SHIFT	8
+#define PMSIDR_EL1_INTERVAL_MASK	0xFUL
+#define PMSIDR_EL1_MAXSIZE_SHIFT	12
+#define PMSIDR_EL1_MAXSIZE_MASK		0xFUL
+#define PMSIDR_EL1_COUNTSIZE_SHIFT	16
+#define PMSIDR_EL1_COUNTSIZE_MASK	0xFUL
+
+#define PMSIDR_EL1	sys_reg(3, 0, 9, 9, 7)
+
+#define PMBIDR_EL1	sys_reg(3, 0, 9, 10, 7)
+
+static int min_interval(uint8_t idr_bits)
+{
+	switch (idr_bits) {
+	case 0x0:
+		return 256;
+	case 0x2:
+		return 512;
+	case 0x3:
+		return 768;
+	case 0x4:
+		return 1024;
+	case 0x5:
+		return 1536;
+	case 0x6:
+		return 2048;
+	case 0x7:
+		return 3072;
+	case 0x8:
+		return 4096;
+	default:
+		return -1;
+	}
+}
+
+static bool spe_probe(void)
+{
+	uint64_t pmbidr_el1, pmsidr_el1;
+	uint8_t pmsver;
+
+	pmsver = (get_id_aa64dfr0() >> ID_DFR0_PMSVER_SHIFT) & ID_DFR0_PMSVER_MASK;
+
+	report_info("PMSVer = %d", pmsver);
+	if (!pmsver || pmsver > 2)
+		return false;
+
+	pmbidr_el1 = read_sysreg_s(PMBIDR_EL1);
+	if (pmbidr_el1 & PMBIDR_EL1_P) {
+		report_info("MBIDR_EL1: Profiling buffer owned by this exception level");
+		return false;
+	}
+
+	spe.align = 1 << (pmbidr_el1 & PMBIDR_EL1_ALIGN_MASK);
+
+	pmsidr_el1 = read_sysreg_s(PMSIDR_EL1);
+
+	spe.min_interval = min_interval((pmsidr_el1 >> PMSIDR_EL1_INTERVAL_SHIFT) & PMSIDR_EL1_INTERVAL_MASK);
+	spe.maxsize = 1 << ((pmsidr_el1 >> PMSIDR_EL1_MAXSIZE_SHIFT) & PMSIDR_EL1_MAXSIZE_MASK);
+	spe.countsize = (pmsidr_el1 >> PMSIDR_EL1_COUNTSIZE_SHIFT) & PMSIDR_EL1_COUNTSIZE_MASK;
+
+	spe.fl_cap = pmsidr_el1 & PMSIDR_EL1_FL;
+	spe.ft_cap = pmsidr_el1 & PMSIDR_EL1_FT;
+	spe.fe_cap = pmsidr_el1 & PMSIDR_EL1_FE;
+
+	report_info("Align= %d bytes, Min Interval=%d Single record Max Size = %d bytes",
+			spe.align, spe.min_interval, spe.maxsize);
+	report_info("Filtering Caps: Lat=%d Type=%d Events=%d", spe.fl_cap, spe.ft_cap, spe.fe_cap);
+	if (spe.align == spe.maxsize) {
+		report_info("Each record is exactly %d bytes", spe.maxsize);
+		spe.unique_record_size = true;
+	}
+
+	spe.buffer = alloc_pages(0);
+
+	return true;
+}
+
+static void test_spe_introspection(void)
+{
+	report(spe.countsize == 0x2, "PMSIDR_EL1: CountSize = 0b0010");
+	report(spe.maxsize >= 16 && spe.maxsize <= 2048,
+		"PMSIDR_EL1: Single record max size = %d bytes", spe.maxsize);
+	report(spe.min_interval >= 256 && spe.min_interval <= 4096,
+		"PMSIDR_EL1: Minimal sampling interval = %d", spe.min_interval);
+}
+
+#endif
+
+int main(int argc, char *argv[])
+{
+	if (!spe_probe()) {
+		printf("SPE not supported, test skipped...\n");
+		return report_summary();
+	}
+
+	if (argc < 2)
+		report_abort("no test specified");
+
+	report_prefix_push("spe");
+
+	if (strcmp(argv[1], "spe-introspection") == 0) {
+		report_prefix_push(argv[1]);
+		test_spe_introspection();
+		report_prefix_pop();
+	} else {
+		report_abort("Unknown sub-test '%s'", argv[1]);
+	}
+	return report_summary();
+}
diff --git a/arm/unittests.cfg b/arm/unittests.cfg
index f776b66..c070939 100644
--- a/arm/unittests.cfg
+++ b/arm/unittests.cfg
@@ -134,6 +134,14 @@ extra_params = -append 'pmu-overflow-interrupt'
 #groups = pmu
 #accel = tcg
 
+[spe-introspection]
+file = spe.flat
+groups = spe
+arch = arm64
+extra_params = -append 'spe-introspection'
+accel = kvm
+arch = arm64
+
 # Test GIC emulation
 [gicv2-ipi]
 file = gic.flat

From patchwork Mon Aug 31 19:34:13 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eric Auger <eric.auger@redhat.com>
X-Patchwork-Id: 11746909
Return-Path: <SRS0=MvWC=CJ=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 1A0E3722
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:42 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id F0C2C2145D
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:41 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=redhat.com header.i=@redhat.com
 header.b="QKI1V/Ke"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729531AbgHaTel (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Mon, 31 Aug 2020 15:34:41 -0400
Received: from us-smtp-1.mimecast.com ([207.211.31.81]:33585 "EHLO
        us-smtp-delivery-1.mimecast.com" rhost-flags-OK-OK-OK-FAIL)
        by vger.kernel.org with ESMTP id S1729430AbgHaTej (ORCPT
        <rfc822;kvm@vger.kernel.org>); Mon, 31 Aug 2020 15:34:39 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=redhat.com;
        s=mimecast20190719; t=1598902476;
        h=from:from:reply-to:subject:subject:date:date:message-id:message-id:
         to:to:cc:mime-version:mime-version:
         content-transfer-encoding:content-transfer-encoding:
         in-reply-to:in-reply-to:references:references;
        bh=TGiGuMkb/kt3ln7/bHWTnbLda6Wmue4f9drr7QeU4IY=;
        b=QKI1V/KedQUbaNATlkEioApYihxZcEywI+F3LdZuhBp2594QDIHQLO/cNaHJeUvDQR2MgQ
        OD8OSrloMw41gRr758TrXUbrxJo2WjmYcHmXKNA0Meq7q2WfwLTVdTsSMI1GJ+8o6s52hv
        k71oc1DBgWJtvRFEYZ+VAVCGSE2af9Y=
Received: from mimecast-mx01.redhat.com (mimecast-mx01.redhat.com
 [209.132.183.4]) (Using TLS) by relay.mimecast.com with ESMTP id
 us-mta-105-W7Q8DgKwPvCiInBKbhD9sg-1; Mon, 31 Aug 2020 15:34:32 -0400
X-MC-Unique: W7Q8DgKwPvCiInBKbhD9sg-1
Received: from smtp.corp.redhat.com (int-mx03.intmail.prod.int.phx2.redhat.com
 [10.5.11.13])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mimecast-mx01.redhat.com (Postfix) with ESMTPS id 1B6BA18A224C;
        Mon, 31 Aug 2020 19:34:31 +0000 (UTC)
Received: from laptop.redhat.com (ovpn-112-112.ams2.redhat.com
 [10.36.112.112])
        by smtp.corp.redhat.com (Postfix) with ESMTP id A3A3B7EB69;
        Mon, 31 Aug 2020 19:34:28 +0000 (UTC)
From: Eric Auger <eric.auger@redhat.com>
To: eric.auger.pro@gmail.com, eric.auger@redhat.com,
        kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu,
        qemu-devel@nongnu.org, drjones@redhat.com, andrew.murray@arm.com,
        sudeep.holla@arm.com, maz@kernel.org, will@kernel.org,
        haibo.xu@linaro.org
Subject: [kvm-unit-tests RFC 3/4] spe: Add profiling buffer test
Date: Mon, 31 Aug 2020 21:34:13 +0200
Message-Id: <20200831193414.6951-4-eric.auger@redhat.com>
In-Reply-To: <20200831193414.6951-1-eric.auger@redhat.com>
References: <20200831193414.6951-1-eric.auger@redhat.com>
MIME-Version: 1.0
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.13
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Add the code to prepare for profiling at EL1. The code under profiling
is a simple loop doing memory addresses. We simply check the profiling
buffer write position increases, ie. the buffer gets filled. No event
is expected.

Signed-off-by: Eric Auger <eric.auger@redhat.com>
---

To make sure no buffer full events is likely to be received, the number
of to be collected events should be estimated. This needs to be done.
Same for next patch. I tried to read PMSICR.COUNT after a single iteration
but I get a value greated than the set interval so I wonder whether this
is a bug or rather than reading this value gives unpredictable value.
---
 arm/spe.c               | 161 ++++++++++++++++++++++++++++++++++++++++
 arm/unittests.cfg       |   8 ++
 lib/arm64/asm/barrier.h |   1 +
 3 files changed, 170 insertions(+)

diff --git a/arm/spe.c b/arm/spe.c
index 153c182..7996f79 100644
--- a/arm/spe.c
+++ b/arm/spe.c
@@ -14,9 +14,11 @@
 #include "errata.h"
 #include "asm/barrier.h"
 #include "asm/sysreg.h"
+#include "asm/page.h"
 #include "asm/processor.h"
 #include "alloc_page.h"
 #include <bitops.h>
+#include "alloc.h"
 
 struct spe {
 	int min_interval;
@@ -27,6 +29,10 @@ struct spe {
 	bool fe_cap;
 	int align;
 	void *buffer;
+	uint64_t pmbptr_el1;
+	uint64_t pmblimitr_el1;
+	uint64_t pmsirr_el1;
+	uint64_t pmscr_el1;
 	bool unique_record_size;
 };
 
@@ -36,6 +42,7 @@ static struct spe spe;
 
 static bool spe_probe(void) { return false; }
 static void test_spe_introspection(void) { }
+static void test_spe_buffer(void) { }
 
 #else
 
@@ -59,10 +66,35 @@ static void test_spe_introspection(void) { }
 #define PMSIDR_EL1_COUNTSIZE_SHIFT	16
 #define PMSIDR_EL1_COUNTSIZE_MASK	0xFUL
 
+#define PMSIRR_EL1_INTERVAL_SHIFT	8
+#define PMSIRR_EL1_INTERVAL_MASK	0xFFFFFF
+
+#define PMSFCR_EL1_FE			0x1
+#define PMSFCR_EL1_FT			0x2
+#define PMSFCR_EL1_FL			0x4
+#define PMSFCR_EL1_B			0x10000
+#define PMSFCR_EL1_LD			0x20000
+#define PMSFCR_EL1_ST			0x40000
+
+#define PMSCR_EL1	sys_reg(3, 0, 9, 9, 0)
+#define PMSICR_EL1	sys_reg(3, 0, 9, 9, 2)
+#define PMSIRR_EL1	sys_reg(3, 0, 9, 9, 3)
+#define PMSFCR_EL1	sys_reg(3, 0, 9, 9, 4)
+#define PMSEVFR_EL1	sys_reg(3, 0, 9, 9, 5)
 #define PMSIDR_EL1	sys_reg(3, 0, 9, 9, 7)
 
+#define PMBLIMITR_EL1	sys_reg(3, 0, 9, 10, 0)
+#define PMBPTR_EL1	sys_reg(3, 0, 9, 10, 1)
+#define PMBSR_EL1	sys_reg(3, 0, 9, 10, 3)
 #define PMBIDR_EL1	sys_reg(3, 0, 9, 10, 7)
 
+#define PMBLIMITR_EL1_E			0x1
+
+#define PMSCR_EL1_E1SPE			0x2
+#define PMSCR_EL1_PA			0x10
+#define PMSCR_EL1_TS			0x20
+#define PMSCR_EL1_PCT			0x40
+
 static int min_interval(uint8_t idr_bits)
 {
 	switch (idr_bits) {
@@ -138,6 +170,131 @@ static void test_spe_introspection(void)
 		"PMSIDR_EL1: Minimal sampling interval = %d", spe.min_interval);
 }
 
+static void mem_access_loop(void *addr, int loop, uint64_t pmblimitr)
+{
+asm volatile(
+	"	msr_s " xstr(PMBLIMITR_EL1) ", %[pmblimitr]\n"
+	"       isb\n"
+	"       mov     x10, %[loop]\n"
+	"1:     sub     x10, x10, #1\n"
+	"       ldr     x9, [%[addr]]\n"
+	"       cmp     x10, #0x0\n"
+	"       b.gt    1b\n"
+	"	bfxil   %[pmblimitr], xzr, 0, 1\n"
+	"	msr_s " xstr(PMBLIMITR_EL1) ", %[pmblimitr]\n"
+	"       isb\n"
+	:
+	: [addr] "r" (addr), [pmblimitr] "r" (pmblimitr), [loop] "r" (loop)
+	: "x8", "x9", "x10", "cc");
+}
+
+char null_buff[PAGE_SIZE] = {};
+
+static void reset(void)
+{
+	/* erase the profiling buffer, reset the start and limit addresses */
+	spe.pmbptr_el1 = (uint64_t)spe.buffer;
+	spe.pmblimitr_el1 = (uint64_t)(spe.buffer + PAGE_SIZE);
+	write_sysreg_s(spe.pmbptr_el1, PMBPTR_EL1);
+	write_sysreg_s(spe.pmblimitr_el1, PMBLIMITR_EL1);
+	isb();
+
+	/* Drain any buffered data */
+	psb_csync();
+	dsb(nsh);
+
+	memset(spe.buffer, 0, PAGE_SIZE);
+
+	/* reset the syndrome register */
+	write_sysreg_s(0, PMBSR_EL1);
+
+	/* SW must write 0 to PMSICR_EL1 before enabling sampling profiling */
+	write_sysreg_s(0, PMSICR_EL1);
+
+	/* Filtering disabled */
+	write_sysreg_s(0, PMSFCR_EL1);
+
+	/* Interval Reload Register */
+	spe.pmsirr_el1 = (spe.min_interval & PMSIRR_EL1_INTERVAL_MASK) << PMSIRR_EL1_INTERVAL_SHIFT;
+	write_sysreg_s(spe.pmsirr_el1, PMSIRR_EL1);
+
+	/* Control Registrer */
+	spe.pmscr_el1 = PMSCR_EL1_E1SPE | PMSCR_EL1_TS | PMSCR_EL1_PCT | PMSCR_EL1_PA;
+	write_sysreg_s(spe.pmscr_el1, PMSCR_EL1);
+
+	/* Make sure the syndrome register is void */
+	write_sysreg_s(0, PMBSR_EL1);
+}
+
+static inline void drain(void)
+{
+	/* ensure profiling data are written */
+	psb_csync();
+	dsb(nsh);
+}
+
+static void test_spe_buffer(void)
+{
+	uint64_t pmbsr_el1, val1, val2;
+	void *addr = malloc(10 * PAGE_SIZE);
+
+	reset();
+
+	val1 = read_sysreg_s(PMBPTR_EL1);
+	val2 = read_sysreg_s(PMBLIMITR_EL1);
+	report(val1 == spe.pmbptr_el1 && val2 == spe.pmblimitr_el1,
+	       "PMBPTR_EL1, PMBLIMITR_EL1: reset");
+
+	val1 = read_sysreg_s(PMSIRR_EL1);
+	report(val1 == spe.pmsirr_el1, "PMSIRR_EL1: Sampling interval set to %d", spe.min_interval);
+
+	val1 = read_sysreg_s(PMSCR_EL1);
+	report(val1 == spe.pmscr_el1, "PMSCR_EL1: EL1 Statistical Profiling enabled");
+
+	val1 = read_sysreg_s(PMSFCR_EL1);
+	report(!val1, "PMSFCR_EL1: No Filter Control");
+
+	report(!memcmp(spe.buffer, null_buff, PAGE_SIZE),
+		       "Profiling buffer empty before profiling");
+
+	val1 = read_sysreg_s(PMBSR_EL1);
+	report(!val1, "PMBSR_EL1: Syndrome Register void before profiling");
+
+	mem_access_loop(addr, 1, spe.pmblimitr_el1 | PMBLIMITR_EL1_E);
+	drain();
+	val1 = read_sysreg_s(PMSICR_EL1);
+	/*
+	 * TODO: the value read in PMSICR_EL1.count currently seems not consistent with
+	 * programmed interval. Getting a good value would allow to estimate the number
+	 * of records to be collected in next step.
+	 */
+	report_info("count for a single iteration: PMSICR_EL1.count=%lld interval=%d",
+		    val1 & GENMASK_ULL(31, 0), spe.min_interval);
+
+	/* Stuff to profile */
+
+	mem_access_loop(addr, 1000000, spe.pmblimitr_el1 | PMBLIMITR_EL1_E);
+
+	/* end of stuff to profile */
+
+	drain();
+
+	report(memcmp(spe.buffer, null_buff, PAGE_SIZE), "Profiling buffer filled");
+
+	val1 = read_sysreg_s(PMBPTR_EL1);
+	val2 = val1 - (uint64_t)spe.buffer;
+	report(val1 > (uint64_t)spe.buffer,
+		"PMBPTR_EL1: Current write position has increased: 0x%lx -> 0x%lx (%ld bytes)",
+		(uint64_t)spe.buffer, val1, val2);
+	if (spe.unique_record_size)
+		report_info("This corresponds to %ld record(s) of %d bytes",
+			    val2 / spe.maxsize, spe.maxsize);
+	pmbsr_el1 = read_sysreg_s(PMBSR_EL1);
+	report(!pmbsr_el1, "PMBSR_EL1: no event");
+
+	free(addr);
+}
+
 #endif
 
 int main(int argc, char *argv[])
@@ -156,6 +313,10 @@ int main(int argc, char *argv[])
 		report_prefix_push(argv[1]);
 		test_spe_introspection();
 		report_prefix_pop();
+	} else if (strcmp(argv[1], "spe-buffer") == 0) {
+		report_prefix_push(argv[1]);
+		test_spe_buffer();
+		report_prefix_pop();
 	} else {
 		report_abort("Unknown sub-test '%s'", argv[1]);
 	}
diff --git a/arm/unittests.cfg b/arm/unittests.cfg
index c070939..bb0e84c 100644
--- a/arm/unittests.cfg
+++ b/arm/unittests.cfg
@@ -142,6 +142,14 @@ extra_params = -append 'spe-introspection'
 accel = kvm
 arch = arm64
 
+[spe-buffer]
+file = spe.flat
+groups = spe
+arch = arm64
+extra_params = -append 'spe-buffer'
+accel = kvm
+arch = arm64
+
 # Test GIC emulation
 [gicv2-ipi]
 file = gic.flat
diff --git a/lib/arm64/asm/barrier.h b/lib/arm64/asm/barrier.h
index 0e1904c..f9ede15 100644
--- a/lib/arm64/asm/barrier.h
+++ b/lib/arm64/asm/barrier.h
@@ -23,5 +23,6 @@
 #define smp_mb()	dmb(ish)
 #define smp_rmb()	dmb(ishld)
 #define smp_wmb()	dmb(ishst)
+#define psb_csync()	asm volatile("hint #17" : : : "memory")
 
 #endif /* _ASMARM64_BARRIER_H_ */

From patchwork Mon Aug 31 19:34:14 2020
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Eric Auger <eric.auger@redhat.com>
X-Patchwork-Id: 11746911
Return-Path: <SRS0=MvWC=CJ=vger.kernel.org=kvm-owner@kernel.org>
Received: from mail.kernel.org (pdx-korg-mail-1.web.codeaurora.org
 [172.30.200.123])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 418E7722
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:43 +0000 (UTC)
Received: from vger.kernel.org (vger.kernel.org [23.128.96.18])
	by mail.kernel.org (Postfix) with ESMTP id 2509620FC3
	for <patchwork-kvm@patchwork.kernel.org>;
 Mon, 31 Aug 2020 19:34:43 +0000 (UTC)
Authentication-Results: mail.kernel.org;
	dkim=pass (1024-bit key) header.d=redhat.com header.i=@redhat.com
 header.b="WIhWWcLq"
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1729348AbgHaTel (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Mon, 31 Aug 2020 15:34:41 -0400
Received: from us-smtp-2.mimecast.com ([205.139.110.61]:24907 "EHLO
        us-smtp-delivery-1.mimecast.com" rhost-flags-OK-OK-OK-FAIL)
        by vger.kernel.org with ESMTP id S1729455AbgHaTej (ORCPT
        <rfc822;kvm@vger.kernel.org>); Mon, 31 Aug 2020 15:34:39 -0400
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=redhat.com;
        s=mimecast20190719; t=1598902477;
        h=from:from:reply-to:subject:subject:date:date:message-id:message-id:
         to:to:cc:mime-version:mime-version:
         content-transfer-encoding:content-transfer-encoding:
         in-reply-to:in-reply-to:references:references;
        bh=UbfoLXN+nHRwFXdTrfiaSZqZbGEzYEgETohlSjexE70=;
        b=WIhWWcLq12Jsf9yQjTV5hvkLkRGoQMQEhTLzeIbJ8iNbbbaA7Fs+Ac0Daovcl38rrTd7MB
        /KXY4iDtGWSGjLSgZlLfLQuDqgety/VatpMEOILgOtpr8MeYXQrTQ3faztR+eqQ5D7d2rT
        YCjYRwmmSL6u05FFW2pcBjlH2VmD+QQ=
Received: from mimecast-mx01.redhat.com (mimecast-mx01.redhat.com
 [209.132.183.4]) (Using TLS) by relay.mimecast.com with ESMTP id
 us-mta-184-RB50YXbIM1yGtBsKCVNXEg-1; Mon, 31 Aug 2020 15:34:35 -0400
X-MC-Unique: RB50YXbIM1yGtBsKCVNXEg-1
Received: from smtp.corp.redhat.com (int-mx03.intmail.prod.int.phx2.redhat.com
 [10.5.11.13])
        (using TLSv1.2 with cipher AECDH-AES256-SHA (256/256 bits))
        (No client certificate requested)
        by mimecast-mx01.redhat.com (Postfix) with ESMTPS id DF1EC8030DD;
        Mon, 31 Aug 2020 19:34:33 +0000 (UTC)
Received: from laptop.redhat.com (ovpn-112-112.ams2.redhat.com
 [10.36.112.112])
        by smtp.corp.redhat.com (Postfix) with ESMTP id 7169F7EB85;
        Mon, 31 Aug 2020 19:34:31 +0000 (UTC)
From: Eric Auger <eric.auger@redhat.com>
To: eric.auger.pro@gmail.com, eric.auger@redhat.com,
        kvm@vger.kernel.org, kvmarm@lists.cs.columbia.edu,
        qemu-devel@nongnu.org, drjones@redhat.com, andrew.murray@arm.com,
        sudeep.holla@arm.com, maz@kernel.org, will@kernel.org,
        haibo.xu@linaro.org
Subject: [kvm-unit-tests RFC 4/4] spe: Test Profiling Buffer Events
Date: Mon, 31 Aug 2020 21:34:14 +0200
Message-Id: <20200831193414.6951-5-eric.auger@redhat.com>
In-Reply-To: <20200831193414.6951-1-eric.auger@redhat.com>
References: <20200831193414.6951-1-eric.auger@redhat.com>
MIME-Version: 1.0
X-Scanned-By: MIMEDefang 2.79 on 10.5.11.13
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org

Setup the infrastructure to check the occurence of events.
The test checks the Buffer Full event occurs when no space
is available. The PPI is handled and we check the syndrome register
against the expected event.

Signed-off-by: Eric Auger <eric.auger@redhat.com>
---
 arm/spe.c         | 141 +++++++++++++++++++++++++++++++++++++++++++++-
 arm/unittests.cfg |   8 +++
 2 files changed, 148 insertions(+), 1 deletion(-)

diff --git a/arm/spe.c b/arm/spe.c
index 7996f79..2f5ee35 100644
--- a/arm/spe.c
+++ b/arm/spe.c
@@ -19,6 +19,7 @@
 #include "alloc_page.h"
 #include <bitops.h>
 #include "alloc.h"
+#include <asm/gic.h>
 
 struct spe {
 	int min_interval;
@@ -36,13 +37,37 @@ struct spe {
 	bool unique_record_size;
 };
 
+enum spe_event_exception_class {
+	EC_STAGE1_DATA_ABORT =  0x24,
+	EC_STAGE2_DATA_ABORT = 0x25,
+	EC_OTHER = 0,
+};
+
+struct spe_event {
+	enum spe_event_exception_class ec;
+	bool dl;	/* data lost */
+	bool ea;	/* external abort */
+	bool s;		/* service */
+	bool coll;	/* collision */
+	union {
+		bool buffer_filled; /* ec = other */
+	} mss;
+};
+
 static struct spe spe;
 
+struct spe_stats {
+	struct spe_event observed;
+	bool unexpected;
+};
+static struct spe_stats spe_stats;
+
 #ifdef __arm__
 
 static bool spe_probe(void) { return false; }
 static void test_spe_introspection(void) { }
 static void test_spe_buffer(void) { }
+static void test_spe_events(void) { }
 
 #else
 
@@ -95,6 +120,16 @@ static void test_spe_buffer(void) { }
 #define PMSCR_EL1_TS			0x20
 #define PMSCR_EL1_PCT			0x40
 
+#define PMBSR_EL1_COLL			0x10000
+#define PMBSR_EL1_S			0x20000
+#define PMBSR_EL1_EA			0x40000
+#define PMBSR_EL1_DL			0x80000
+#define PMBSR_EL1_EC_SHIFT		26
+#define PMBSR_EL1_EC_MASK		0x3F
+#define PMBSR_EL1_MISS_MASK		0xFFFF
+
+#define SPE_PPI 21
+
 static int min_interval(uint8_t idr_bits)
 {
 	switch (idr_bits) {
@@ -119,6 +154,44 @@ static int min_interval(uint8_t idr_bits)
 	}
 }
 
+static int decode_syndrome_register(uint64_t sr, struct spe_event *event, bool verbose)
+{
+	if (!sr)
+		return 0;
+
+	if (sr & PMBSR_EL1_S)
+		event->s = true;
+	if (sr & PMBSR_EL1_COLL)
+		event->coll = true;
+	if (sr & PMBSR_EL1_EA)
+		event->ea = true;
+	if (sr & PMBSR_EL1_DL)
+		event->dl = true;
+	if (verbose)
+		report_info("PMBSR_EL1: Service=%d Collision=%d External Fault=%d DataLost=%d",
+			    event->s, event->coll, event->ea, event->dl);
+
+	switch ((sr >> PMBSR_EL1_EC_SHIFT) & PMBSR_EL1_EC_MASK) {
+	case EC_OTHER:
+		event->ec = EC_OTHER;
+		event->mss.buffer_filled = sr & 0x1;
+		if (verbose)
+			report_info("PMBSR_EL1: EC = OTHER buffer filled=%d", event->mss.buffer_filled);
+		break;
+	case EC_STAGE1_DATA_ABORT:
+		event->ec = EC_STAGE1_DATA_ABORT;
+		report_info("PMBSR_EL1: EC = stage 1 data abort");
+		break;
+	case EC_STAGE2_DATA_ABORT:
+		event->ec = EC_STAGE2_DATA_ABORT;
+		report_info("PMBSR_EL1: EC = stage 2 data abort");
+		break;
+	default:
+		return -1;
+	}
+	return 0;
+}
+
 static bool spe_probe(void)
 {
 	uint64_t pmbidr_el1, pmsidr_el1;
@@ -224,6 +297,13 @@ static void reset(void)
 
 	/* Make sure the syndrome register is void */
 	write_sysreg_s(0, PMBSR_EL1);
+
+	memset(&spe_stats, 0, sizeof(spe_stats));
+}
+
+inline bool event_match(struct spe_event *observed, struct spe_event *expected)
+{
+	return !memcmp(observed, expected, sizeof(struct spe_event));
 }
 
 static inline void drain(void)
@@ -235,6 +315,7 @@ static inline void drain(void)
 
 static void test_spe_buffer(void)
 {
+	struct spe_event observed = {}, expected = {};
 	uint64_t pmbsr_el1, val1, val2;
 	void *addr = malloc(10 * PAGE_SIZE);
 
@@ -290,7 +371,61 @@ static void test_spe_buffer(void)
 		report_info("This corresponds to %ld record(s) of %d bytes",
 			    val2 / spe.maxsize, spe.maxsize);
 	pmbsr_el1 = read_sysreg_s(PMBSR_EL1);
-	report(!pmbsr_el1, "PMBSR_EL1: no event");
+	report(!(decode_syndrome_register(pmbsr_el1, &observed, true)) &&
+	       event_match(&observed, &expected), "PMBSR_EL1: no event");
+
+	free(addr);
+}
+
+static void irq_handler(struct pt_regs *regs)
+{
+	uint32_t irqstat, irqnr;
+
+	irqstat = gic_read_iar();
+	irqnr = gic_iar_irqnr(irqstat);
+
+	if (irqnr == SPE_PPI) {
+		uint64_t pmbsr_el1 = read_sysreg_s(PMBSR_EL1);
+
+		if (decode_syndrome_register(pmbsr_el1, &spe_stats.observed, true))
+			spe_stats.unexpected = true;
+		report_info("SPE IRQ! SR=0x%lx", pmbsr_el1);
+		write_sysreg_s(0, PMBSR_EL1);
+	} else {
+		spe_stats.unexpected = true;
+	}
+	gic_write_eoir(irqstat);
+}
+
+static inline bool has_event_occurred(struct spe_event *expected)
+{
+	return (!spe_stats.unexpected && event_match(&spe_stats.observed, expected));
+}
+
+static void test_spe_events(void)
+{
+	struct spe_event expected = {.ec = EC_OTHER, .mss.buffer_filled = true, .s = true};
+	void *addr = malloc(10 * PAGE_SIZE);
+
+	gic_enable_defaults();
+	install_irq_handler(EL1H_IRQ, irq_handler);
+	local_irq_enable();
+	gic_enable_irq(SPE_PPI);
+
+	reset();
+
+	/* Willingly set pmblimitr tp pmdptr */
+	spe.pmblimitr_el1 = spe.pmbptr_el1;
+
+	mem_access_loop(addr, 100000, spe.pmblimitr_el1 | PMBLIMITR_EL1_E);
+	drain();
+	report(has_event_occurred(&expected), "PMBSR_EL1: buffer full event");
+
+	/* redo it once */
+
+	mem_access_loop(addr, 100000, spe.pmblimitr_el1 | PMBLIMITR_EL1_E);
+	drain();
+	report(has_event_occurred(&expected), "PMBSR_EL1: buffer full event");
 
 	free(addr);
 }
@@ -317,6 +452,10 @@ int main(int argc, char *argv[])
 		report_prefix_push(argv[1]);
 		test_spe_buffer();
 		report_prefix_pop();
+	} else if (strcmp(argv[1], "spe-events") == 0) {
+		report_prefix_push(argv[1]);
+		test_spe_events();
+		report_prefix_pop();
 	} else {
 		report_abort("Unknown sub-test '%s'", argv[1]);
 	}
diff --git a/arm/unittests.cfg b/arm/unittests.cfg
index bb0e84c..b2b07be 100644
--- a/arm/unittests.cfg
+++ b/arm/unittests.cfg
@@ -150,6 +150,14 @@ extra_params = -append 'spe-buffer'
 accel = kvm
 arch = arm64
 
+[spe-events]
+file = spe.flat
+groups = spe
+arch = arm64
+extra_params = -append 'spe-events'
+accel = kvm
+arch = arm64
+
 # Test GIC emulation
 [gicv2-ipi]
 file = gic.flat
